#!!!!!!!!!!!!!! pip install rpy2==3.5.1  æ–°ã—ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹

# åŸºæœ¬çš„ã«globalå¤‰æ•°ã§è¨ˆç®—ã™ã‚‹ã€‚
# pythonã‹ã‚‰assgnã•ã‚Œã‚‹ã®ã¯globalå¤‰æ•°


import streamlit as st
import rpy2
import csv
import re
import os
import numpy as np
import pandas as pd
import rpy2.robjects as ro
from rpy2.robjects.packages import importr
from rpy2.robjects import pandas2ri
from rpy2.robjects.vectors import StrVector
import pyper
import shutil
from PIL import Image
from helper_func import clear_old_directories, clear_old_files, remove_after_space, remove_sample_num
import time
import sys
from rpy2.robjects.conversion import localconverter

from collections import Counter

def clean_column_names_for_r(df):
    """
    Convert DataFrame column names to R-safe format
    """
    original_columns = df.columns.tolist()
    cleaned_columns = []
    mapping = {}
    
    for col in original_columns:
        # Rå®‰å…¨ãªæ–‡å­—ï¼ˆè‹±æ•°å­—ã¨ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ï¼‰ä»¥å¤–ã‚’ãƒ”ãƒªã‚ªãƒ‰ã«ç½®æ›
        cleaned = re.sub(r'[^a-zA-Z0-9_]', '.', str(col))
        # å…ˆé ­ãŒæ•°å­—ã®å ´åˆã¯Xã‚’è¿½åŠ 
        if cleaned and cleaned[0].isdigit():
            cleaned = 'X' + cleaned
        # é€£ç¶šã™ã‚‹ãƒ”ãƒªã‚ªãƒ‰ã‚’1ã¤ã«
        cleaned = re.sub(r'\.+', '.', cleaned)
        # æœ«å°¾ã®ãƒ”ãƒªã‚ªãƒ‰ã‚’å‰Šé™¤
        cleaned = cleaned.rstrip('.')
        
        cleaned_columns.append(cleaned)
        if col != cleaned:
            mapping[col] = cleaned
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚«ãƒ©ãƒ åã‚’å¤‰æ›´
    df.columns = cleaned_columns
    
    return df, mapping, original_columns

def remove_common_suffix(strings):
    if not strings or len(strings) == 0:
        return []    
    # æœ€ã‚‚çŸ­ã„æ–‡å­—åˆ—ã®é•·ã•ã‚’å–å¾—
    min_length = min(len(s) for s in strings)
    # å…±é€šã®æœ«å°¾éƒ¨åˆ†ã®é•·ã•ã‚’è¦‹ã¤ã‘ã‚‹
    suffix_length = 0
    for i in range(1, min_length + 1):
        suffix = strings[0][-i:]
        if all(s.endswith(suffix) for s in strings):
            suffix_length = i
        else:
            break            
    # å…±é€šã®æœ«å°¾éƒ¨åˆ†ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯å…ƒã®ãƒªã‚¹ãƒˆã‚’è¿”ã™
    if suffix_length == 0:
        return strings        
    # å…±é€šã®æœ«å°¾éƒ¨åˆ†ã‚’å‰Šé™¤ã—ã¦æ–°ã—ã„ãƒªã‚¹ãƒˆã‚’ä½œæˆ
    return [s[:-suffix_length] for s in strings]


def rename_duplicates(df):
    """
    Rename duplicate indices by adding _2, _3, etc. to subsequent occurrences   
    Args:
        df: pandas DataFrame
    Returns:
        DataFrame with renamed indices
    """
    # Get current index values
    lis = df.index.values
    
    # Count occurrences of each value
    counts = Counter()
    new_indices = []
    
    for x in lis:
        counts[x] += 1
        if counts[x] == 1:
            new_indices.append(x)
        else:
            new_indices.append(f"{x}_{counts[x]}")
    
    # Check if there were any duplicates
    if len(lis) != len(set(lis)):
        st.markdown("#### There are duplicated rows. Converting the names...")
        st.write("The gene names of subsequent occurrences have _2, _3, etc. at the end.")
        
        # Display which names were changed
        for name, count in counts.items():
            if count > 1:
                st.write(f"'{name}' appears {count} times â†’ {name}, " + 
                        ", ".join([f"{name}_{i}" for i in range(2, count + 1)]))
    
    # Set new index
    df.index = new_indices
    return df

#March-1 Sept-1å¯¾å¿œ
def excel_autoconversion(dfx):
    p = re.compile(r'(\d+)\-(Mar|Sep)')
    index_name = dfx.index.values
    j = 0
    k = 0
    for i in df.index.values:
        x = p.match(i)
        if x:
            if k == 0:
                st.write("There are Excel-autoconverted gene names")
                k = 1
            autoconvert_flag = True
            st.write("Converting " + i)
            if x.group(2) == "Mar":
                index_name[j] = "March" + x.group(1)
            elif x.group(2) == "Sep":
                index_name[j] = "Sept" + x.group(1)
        j += 1
    dfx.index = index_name
    return(dfx)


def check_excel_autoconversion(dfx):
    p = re.compile(r'(\d+)\-(Mar|Sep|Oct|Dec|Feb|Nov)')
    index_name = dfx.index.values
    j = 0
    k = 0
    for i in df.index.values:
        x = p.match(i)
        if x:
            if k == 0:
                st.markdown("#### There are Excel-autoconverted gene names")
                st.write("Gene names are not converted.")
                k = 1
            autoconvert_flag = True
            st.write(i)
#    return(dfx)

r = pyper.R(use_pandas=True)
f = ro.r("source('pages/deseq2_func.R')") # full pathãŒå¿…è¦

st.set_page_config(page_title="Calculate DESeq2.", page_icon="ğŸ“ƒ")


@st.cache_data
def convert_df(df):
   return df.to_csv(index=True, sep='\t').encode('utf-8')

@st.cache_data
def read_excel(file, index_col=None, header = 0):
    df_xl = pd.read_excel(file, index_col = index_col, header = header)
    return df_xl

@st.cache_data
def read_csv(file, index_col=None, sep=','):
    df_c = pd.read_csv(file, index_col = index_col, header = 0, sep = sep, engine='python')
    return df_c



@st.cache_data
def calc_barplot(data, ylabel):
    fig, ax = plt.subplots()
    ax = sns.barplot(data=data)
    ax.set_xticklabels(ax.get_xticklabels(),rotation = 90)
    ax.set_ylabel(ylabel, fontsize = 14)
    return fig

st.markdown("### DESeq2, limma eBayes, beta regression, GLM")
st.sidebar.title("Options")
st.markdown("#### Options are displayed at the bottom of the left side panel")
with st.sidebar:
    st.markdown("### Analysis Method:")
    test_method = st.radio("Select analysis method:", 
                         ["DESeq2", "limma eBayes", "Beta Regression", 
                          "Generalized Linear Model (GLM)"], 
                         index=0)
    
    st.markdown("###### limma eBayes with logit transformation, beta regression and GLM with beta regression are for proportion data.")

# tempå†…ã«ä¿å­˜ã™ã‚‹
# --- Initialising SessionState ---
if "temp_dir" not in st.session_state:
    st.session_state.temp_dir = True
    #å¤ã„direcotryã¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã™ã‚‹
    temp_dir = "temp/" + str(round(time.time()))
    if not os.path.exists('temp'):
        os.mkdir('temp')
    else:
        clear_old_directories("temp")
        clear_old_files("temp")
        if not os.path.exists(temp_dir):
            os.mkdir(temp_dir)
    st.session_state.temp_dir = temp_dir
    res_dir = temp_dir + '/res'
    st.session_state.res_dir = res_dir
    if not os.path.exists(res_dir):
        os.mkdir(res_dir)

else:
    temp_dir = st.session_state.temp_dir
    res_dir = temp_dir + '/res'
    st.session_state.res_dir = res_dir
    if not os.path.exists(temp_dir):
        os.mkdir(temp_dir)
        os.mkdir(res_dir)
    if not os.path.exists(res_dir):
        os.mkdir(res_dir)


st.markdown("### DESeq2ã«ã¯raw count dataã‚’ä½¿ã†")

use_sf = False # size factorã®ä½¿ç”¨

use_upload = 'Yes'
if 'df' in st.session_state:
    st.write("Available data")
    st.write(st.session_state.df.head())
    if st.session_state.df is not None:
        use_upload = st.radio("Upload new file?", ('Yes','No'), index = 1)
    if use_upload == "No":
        df = st.session_state.df
        input_file_type = 'tsv'
        file_name_head = st.session_state.uploaded_file_name
        # Homerå¯¾å¿œ
        if "Transcript/RepeatID" in df.columns[0]:
            df = df.iloc[:,8:]
            st.write(df.head())
        if "Row_name" in df.columns.to_list(): # Row_nameã‚’å«ã‚€ã¨ã
            df = df.set_index('Row_name')
            df.index.name = "Gene"

uploaded_size_factors = None
if "use_custom_size_factors" not in st.session_state:
    st.session_state.use_custom_size_factors = False

if use_upload == 'Yes':
    st.markdown("##### Data format:")
    file_type = st.radio(
        "",    ('auto', 'Homer','tsv','csv','excel'), index = 0, label_visibility = 'collapsed')
    uploaded_file = st.file_uploader("Choose a file", type=['txt','tsv', 'csv', 'xls','xlsx'])
    use_sf = st.checkbox('Upload Size Factors (Optional)')
    if use_sf:
        uploaded_size_factors = st.file_uploader("Choose a size factors file (TSV format)", type=['tsv'])

    if uploaded_file is not None:

        if file_type == 'auto':
            try:
                df = read_csv(uploaded_file, sep = None)
                st.write("Uploaded file:")
                st.write(df.head())

                content = df.columns.tolist()
#                Gene_column = content[0]

                if "Annotation/Divergence" in content:
                     # colnamesã®å¤‰æ›
                    search_word = '([^\ \(]*)\ \(.*'

                    for i in range(1, len(content)):
                        match = re.search(search_word, content[i])
                        if match:
                            content[i] = match.group(1).replace(' ', '_')
                    df.columns = content # ä¸€æ—¦åå‰ã‚’å¤‰æ›´
                    df['Annotation/Divergence'] = df['Annotation/Divergence'].astype(str) # excel å¯¾å¿œ
                    pattern = "([^|]*)"
                    repatter = re.compile(pattern)
                    f_annotation = lambda x: repatter.match(x).group(1)
                    df.loc[:,'Annotation/Divergence'] = df.loc[:,'Annotation/Divergence'].apply(f_annotation)
                  #  st.write(df.head())
                    # annotation/divergenceä»¥å‰ã‚’é™¤ã
                    df = df.loc[:,'Annotation/Divergence':]
                  #  st.write(df.head())
                    st.write("Converted Annotation/Divergence to gene symbols.")
                content = df.columns.tolist()
                content[0] = 'Gene'
                df.columns = content

         #       df.set_index("Gene", inplace = True)

            except:# excel
                df = read_excel(uploaded_file)
                content = df.columns.tolist()
                if "Annotation/Divergence" in content:
                     # colnamesã®å¤‰æ›
                    search_word = '([^\ \(]*)\ \(.*'

                    for i in range(1, len(content)):
                        match = re.search(search_word, content[i])
                        if match:
                            content[i] = match.group(1).replace(' ', '_')
                    df.columns = content # ä¸€æ—¦åå‰ã‚’å¤‰æ›´
                    df['Annotation/Divergence'] = df['Annotation/Divergence'].astype(str) # excel å¯¾å¿œ
                    pattern = "([^|]*)"
                    repatter = re.compile(pattern)
                    f_annotation = lambda x: repatter.match(x).group(1)
                    df.loc[:,'Annotation/Divergence'] = df.loc[:,'Annotation/Divergence'].apply(f_annotation)
                    # annotation/divergenceä»¥å‰ã‚’é™¤ã
                    df = df.loc[:,'Annotation/Divergence':]
                    content = df.columns.tolist()
                    content[0] = 'Gene'
                    df.columns = content
                    st.write("Converted Annotation/Divergence to gene symbols.")
                else:
                    colnames = df.columns.tolist()
                    colnames[0] = 'Gene'
                    df.columns = colnames

        elif file_type != 'excel':
            if file_type == 'csv':
                df = read_csv(uploaded_file)
            else:
                df = read_csv(uploaded_file, sep = '\t')
            st.write("Original:")
            st.write(df.head())
            if file_type == 'Homer':
                df = df.iloc[:,7:]
                colnames = df.columns.tolist()
                colnames[0] = 'Gene'
                # colnamesã®å¤‰æ›
                search_word = '([^\ \(]*)\ \(.*'
                for i in range(1, len(colnames)):
                    match = re.search(search_word, colnames[i])
                    if match:
                        colnames[i] = match.group(1).replace(' ', '_')
                pattern = "([^|]*)"
                repatter = re.compile(pattern)
                f_annotation = lambda x: repatter.match(x).group(1)
                try:
                    df.iloc[:,0] = df.iloc[:,0].apply(f_annotation)
                    df.columns = colnames
                except:
                    st.markdown("### File format error. Non-Homer file?")

            else:
                colnames = df.columns.tolist()
                colnames[0] = 'Gene'
                df.columns = colnames
        else: # excel
            df = read_excel(uploaded_file)
            content = df.columns.tolist()
            if "Annotation/Divergence" in content:
                 # colnamesã®å¤‰æ›
                search_word = '([^\ \(]*)\ \(.*'

                for i in range(1, len(content)):
                    match = re.search(search_word, content[i])
                    if match:
                        content[i] = match.group(1).replace(' ', '_')
                df.columns = content # ä¸€æ—¦åå‰ã‚’å¤‰æ›´
                df['Annotation/Divergence'] = df['Annotation/Divergence'].astype(str) # excel å¯¾å¿œ
                pattern = "([^|]*)"
                repatter = re.compile(pattern)
                f_annotation = lambda x: repatter.match(x).group(1)
                df.loc[:,'Annotation/Divergence'] = df.loc[:,'Annotation/Divergence'].apply(f_annotation)
                # annotation/divergenceä»¥å‰ã‚’é™¤ã
                df = df.loc[:,'Annotation/Divergence':]
                content = df.columns.tolist()
                content[0] = 'Gene'
                df.columns = content
                st.write("Converted Annotation/Divergence to gene symbols.")
            else:
                colnames = df.columns.tolist()
                colnames[0] = 'Gene'
                df.columns = colnames

        df = df.set_index('Gene')
        file_name_head = os.path.splitext(uploaded_file.name)[0]

    else:
        sys.exit(1)

if df is not None:
    st.write('Original gene number:  ' + str(len(df)))
    st.write(df.head())

    # floatã«å¤‰æ› èª¤å°„æ‚Ÿå…¥
    df = df.astype(float)

    if test_method == "DESeq2": # DESeq2ã®ã¨ãã ã‘æ•´æ•°åŒ–
        if not float.is_integer(df.iloc[:,0].sum()*1000):
            st.markdown("# It is likely that your data are normalized. Please upload unnormalized raw count data.")

        df = df.round(0)

    df = df.loc[~(df==0).all(axis=1)] #ã™ã¹ã¦0ã®rowã‚’é™¤ã

########## excelå¯¾å¿œ?
    st.write("All zero count genes are removed.")
    if df.isnull().values.sum() > 0:
        st.write("There are " + str(df.isnull().values.sum()) + " NaN in :")
        st.write(df[df.isnull().any(axis=1)])
        convert_nan = st.radio( "NaN:",
        ('remove Nan containing genes', 'conver to 0' ), key='remove Nan containing genes')
        if convert_nan == "conver to 0":
            df = df.fillna(0)
        else:
            df = df.dropna(how='any')
############
    check_excel_autoconversion(df)


    if len(df.index.values) != len(set(df.index.values)):
#        st.markdown("#### There are duplicated rows. Converting the names...")
#        st.write("The gene name of the second occurrence has _2 at the end.")
#        lis = df.index.values
#        df.index = [x + ['', '_2'][x in lis[0:i]] for i, x in enumerate(lis)]
        df = rename_duplicates(df)
    # ã“ã“ã«æ–°ã—ã„å‡¦ç†ã‚’è¿½åŠ 
    df, column_name_mapping, original_column_names = clean_column_names_for_r(df)

    # å¤‰æ›ãŒã‚ã£ãŸå ´åˆã¯è­¦å‘Šã‚’è¡¨ç¤º
    if column_name_mapping:
        st.warning("âš ï¸ Special characters in sample names have been converted for R compatibility:")
        for orig, clean in column_name_mapping.items():
            st.write(f"  â€¢ '{orig}' â†’ '{clean}'")

    st.write(df.head())
    total_count = pd.DataFrame(df.sum()[1:])
    total_count.columns= ['Total counts']
    large_var = False
    if max(total_count['Total counts']) > min(total_count['Total counts']) * 2:
        large_var = True
        st.markdown("### Large difference (>2x) in counts")
        st.write(f"Minimum total counts: {min(total_count['Total counts'])}")
        st.markdown("##### Low count samples can be filtered on the side panel.")
        import matplotlib.pyplot as plt
        import seaborn as sns
        df_sum = pd.DataFrame(df.sum())
        df_sum.columns = ['Counts']


        f1 = calc_barplot(df_sum.T, ylabel = "Total counts")
        st.pyplot(f1)

        f2 = calc_barplot(np.log1p(df), ylabel = "ln(x+1)")
        st.pyplot(f2)

    with st.sidebar:
        # DESeq2ã®æ—¢å­˜ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        if test_method == 'DESeq2':
            st.markdown("##### FC adjustment method:")
            type = st.radio("", ('ashr','apeglm', 'normal'), label_visibility="collapsed")
            st.write('DESeq2ã®defaultã¯apeglmã€‚apeglmã§ã¯reference groupã‚’æŒ‡å®šã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚')

            st.markdown("##### FDR cutoff for independent filtering:")
            results_alpha = st.number_input("alpha", value = 0.05, max_value=0.20, min_value=0.00, label_visibility = 'collapsed')
            st.write("alpha in results func")  

            st.markdown("##### Batch correction:")
            sva = st.checkbox('SVA batch removal?')
            sva_calc = True
            if sva:
                sva_calc = st.checkbox('Calculate only 2 surrogate variables? Deselect if want to calculate up to the recommended number.', value = True)
                st.markdown("---")

            ruv = st.checkbox('RUV batch removal?')

            if ruv:
                RUV_alpha = st.number_input('P values threshold for control genes in RUV', min_value=0.0, max_value = 0.5, step = 0.05, value=0.2)
            else:
                RUV_alpha = 0.2

        # limma eBayesã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        elif test_method == 'limma eBayes':
            limma_data = st.radio("Data type:",
                ["RNA-seq count", "Non-count data", "0-1 data (proportion, AUC etc) to logit transformation"],
                index=1)

            if limma_data == "RNA-seq count":
                apply_logit = False
                limma_count = True
                default_trend = True  # RNA-seq countã®å ´åˆã¯trendã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§TRUE
            elif limma_data == "Non-count data":
                apply_logit = False
                limma_count = False
                default_trend = False  # Non-count dataã®å ´åˆã¯trendã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§FALSE
            else:
                apply_logit = True
                limma_count = False
                default_trend = False  # 0-1 dataã®å ´åˆã¯trendã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§FALSE
            
            # trend and robust options
            st.markdown("##### Advanced eBayes options:")
            limma_trend = st.checkbox("Use trend", value=default_trend)
            limma_robust = st.checkbox("Use robust", value=True)
            
            with st.expander("â„¹ï¸ About trend and robust options"):
                st.markdown("""
                **trend option:**
                - åˆ†æ•£ã¨å¹³å‡ç™ºç¾é‡ã®é–¢ä¿‚ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã—ã¾ã™
                - ä½ç™ºç¾éºä¼å­ã¨é«˜ç™ºç¾éºä¼å­ã§åˆ†æ•£ãŒç•°ãªã‚‹å ´åˆã«æœ‰åŠ¹
                - RNA-seqãƒ‡ãƒ¼ã‚¿ã§ã€voomã‚„logå¤‰æ›å¾Œã®ãƒ‡ãƒ¼ã‚¿ã«æ¨å¥¨
                - ã™ã¹ã¦ã®éºä¼å­ã§ä¸€å®šã®åˆ†æ•£ã‚’ä»®å®šã›ãšã€ã‚ˆã‚ŠæŸ”è»Ÿãªãƒ¢ãƒ‡ãƒ«ã‚’é©ç”¨
                
                **robust option:**
                - å¤–ã‚Œå€¤ã«å¯¾ã—ã¦ãƒ­ãƒã‚¹ãƒˆãªæ¨å®šã‚’è¡Œã„ã¾ã™
                - ãƒ™ã‚¤ã‚ºæ¨å®šã§å¤–ã‚Œå€¤ã®å½±éŸ¿ã‚’è»½æ¸›
                - ãƒ‡ãƒ¼ã‚¿ã«ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚„å¤–ã‚Œå€¤ãŒå«ã¾ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹å ´åˆã«æ¨å¥¨
                - è¨ˆç®—æ™‚é–“ã¯å°‘ã—é•·ããªã‚Šã¾ã™ãŒã€ã‚ˆã‚Šå®‰å®šã—ãŸçµæœã‚’å¾—ã‚‰ã‚Œã¾ã™
                
                **æ¨å¥¨ã•ã‚Œã‚‹ä½¿ç”¨ä¾‹:**
                - RNA-seqã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿: trend=TRUE, robust=TRUE
                - éã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆãƒã‚¤ã‚¯ãƒ­ã‚¢ãƒ¬ã‚¤ç­‰ï¼‰: trend=FALSE, robust=TRUE
                - 0-1ãƒ‡ãƒ¼ã‚¿ï¼ˆæ¯”ç‡ãƒ‡ãƒ¼ã‚¿ï¼‰: trend=FALSE, robust=TRUE
                - ãã‚Œã„ãªæ­£è¦åŒ–æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿: ä¸¡æ–¹FALSEï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
                
                **ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—åˆ¥ã®æ¨å¥¨è¨­å®šï¼š**
                - **"RNA-seq count"**: trend=TRUE, robust=TRUE (è‡ªå‹•è¨­å®š)
                  - ã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã¯å¹³å‡-åˆ†æ•£é–¢ä¿‚ãŒã‚ã‚Šã€å¤–ã‚Œå€¤ã‚‚å­˜åœ¨ã™ã‚‹å¯èƒ½æ€§ãŒé«˜ã„
                - **"Non-count data"**: trend=FALSE, robust=TRUE (è‡ªå‹•è¨­å®š)
                  - æ­£è¦åŒ–æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã¯å¹³å‡-åˆ†æ•£é–¢ä¿‚ãŒå®‰å®šåŒ–æ¸ˆã¿
                  - å¤–ã‚Œå€¤ã«å¯¾ã™ã‚‹ãƒ­ãƒã‚¹ãƒˆæ€§ã¯ä¾ç„¶ã¨ã—ã¦æœ‰ç”¨
                - **"0-1 data"**: trend=FALSE, robust=TRUE (è‡ªå‹•è¨­å®š)
                  - æ¯”ç‡ãƒ‡ãƒ¼ã‚¿ã¯å¤‰æ›æ¸ˆã¿ã§å¹³å‡-åˆ†æ•£é–¢ä¿‚ã¯å®‰å®š
                  - ãƒ­ãƒã‚¹ãƒˆæ¨å®šã§å¤–ã‚Œå€¤ã®å½±éŸ¿ã‚’è»½æ¸›
                
                **æ³¨æ„ï¼š** 
                - trendã¨robustã®åˆæœŸå€¤ã¯ã€é¸æŠã—ãŸãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã«åŸºã¥ã„ã¦è‡ªå‹•è¨­å®šã•ã‚Œã¾ã™
                - robustã‚ªãƒ—ã‚·ãƒ§ãƒ³ã¯å¸¸ã«TRUEãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã™ï¼ˆã‚ˆã‚Šå®‰å®šã—ãŸçµæœï¼‰
                - å¿…è¦ã«å¿œã˜ã¦æ‰‹å‹•ã§è¨­å®šã‚’å¤‰æ›´ã§ãã¾ã™
                """)

        # Beta Regressionã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        elif test_method == 'Beta Regression':
            st.markdown("### Beta Regression Options:")
            epsilon = st.number_input("Epsilon for boundary adjustment (0-1 data)", 
                                    min_value=0.0000001, max_value=0.01, value=0.000001, format="%.7f")
            st.markdown("#### Batch correction:")
            use_batch = st.checkbox('Include batch effect?', value=False)
            n_cores = st.slider("Parallel cores", min_value=1, 
                               max_value=os.cpu_count()-1, 
                               value=max(1, os.cpu_count()//2-4))

        # GAMã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        elif test_method == 'Generalized Linear Model (GLM)':
            st.markdown("### GLM Options:")
            dist_family = st.radio("Probability distribution", 
                                  ["Beta (0-1)", "Gaussian", "Poisson", "Negative Binomial"],
                                  index=0)


            with st.expander("Explain models"):
                st.markdown("""
GLMã‚’mgcvãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®gam()é–¢æ•°ã§å®Ÿè£…

1. Betaåˆ†å¸ƒ (Beta Distribution)
é©ç”¨ãƒ‡ãƒ¼ã‚¿ï¼š0ã¨1ã®é–“ã®å€¤ï¼ˆæ­£è¦åŒ–ç™ºç¾é‡ã€æ¯”ç‡ãƒ‡ãƒ¼ã‚¿ï¼‰  
ãƒªãƒ³ã‚¯é–¢æ•°ï¼šé€šå¸¸ãƒ­ã‚¸ãƒƒãƒˆãƒªãƒ³ã‚¯ï¼ˆlogitï¼‰ã‚’ä½¿ç”¨  
æ¨å®šï¼šæœ€å°¤æ³•ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¨å®šï¼ˆBetaåˆ†å¸ƒã®å½¢çŠ¶ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿Î±ã€Î²ï¼‰  
æ¤œå®šï¼šæ¡ä»¶ã®ä¿‚æ•°ã«ã¤ã„ã¦ã®Waldæ¤œå®šï¼ˆä¿‚æ•°/æ¨™æº–èª¤å·®ï¼‰ã‚’å®Ÿæ–½  
å¤šé‡æ¤œå®šè£œæ­£ï¼šBenjamini-Hochbergæ³•ã§FDRã‚’åˆ¶å¾¡  
Betaå›å¸°ã¨GAM-Betaå®Ÿè£…ã¯æœ¬è³ªçš„ã«åŒã˜ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ   
batchã‚’å«ã¾ãªã„å ´åˆã¯æœ¬è³ªçš„ã«ã¯ã€Œ0-1ãƒ‡ãƒ¼ã‚¿ã«é©å¿œã—ãŸANOVAã€

2. ã‚¬ã‚¦ã‚¹åˆ†å¸ƒ (Gaussian Distribution)  
é©ç”¨ãƒ‡ãƒ¼ã‚¿ï¼šé€£ç¶šå€¤ã§æ­£è¦åˆ†å¸ƒã«å¾“ã†ãƒ‡ãƒ¼ã‚¿ï¼ˆæ­£è¦åŒ–æ¸ˆã¿ã®ãƒ­ã‚°ã‚«ã‚¦ãƒ³ãƒˆãªã©ï¼‰  
ãƒªãƒ³ã‚¯é–¢æ•°ï¼šæ’ç­‰ãƒªãƒ³ã‚¯ï¼ˆidentityï¼‰  
æ¨å®šï¼šæœ€å°äºŒä¹—æ³•ï¼ˆã¾ãŸã¯æœ€å°¤æ³•ï¼‰ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¨å®š  
æ¤œå®šï¼štæ¤œå®šã«åŸºã¥ã„ã¦ã‚°ãƒ«ãƒ¼ãƒ—é–“ã®å·®ã‚’è©•ä¾¡  
å¤šé‡æ¤œå®šè£œæ­£ï¼šBenjamini-Hochbergæ³•ã§FDRåˆ¶å¾¡  
æ¨™æº–çš„ãªç·šå½¢ãƒ¢ãƒ‡ãƒ«ï¼ˆANOVAçš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼‰  
batchã‚’å«ã¾ãªã„å ´åˆã¯æ¨™æº–çš„ãªANOVAã¨ä¸€è‡´ï¼ˆFæ¤œå®šã«ã‚ˆã‚‹ã‚°ãƒ«ãƒ¼ãƒ—é–“å·®ç•°ã®è©•ä¾¡ï¼‰

3. ãƒã‚¢ã‚½ãƒ³åˆ†å¸ƒ (Poisson Distribution)  
é©ç”¨ãƒ‡ãƒ¼ã‚¿ï¼šå˜ç´”ãªã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆéåˆ†æ•£ãŒãªã„å ´åˆï¼‰  
ãƒªãƒ³ã‚¯é–¢æ•°ï¼šå¯¾æ•°ãƒªãƒ³ã‚¯ï¼ˆlogï¼‰  
æ¨å®šï¼šæœ€å°¤æ³•ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¨å®šï¼ˆÎ»ï¼šå¹³å‡=åˆ†æ•£ï¼‰  
æ¤œå®šï¼šå°¤åº¦æ¯”æ¤œå®šã¾ãŸã¯ Waldæ¤œå®š  
å¤šé‡æ¤œå®šè£œæ­£ï¼šBenjamini-Hochbergæ³•ã§FDRåˆ¶å¾¡  

4. è² ã®äºŒé …åˆ†å¸ƒ (Negative Binomial Distribution)  
é©ç”¨ãƒ‡ãƒ¼ã‚¿ï¼šéåˆ†æ•£ã®ã‚ã‚‹ã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆRNA-seqãƒ‡ãƒ¼ã‚¿ãªã©ï¼‰  
ãƒªãƒ³ã‚¯é–¢æ•°ï¼šå¯¾æ•°ãƒªãƒ³ã‚¯ï¼ˆlogï¼‰  
æ¨å®šï¼šæœ€å°¤æ³•ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¨å®šï¼ˆÎ¼ï¼šå¹³å‡ã€Î¸ï¼šéåˆ†æ•£ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰  
éåˆ†æ•£æ¨å®šï¼šéºä¼å­ã”ã¨ã®åˆ†æ•£ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ï¼ˆDESeq2ã¨é¡ä¼¼ï¼‰  
æ¤œå®šï¼šå°¤åº¦æ¯”æ¤œå®šã¾ãŸã¯ Waldæ¤œå®š  
å¤šé‡æ¤œå®šè£œæ­£ï¼šBenjamini-Hochbergæ³•ã§FDRåˆ¶å¾¡  
ãƒã‚¢ã‚½ãƒ³åˆ†å¸ƒã®æ‹¡å¼µã§ã€variance > mean ã‚’è¨±å®¹
                """)

            if dist_family == "Beta (0-1)":
                dist_short = "beta"
                epsilon = st.number_input("Epsilon for boundary adjustment", 
                                       min_value=0.0000001, max_value=0.01, value=0.000001, format="%.7f")
            elif dist_family == "Gaussian":
                dist_short = "gaussian"
            elif dist_family == "Poisson":
                dist_short = "poisson"
            elif dist_family == "Negative Binomial":
                dist_short = "nb"
                nb_theta = st.number_input("éåˆ†æ•£ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (theta)", 
                                         min_value=0.1, max_value=100.0, value=10.0)

            st.markdown("#### Batch correction:")
            use_batch = st.checkbox('Include batch effect?', value=False)
            n_cores = st.slider("Parallel cores", min_value=1, 
                               max_value=os.cpu_count()-1, 
                               value=max(1, os.cpu_count()//2-4))

        # å…±é€šã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        independentFiltering = True  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
        if test_method == 'DESeq2' or (test_method == 'limma eBayes' and limma_count):
            st.markdown("#### Filter out weakly-expressed genes before multiple test correction:",help = "independentFiltering default:TRUE å¹³å‡æ­£è¦åŒ–ã‚«ã‚¦ãƒ³ãƒˆã«åŸºã¥ã„ã¦éºä¼å­ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã€å¤šé‡æ¤œå®šè£œæ­£ã®è² æ‹…ã‚’æ¸›ã‚‰ã™ã“ã¨ã§çµ±è¨ˆçš„æ¤œå‡ºåŠ›ã‚’å‘ä¸Šã•ã›ã‚‹")
            independentFiltering = st.checkbox('Yes', value=True)

        st.markdown("#### Additional filtering:")
        st.markdown("##### Filter the genes > counts in all samples:")
        min_threshold = st.number_input("count minimum", value=0, label_visibility='collapsed')
        min_threshold = int(min_threshold)
        
        st.markdown("##### Filter the genes > counts in at least one sample:")
        max_threshold = st.number_input("count max", value=0, label_visibility='collapsed')
        max_threshold = int(max_threshold)

        sample_threshold = 0
        remove_zero_samples = False

        if large_var:
            st.markdown("##### Filter the samples <= counts:")
            sample_threshold = st.number_input("Minimum total cout", value = 0, label_visibility = 'collapsed')

        # DESeq2ä»¥å¤–ã®å ´åˆã€ã‚¼ãƒ­ã‚«ã‚¦ãƒ³ãƒˆã‚µãƒ³ãƒ—ãƒ«é™¤å»ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¡¨ç¤º
        if test_method != 'DESeq2':
            st.markdown("##### Remove samples with zero counts:")
            remove_zero_samples = st.checkbox("Remove samples with total count = 0", value=False)
        else:
            # DESeq2ã®å ´åˆã¯å¸¸ã«é™¤å»
            remove_zero_samples = True

        st.markdown("##### Output style:")
        deseq2_flag = st.radio( "Homer: positive in A vs B means up in B; DESeq2: positive in A vs B means up in A", ('Homer','DESeq2'), index = 1)
        if deseq2_flag =='DESeq2':
            deseq2 = True
        else:
            deseq2 = False

    # DESeq2ã®å ´åˆã€ã¾ãŸã¯æ˜ç¤ºçš„ã«æŒ‡å®šã•ã‚ŒãŸå ´åˆã«ã‚¼ãƒ­ã‚«ã‚¦ãƒ³ãƒˆã‚µãƒ³ãƒ—ãƒ«ã‚’é™¤å»
    if test_method == 'DESeq2' or remove_zero_samples:
        if any(df.sum() <= sample_threshold): # count 0ã®åˆ—ã‚’é™¤ã
            st.markdown('#### There are the samples that have counts <= ' + str(sample_threshold))
            st.write(", ".join(df.columns[df.sum() <= sample_threshold].to_list()))
            st.markdown('##### They are removed. Now data are:')
            df = df.drop(df.columns[df.sum() <= sample_threshold].to_list(), axis = 1)
            st.write(df.head())

    if min_threshold > 0:
        df = df[df.apply(min, axis=1) > min_threshold]
    if max_threshold > 0:
        df = df[df.apply(max, axis=1) > max_threshold]

    st.markdown(f'#### Filtered gene number: {str(len(df))}')

    condition = [str(i) for i in df.columns.tolist()] #erroré˜²æ­¢
    group_condition = remove_common_suffix(condition) #æœ«å°¾ã®å…±é€šè¦ç´ ã‚’é™¤ã
#    group_condition = [remove_after_space(x) for x in condition] #ã‚¹ãƒšãƒ¼ã‚¹ä»¥é™ã‚’é™¤ã
    group_condition = [remove_sample_num(x) for x in group_condition] #æœ«å°¾ã®æ•°å­—ã¨_ã‚’é™¤ã
    group_condition = [x.rstrip('.') for x in group_condition] # .ã‚’é™¤ã


    df_e = pd.DataFrame(group_condition, index = condition, columns = ["Group"])
    df_b = pd.DataFrame(condition, index =condition, columns = ["Batch"])

    batch_in = st.checkbox('Setting batch?')
    with st.form("input_groups and batch"):
        st.write('Set groups:')
    #    edited_df_e = st.experimental_data_editor(df_e)
        edited_df_e = st.data_editor(df_e)

        condition = edited_df_e.iloc[:,0].tolist()
        
        if batch_in:
            st.write('Set batch:')
    #        edited_df_b = st.experimental_data_editor(df_b)
            edited_df_b = st.data_editor(df_b)

        if batch_in:
            batch = edited_df_b.iloc[:,0].tolist()
            st.write('Batch: ' + '  '.join(batch))
        else:
            batch = ["No batch"] #batchãŒãªã„ã¨ã

        submitted = st.form_submit_button("Submit")
    st.write('Group: ' + ' '.join(condition))

    if (len(condition) != len(df.columns)):
            st.write("The number of group name does not match the data.")

#    df_condition = pd.DataFrame(condition)
#    df_batch = pd.DataFrame(batch)

    ref_in = st.checkbox('Setting referece group?')
    if ref_in or (type == 'apeglm'):
        st.markdown("##### Select a group used as the referece:")
        ref_group = st.selectbox("", set(condition), label_visibility="collapsed")
    else:
        ref_group = condition[0]

    rld_calc = st.checkbox('Calculate rlog?', value = False )

    for i in df.columns.values:
        a = df.select_dtypes(exclude='number')
        if not a.empty:
            st.write("There is a non-nemeric value in ")
            st.write(a)

#    df = excel_autoconversion(df) # 1-Marãªã©ã®èª¤å¤‰æ›ã¸ã®å¯¾å¿œ


    st.markdown("---")
    # ã‚µã‚¤ã‚ºãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ã®è¨­å®šã¨ç¢ºèª
    if use_sf and uploaded_size_factors is not None:
        size_factors_df = pd.read_csv(uploaded_size_factors, sep='\t', index_col=0)
        st.write("Uploaded size factors file:")
        st.write(size_factors_df.head())

        selected_column = st.selectbox("Select the column containing size factors:", size_factors_df.columns)

        if st.button("Confirm size factors"):
            if size_factors_df.index.tolist() == df.columns.tolist():
                size_factors = size_factors_df[selected_column]
                with localconverter(ro.default_converter + pandas2ri.converter):
                    ro.r.assign('custom_size_factors', ro.FloatVector(size_factors.values))
                ro.r('use_custom_size_factors <- TRUE')
                st.success(f"Size factors from column '{selected_column}' will be used in the analysis.")
                st.session_state.use_custom_size_factors = True

                # Rå¤‰æ•°ã®å†…å®¹ã‚’ç¢ºèª
                display_r_variable("use_custom_size_factors")
                display_r_variable("custom_size_factors")
            else:
                st.error("The row names in the size factors file do not match the column names in the count data. Please check your file.")
                ro.r('use_custom_size_factors <- FALSE')
                ro.r('custom_size_factors <- NULL')
                st.session_state.use_custom_size_factors = False
        st.markdown("---")
    else:
        ro.r('use_custom_size_factors <- FALSE')
        ro.r('custom_size_factors <- NULL')
        st.session_state.use_custom_size_factors = False



    # ã€ŒRun DESeq2ã€ãƒœã‚¿ãƒ³ã‚’ã€ŒRun Analysisã€ã«å¤‰æ›´
    if st.button('Run Analysis'):
        # å…±é€šã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        try:
            r.assign('df', df)
            pyper_df_path = "saveRDS(df, '" + temp_dir + "/pyper_df.RDS')"
            r(pyper_df_path)
            read_pyper_df = "cts <- readRDS('" + temp_dir + "/pyper_df.RDS')"
            ro.r(read_pyper_df)
            
            r_condition = ro.StrVector(condition)
            ro.r.assign('condition', r_condition)
            r_batch = ro.StrVector(batch)
            ro.r.assign('batch', r_batch)
            ro.r.assign('ref_in', ref_in)
            ro.r.assign('ref_group', ref_group)
            ro.r.assign('independentFiltering', independentFiltering)
            ro.r.assign('deseq2', deseq2)
            ro.r.assign('res_dir', res_dir)
            ro.r.assign('temp_dir', temp_dir)
            
            ro.r("make_coldata()")
            
        except Exception as e:
            st.markdown(f"## Error: {str(e)}")
            st.markdown("## rpy2 error. Reinstall: pip install rpy2==3.5.1")
            sys.exit(1)

        # ãƒ¡ã‚½ãƒƒãƒ‰å›ºæœ‰ã®å®Ÿè¡Œãƒ­ã‚¸ãƒƒã‚¯
        if test_method == 'DESeq2':
            # æ—¢å­˜ã®DESeq2ã‚³ãƒ¼ãƒ‰
            ro.r.assign('sva', sva)
            ro.r.assign('ruv', ruv)
            ro.r.assign('RUV.alpha', RUV_alpha)
            ro.r.assign('type', type)
            ro.r.assign('sva_calc', sva_calc)
            ro.r.assign('rld_calc', rld_calc)
            ro.r.assign('results_alpha', results_alpha)
            
            with st.spinner('Calculating DESeq2...'):
                if batch == ['No batch']:
                    ro.r('calc_dds_nobatch()')
                else:
                    ro.r('calc_dds_batch()')
                py_res = ro.r('calc_deseq()')
            
            image = Image.open(res_dir + '/DispersionEstimates.png')
            st.image(image, caption='Despersion Estimates')
            
            with open(res_dir + '/DESeq2_output.txt') as f:
                out = f.readlines()
                for i in out:
                    if ("NULL" not in i) and ("results" not in i):
                        st.write(i)
            
            res_df = pd.read_csv(res_dir + '/DESeq2_res.tsv', sep='\t', index_col=0)
            res_df = res_df.fillna(1)
            st.dataframe(res_df)
            
            if sva:
                st.markdown("#### =======SVA=======")
                try:
                    with st.spinner('Preparing SVAseq...'):
                        sva_n = ro.r("sv_n <- calc_sva_n()")
                    st.write("Recommended number of SVA covariates: " + str(int(sva_n[0])))
                except:
                    pass

                                # ä¸¡æ–¹ã®æ–¹æ³•ã§è¨ˆç®—
                ro.r("sv_both <- calc_sva_n_both()")
                
                # çµæœã‚’å–å¾—
                sv_be = int(ro.r("svn_be")[0])
                sv_leek_result = ro.r("svn_leek")
                
                # Leekæ³•ã®çµæœç¢ºèªï¼ˆNAã®å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ï¼‰
                if sv_leek_result[0] != ro.NA_Logical:
                    sv_leek = int(sv_leek_result[0])
                else:
                    sv_leek = None
            
                # çµæœã‚’è¡¨ç¤º
                col1, col2 = st.columns(2)
                
                with col1:
                    st.metric(
                        "BE method (default)", 
                        sv_be,
                        help="Buja-Eyuboglu method - tends to estimate more factors"
                    )
                    
                with col2:
                    if sv_leek is not None:
                        st.metric(
                            "Leek method", 
                            sv_leek,
                            help="More conservative estimation"
                        )
                    else:
                        st.metric("Leek method", "Failed")
                        

                # è­¦å‘Šã‚„ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’è¡¨ç¤º
                if sv_leek is not None:
                    if sv_be > 10:
                        st.warning(f"""
                        âš ï¸ **High number of surrogate variables detected**
                        
                        - BE method suggests {sv_be} variables
                        - Leek method suggests {sv_leek} variables
                        
                        This may indicate:
                        - Strong batch effects in your data
                        - Potential overfitting risk
                        - Need for alternative approaches
                        """)
                        
                    if sv_be > sv_leek * 2:
                        st.info(f"""
                        ğŸ’¡ **Large discrepancy between methods**
                        
                        The BE estimate ({sv_be}) is more than twice the Leek estimate ({sv_leek}).
                        Consider:
                        1. Using the more conservative Leek estimate
                        2. Starting with fewer SVs and checking DEG retention
                        3. Investigating sample outliers
                        """)
                
                with st.spinner('Calculating SVAseq...'):
                    ro.r("calc_svseq()")
                
                with open(res_dir + '/SVA_output.txt') as f:
                    out = f.readlines()
                    for i in out:
                        if ("NULL" not in i)  and ("results" not in i):
                            st.write(i)
                
            if ruv:
                st.markdown("#### =======RUV=======")
                with st.spinner('Calculating RUVseq...'):
                    ro.r("calc_ruvseq()")
                
                with open(res_dir + '/RUVseq.txt') as f:
                    out = f.readlines()
                    for i in out:
                        if ("NULL" not in i)  and ("results" not in i):
                            st.write(i)
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ãƒ‡ãƒ¼ã‚¿ã‚’æ®‹ã™
            if sva:
                st.session_state.deseq2 = read_csv(res_dir + "/SVA_res.tsv", sep='\t', index_col=0)
            elif ruv:
                st.session_state.deseq2 = read_csv(res_dir + "/RUV_res.tsv", sep='\t', index_col=0)
            else:
                st.session_state.deseq2 = read_csv(res_dir + "/DESeq2_res.tsv", sep='\t', index_col=0)
            
            file_name = file_name_head + "_DESeq2"
        
        elif test_method == 'limma eBayes':
            # limma eBayesã®å®Ÿè¡Œãƒ­ã‚¸ãƒƒã‚¯
            ro.r.assign('limma_count', limma_count)
            ro.r.assign('apply_logit', apply_logit)
            ro.r.assign('limma_trend', limma_trend)
            ro.r.assign('limma_robust', limma_robust)
            
            with st.spinner('Calculating limma eBayes...'):
                ro.r('calc_limma()')
            
            if limma_count:
                try:
                    image = Image.open(res_dir + '/voom_plot.png')
                    st.image(image, caption='Voom Mean-Variance Trend')
                except:
                    st.write("Voom plot not available")
            res_df = pd.read_csv(res_dir + '/limma_res.tsv', sep='\t', index_col=0)
            res_df = res_df.fillna(1)
            # adj.pvalueã§çµ‚ã‚ã‚‹åˆ—ã‚’æ¤œç´¢ã—ã¦å„æ¯”è¼ƒã”ã¨ã«æœ‰æ„éºä¼å­æ•°ã‚’è¡¨ç¤º
            adj_pvalue_columns = [col for col in res_df.columns if '.adj.pvalue' in col]
            st.markdown("### Significant genes (FDR < 0.05):")
            total_significant = 0
            for col in adj_pvalue_columns:
                comparison = col.split('.adj.pvalue')[0]  # æ¯”è¼ƒåã‚’å–å¾—
                sig_count = (res_df[col] < 0.05).sum()
                total_significant += sig_count
                st.write(f"- {comparison}: {sig_count}")
            st.write(f"Total significant genes: {total_significant}")

            st.dataframe(res_df)
            
            st.session_state.deseq2 = res_df  # çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
            file_name = file_name_head + "_limma"
        
        elif test_method == 'Beta Regression':
            ro.r.assign('epsilon', epsilon)
            ro.r.assign('n_cores', n_cores)
            ro.r.assign('use_batch', use_batch)

            with st.spinner('Calculating Beta Regression...'):
                ro.r('calc_betareg()')

            # çµæœã®èª­ã¿è¾¼ã¿ã¨è¡¨ç¤º
            try:
                res_df = pd.read_csv(res_dir + '/betareg_res.tsv', sep='\t', index_col=0)
                res_df = res_df.fillna(1)
                
                # adj.pvalueã§çµ‚ã‚ã‚‹åˆ—ã‚’æ¤œç´¢ã—ã¦å„æ¯”è¼ƒã”ã¨ã«æœ‰æ„éºä¼å­æ•°ã‚’è¡¨ç¤º
                adj_pvalue_columns = [col for col in res_df.columns if '.adj.pvalue' in col]
                st.markdown("### Significant genes (FDR < 0.05):")
                total_significant = 0
                for col in adj_pvalue_columns:
                    comparison = col.split('.adj.pvalue')[0]  # æ¯”è¼ƒåã‚’å–å¾—
                    sig_count = (res_df[col] < 0.05).sum()
                    total_significant += sig_count
                    st.write(f"- {comparison}: {sig_count}")
                st.write(f"Total significant genes: {total_significant}")
                
                st.dataframe(res_df)
                
                st.session_state.deseq2 = res_df
            except Exception as e:
                st.error(f"Error processing Beta Regression results: {str(e)}")
                st.write("Check the R output for details.")

            file_name = file_name_head + "_betareg"
        
        elif test_method == 'Generalized Linear Model (GLM)':
            # GAMã®å®Ÿè¡Œãƒ­ã‚¸ãƒƒã‚¯
            ro.r.assign('dist_short', dist_short)
            ro.r.assign('use_batch', use_batch)
            ro.r.assign('n_cores', n_cores)
            
            if dist_short == "beta":
                ro.r.assign('epsilon', epsilon)
            elif dist_short == "nb":
                ro.r.assign('nb_theta', nb_theta)
            
            with st.spinner('Calculating GLM...'):
                ro.r('calc_gam()')
            
            # GAMã®å ´åˆ
            res_df = pd.read_csv(res_dir + f'/glm_{dist_short}_res.tsv', sep='\t', index_col=0)
            res_df = res_df.fillna(1)

            adj_pvalue_columns = [col for col in res_df.columns if '.adj.pvalue' in col]
            st.markdown("### Significant genes (FDR < 0.05):")
            total_significant = 0
            for col in adj_pvalue_columns:
                comparison = col.split('.adj.pvalue')[0]
                sig_count = (res_df[col] < 0.05).sum()
                total_significant += sig_count
                st.write(f"- {comparison}: {sig_count}")
            st.write(f"Total significant genes: {total_significant}")

            st.dataframe(res_df)
            
            st.session_state.deseq2 = res_df
            file_name = file_name_head + "_glm"
        
        # çµæœã®ZIPã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ä½œæˆã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
        shutil.make_archive(file_name, format='zip', root_dir=res_dir)
        
        with open(file_name + ".zip", "rb") as fp:
            btn = st.download_button(
                label="Download Results",
                data=fp,
                file_name=file_name + ".zip",
                mime="zip"
            )
        
        try:
            os.remove(file_name + ".zip")
        except:
            pass



#ã€€ãƒ‡ãƒ¼ã‚¿ã‚’é€ã‚‹å‰ã«ã™ã¹ã¦ã‚¼ãƒ­ã®ãƒ‡ãƒ¼ã‚¿ã¯é™¤ãã¹ã


# refãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹ã¨ãã¯ãƒ•ã‚¡ã‚¤ãƒ«åã‚’èª¿æ•´ã™ã‚‹?
