#!!!!!!!!!!!!!! pip install rpy2==3.5.1  æ–°ã—ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹

# åŸºæœ¬çš„ã«globalå¤‰æ•°ã§è¨ˆç®—ã™ã‚‹ã€‚
# pythonã‹ã‚‰assgnã•ã‚Œã‚‹ã®ã¯globalå¤‰æ•°


import streamlit as st
import rpy2
import csv
import re
import os
import numpy as np
import pandas as pd
import rpy2.robjects as ro
from rpy2.robjects.packages import importr
from rpy2.robjects import pandas2ri
from rpy2.robjects.vectors import StrVector
import pyper
import shutil
from PIL import Image
import itertools
from helper_func import clear_old_directories, clear_old_files, remove_after_space, remove_sample_num
import time
import sys
from collections import Counter

def remove_common_suffix(strings):
    if not strings or len(strings) == 0:
        return []    
    # æœ€ã‚‚çŸ­ã„æ–‡å­—åˆ—ã®é•·ã•ã‚’å–å¾—
    min_length = min(len(s) for s in strings)
    # å…±é€šã®æœ«å°¾éƒ¨åˆ†ã®é•·ã•ã‚’è¦‹ã¤ã‘ã‚‹
    suffix_length = 0
    for i in range(1, min_length + 1):
        suffix = strings[0][-i:]
        if all(s.endswith(suffix) for s in strings):
            suffix_length = i
        else:
            break            
    # å…±é€šã®æœ«å°¾éƒ¨åˆ†ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯å…ƒã®ãƒªã‚¹ãƒˆã‚’è¿”ã™
    if suffix_length == 0:
        return strings        
    # å…±é€šã®æœ«å°¾éƒ¨åˆ†ã‚’å‰Šé™¤ã—ã¦æ–°ã—ã„ãƒªã‚¹ãƒˆã‚’ä½œæˆ
    return [s[:-suffix_length] for s in strings]


def rename_duplicates(df):
    """
    Rename duplicate indices by adding _2, _3, etc. to subsequent occurrences   
    Args:
        df: pandas DataFrame
    Returns:
        DataFrame with renamed indices
    """
    # Get current index values
    lis = df.index.values
    
    # Count occurrences of each value
    counts = Counter()
    new_indices = []
    
    for x in lis:
        counts[x] += 1
        if counts[x] == 1:
            new_indices.append(x)
        else:
            new_indices.append(f"{x}_{counts[x]}")
    
    # Check if there were any duplicates
    if len(lis) != len(set(lis)):
        st.markdown("#### There are duplicated rows. Converting the names...")
        st.write("The gene names of subsequent occurrences have _2, _3, etc. at the end.")
        
        # Display which names were changed
        for name, count in counts.items():
            if count > 1:
                st.write(f"'{name}' appears {count} times â†’ {name}, " + 
                        ", ".join([f"{name}_{i}" for i in range(2, count + 1)]))
    
    # Set new index
    df.index = new_indices
    return df

@st.cache_data
def check_excel_autoconversion(dfx):
    p = re.compile(r'(\d+)\-(Mar|Sep|Oct|Dec|Feb|Nov)')
    index_name = dfx.index.values
    j = 0
    k = 0
    for i in df.index.values:
        x = p.match(i)
        if x:
            if k == 0:
                st.markdown("#### There are Excel-autoconverted gene names")
                st.write("Gene names are not converted.")
                k = 1
            autoconvert_flag = True
            st.write(i)


r = pyper.R(use_pandas=True)
f = ro.r("source('pages/deseq2_func.R')") # full pathãŒå¿…è¦

st.set_page_config(page_title="DESeq2-LRT", page_icon="ğŸ“ƒ")

@st.cache_data
def read_csv(file, index_col=None, sep=',', header = 0):
    df_c = pd.read_csv(file, index_col = index_col, header = header, sep = sep)
    return df_c


@st.cache_data
def convert_df(df):
   return df.to_csv(index=True, sep='\t').encode('utf-8')

@st.cache_data
def read_excel(file, index_col=None, header = 0):
    df_xl = pd.read_excel(file, index_col = index_col, header = header)
    return df_xl

@st.cache_data
def calc_barplot(data, ylabel):
    fig, ax = plt.subplots()
    ax = sns.barplot(data=data)
    ax.set_xticklabels(ax.get_xticklabels(),rotation = 90)
    ax.set_ylabel(ylabel, fontsize = 14)
    return fig


# tempå†…ã«ä¿å­˜ã™ã‚‹
# --- Initialising SessionState ---
if "temp_dir" not in st.session_state:
    st.session_state.temp_dir = True
    #å¤ã„direcotryã¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã™ã‚‹
    temp_dir = "temp/" + str(round(time.time()))
    if not os.path.exists('temp'):
        os.mkdir('temp')
    else:
        clear_old_directories("temp")
        clear_old_files("temp")
    os.mkdir(temp_dir)
    st.session_state.temp_dir = temp_dir
    res_dir = temp_dir + '/res_LRT'
    st.session_state.res_dir = res_dir
    os.mkdir(res_dir)

else:
    temp_dir = st.session_state.temp_dir
    res_dir = temp_dir + '/res_LRT'
    st.session_state.res_dir = res_dir
    if not os.path.exists(temp_dir):
        os.mkdir(temp_dir)
        os.mkdir(res_dir)
    if not os.path.exists(res_dir):
        os.mkdir(res_dir)

st.sidebar.title("Options")
with st.sidebar:
    st.markdown("#### Test medhod:")
    test_method = st.radio("Test method:", 
                         ["DESeq2-LRT", "limma eBayes", "Beta Regression", 
                          "Generalized Linear Model (GLM)", "Generalized Additive Model (GAM)", "maSigPro"], 
                         index=0, label_visibility = 'collapsed')

    st.markdown("##### limma eBayes with logit transformation and beta regression are for proportion data.")

    if test_method == 'DESeq2-LRT':
        st.markdown("---")
        st.markdown("### DESeq2 Polynomial Options:")
        add_polynomial = st.checkbox("Add polynomial terms for time variable?", value=False, 
                                   help="Non-linear changes over timeï¼ˆæ™‚é–“çµŒéã«ä¼´ã†éç·šå½¢å¤‰åŒ–ï¼‰ã‚’æ¤œå‡ºã™ã‚‹ãŸã‚ã«å¤šé …å¼ã®é …ã‚’åŠ ãˆã¾ã™")

        
        if add_polynomial:
            st.markdown("#### Using first variable from full model as time variable, which must be numeric.")

            polynomial_term = st.radio("Polynomial degree", 
                                    ['2: Quadratic: U-shaped pattern', 
                                     '3: Cubic: S-shaped pattern'], 
                                    index=0, 
                                    help="2æ¬¡å¤šé …å¼ï¼š1ã¤ã®æ–¹å‘å¤‰åŒ–ï¼ˆå¢—åŠ â†’æ¸›å°‘ãªã©ï¼‰ã‚’æ¤œå‡ºã€‚3æ¬¡å¤šé …å¼ï¼š2ã¤ã®æ–¹å‘å¤‰åŒ–ï¼ˆå¢—åŠ â†’æ¸›å°‘â†’å¢—åŠ ãªã©ï¼‰ã‚’æ¤œå‡º")
            
            # å¤šé …å¼å®Ÿè£…æ–¹æ³•ã®é¸æŠ
            poly_implementation = st.radio("Implementation method",
                                        ["poly() function", "I() function (explicit powers)"],
                                        index=0,
                                        help="poly()é–¢æ•°ï¼šç›´äº¤å¤šé …å¼ã‚‚ä½¿ç”¨å¯èƒ½ã§æ¨å¥¨ã€‚I()é–¢æ•°ï¼šå˜ç´”ãªã¹ãä¹—é …ã®ä½¿ç”¨")
            
            # poly()é–¢æ•°ã‚’ä½¿ã†å ´åˆã®è¿½åŠ ã‚ªãƒ—ã‚·ãƒ§ãƒ³
            use_poly_function = poly_implementation.startswith("poly()")
            
            if use_poly_function:
                # å¤šé …å¼ã‚¿ã‚¤ãƒ—ã®é¸æŠã‚ªãƒ—ã‚·ãƒ§ãƒ³
                poly_type = st.radio("Polynomial type",
                                   ["Orthogonal", "Raw"],
                                   index=0,
                                   help="ç›´äº¤å¤šé …å¼ï¼ˆOrthogonalï¼‰ï¼šå…±ç·šæ€§ã‚’é¿ã‘ã‚‹ãŸã‚ã«æ¨å¥¨ã€‚Rawï¼šè§£é‡ˆã—ã‚„ã™ã„ä¿‚æ•°ã‚’å¾—ã‚‹ãŒå…±ç·šæ€§ã®å•é¡ŒãŒã‚ã‚‹å ´åˆã‚ã‚Š")
                use_raw = poly_type.startswith("Raw")
            else:
                use_raw = False  # I()é–¢æ•°ä½¿ç”¨æ™‚ã¯é–¢ä¿‚ãªã„ã®ã§False
                            
            polynomial_degree = 2 if polynomial_term.startswith('2:') else 3
            
        else:
            polynomial_variable = None
            polynomial_degree = 1
            use_raw = False
            use_poly_function = True  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤


    if test_method == 'limma eBayes':
        limma_data = st.radio("Data type:",
            ["RNA-seq count", "Non-count data", "0-1 data (proportion, AUC etc) to logit transformation"],
            index = 1)

        if limma_data == "RNA-seq count":
            apply_logit = False
            limma_count = True
        elif limma_data == "Non-count data":
            apply_logit = False
            limma_count = False
        else:
            apply_logit = True
            limma_count = False
            
        st.markdown("---")
        st.markdown("### limma Polynomial Options:")
        limma_add_polynomial = st.checkbox("Add polynomial terms for time variable?", value=False, 
                                   help="Non-linear changes over timeï¼ˆæ™‚é–“çµŒéã«ä¼´ã†éç·šå½¢å¤‰åŒ–ï¼‰ã‚’æ¤œå‡ºã™ã‚‹ãŸã‚ã«å¤šé …å¼ã®é …ã‚’åŠ ãˆã¾ã™")

        if limma_add_polynomial:
            st.markdown("#### Using first variable from full model as time variable, which must be numeric.")

            limma_polynomial_term = st.radio("Polynomial degree", 
                                    ['2: Quadratic: U-shaped pattern', 
                                     '3: Cubic: S-shaped pattern'], 
                                    index=0, 
                                    help="2æ¬¡å¤šé …å¼ï¼š1ã¤ã®æ–¹å‘å¤‰åŒ–ï¼ˆå¢—åŠ â†’æ¸›å°‘ãªã©ï¼‰ã‚’æ¤œå‡ºã€‚3æ¬¡å¤šé …å¼ï¼š2ã¤ã®æ–¹å‘å¤‰åŒ–ï¼ˆå¢—åŠ â†’æ¸›å°‘â†’å¢—åŠ ãªã©ï¼‰ã‚’æ¤œå‡º")
            
            # å¤šé …å¼å®Ÿè£…æ–¹æ³•ã®é¸æŠ
            limma_poly_implementation = st.radio("Implementation method",
                                        ["poly() function", "I() function (explicit powers)"],
                                        index=0,
                                        help="poly()é–¢æ•°ï¼šç›´äº¤å¤šé …å¼ã‚‚ä½¿ç”¨å¯èƒ½ã§æ¨å¥¨ã€‚I()é–¢æ•°ï¼šå˜ç´”ãªã¹ãä¹—é …ã®ä½¿ç”¨")
            
            # poly()é–¢æ•°ã‚’ä½¿ã†å ´åˆã®è¿½åŠ ã‚ªãƒ—ã‚·ãƒ§ãƒ³
            limma_use_poly_function = limma_poly_implementation.startswith("poly()")
            
            if limma_use_poly_function:
                # å¤šé …å¼ã‚¿ã‚¤ãƒ—ã®é¸æŠã‚ªãƒ—ã‚·ãƒ§ãƒ³
                limma_poly_type = st.radio("Polynomial type",
                                   ["Orthogonal", "Raw"],
                                   index=0,
                                   help="ç›´äº¤å¤šé …å¼ï¼ˆOrthogonalï¼‰ï¼šå…±ç·šæ€§ã‚’é¿ã‘ã‚‹ãŸã‚ã«æ¨å¥¨ã€‚Rawï¼šè§£é‡ˆã—ã‚„ã™ã„ä¿‚æ•°ã‚’å¾—ã‚‹ãŒå…±ç·šæ€§ã®å•é¡ŒãŒã‚ã‚‹å ´åˆã‚ã‚Š")
                limma_use_raw = limma_poly_type.startswith("Raw")
            else:
                limma_use_raw = False  # I()é–¢æ•°ä½¿ç”¨æ™‚ã¯é–¢ä¿‚ãªã„ã®ã§False
                            
            limma_polynomial_degree = 2 if limma_polynomial_term.startswith('2:') else 3
            
        else:
            limma_polynomial_variable = None
            limma_polynomial_degree = 1
            limma_use_raw = False
            limma_use_poly_function = True  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            
    # ãƒ™ãƒ¼ã‚¿å›å¸°ç‰¹æœ‰ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    if test_method == 'Beta Regression':
        st.markdown("### Beta Regression Options:")
        epsilon = st.number_input("Epsilon for boundary adjustment (0-1 data)", 
                                min_value=0.0000001, max_value=0.01, value=0.000001, format="%.7f")
        add_higher = st.checkbox("Add polynomial terms?", value=False, help="éç·šå½¢çš„ãªå¤‰åŒ–ã‚’æ‰ãˆã‚‹ãŸã‚å¤šé …é …ã‚’åŠ ãˆã‚‹")
        beta_polynomial_degree = 1
        if add_higher:
            polynomial_term = st.radio("Degree", ['2:Quadratic term','3:Cubic term'], index = 0, help = "2æ¬¡ã®é …ã‚’åŠ ãˆã‚‹ã¨U-shaped/inverted U-shaped patternsãŒæ‰ãˆã‚‰ã‚Œã‚‹ã€‚3æ¬¡ã®é …ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šè¤‡é›‘ãªç™ºç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ‰ãˆã‚‹ã€‚ä¾‹ãˆã°ï¼šæ€¥ä¸Šæ˜‡å¾Œã«æ¨ªã°ã„ã«ãªã‚Šã€ãã®å¾Œä½ä¸‹ã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã€æ³¢å½¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã€‚")
            st.markdown("#### The first item in full model will be used for polynominal term.")
            if polynomial_term == "2:Quadratic term":
                beta_polynomial_degree = 2
            else:
                beta_polynomial_degree = 3

        
    # GLMç‰¹æœ‰ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    if test_method == 'Generalized Linear Model (GLM)':
        st.markdown("### GLM Options:")
        # åˆ†å¸ƒãƒ•ã‚¡ãƒŸãƒªãƒ¼ã®é¸æŠã‚ªãƒ—ã‚·ãƒ§ãƒ³
        glm_dist_family = st.radio("Probability distribution", 
                              ["Beta (0-1)", 
                               "Gaussian", 
                               "Poisson", 
                               "Negative Binomial"],
                              index=0,
                              help="ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸç¢ºç‡åˆ†å¸ƒã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚Beta: 0-1ã®å€¤ï¼ˆå‰²åˆãªã©ï¼‰, Gaussian: é€£ç¶šå€¤ãƒ‡ãƒ¼ã‚¿, Poisson: ã‚·ãƒ³ãƒ—ãƒ«ãªã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿, Negative Binomial: éåˆ†æ•£ã®ã‚ã‚‹ã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆRNA-seq, scRNA-seqç­‰ï¼‰")

        if glm_dist_family == "Beta (0-1)":
            glm_dist_short = "beta"
        elif glm_dist_family == "Gaussian":
            glm_dist_short = "gaussian"
        elif glm_dist_family == "Poisson":
            glm_dist_short = "poisson"
        elif glm_dist_family == "Negative Binomial":
            glm_dist_short = "nb"

        glm_epsilon = 0
        glm_nb_theta = None

        # ãƒªãƒ³ã‚¯é–¢æ•°ã®é¸æŠ
        if glm_dist_family == "Beta (0-1)":
            glm_link = st.radio("Link function for Beta distribution",
                               ["logit", "probit", "cloglog"],
                               index=0,
                               help="logit: æœ€ã‚‚ä¸€èˆ¬çš„ã€probit: æ­£è¦åˆ†å¸ƒãƒ™ãƒ¼ã‚¹ã€cloglog: æ¥µå€¤åˆ†å¸ƒãƒ™ãƒ¼ã‚¹")
            glm_epsilon = st.number_input("Epsilon for boundary adjustment", 
                                   min_value=0.0000001, max_value=0.01, value=0.000001, format="%.7f")
        elif glm_dist_family == "Gaussian":
            glm_link = st.radio("Link function for Gaussian distribution",
                               ["identity", "log", "inverse"],
                               index=0,
                               help="identity: ç·šå½¢é–¢ä¿‚ã€log: æ­£ã®å€¤ã®ã¿ã€inverse: é€†æ•°å¤‰æ›")
        elif glm_dist_family == "Poisson":
            glm_link = st.radio("Link function for Poisson distribution",
                               ["log", "identity", "sqrt"],
                               index=0,
                               help="log: æœ€ã‚‚ä¸€èˆ¬çš„ï¼ˆã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ï¼‰ã€identity: ç·šå½¢ã€sqrt: å¹³æ–¹æ ¹å¤‰æ›")
        elif glm_dist_family == "Negative Binomial":
            glm_link = st.radio("Link function for Negative Binomial distribution",
                               ["log", "identity", "sqrt"],
                               index=0,
                               help="log: æœ€ã‚‚ä¸€èˆ¬çš„ï¼ˆéåˆ†æ•£ã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ï¼‰ã€identity: ç·šå½¢ã€sqrt: å¹³æ–¹æ ¹å¤‰æ›")
            glm_nb_theta = st.number_input("éåˆ†æ•£ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (theta)", 
                                     min_value=0.1, max_value=100.0, value=10.0,
                                     help="å€¤ãŒå°ã•ã„ã»ã©éåˆ†æ•£ãŒå¤§ãã„ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ã€‚RNA-seqã§ã¯é€šå¸¸5-10ç¨‹åº¦ã€‚scRNA:0.5-3 (10x:1-2)")

        # Polynomial options for GLM
        st.markdown("---")
        st.markdown("### GLM Polynomial Options:")
        glm_add_polynomial = st.checkbox("Add polynomial terms for time variable?", value=False, 
                                   help="Non-linear changes over timeï¼ˆæ™‚é–“çµŒéã«ä¼´ã†éç·šå½¢å¤‰åŒ–ï¼‰ã‚’æ¤œå‡ºã™ã‚‹ãŸã‚ã«å¤šé …å¼ã®é …ã‚’åŠ ãˆã¾ã™")

        if glm_add_polynomial:
            st.markdown("#### Using first variable from full model as time variable, which must be numeric.")

            glm_polynomial_term = st.radio("Polynomial degree", 
                                    ['2: Quadratic: U-shaped pattern', 
                                     '3: Cubic: S-shaped pattern'], 
                                    index=0, 
                                    help="2æ¬¡å¤šé …å¼ï¼š1ã¤ã®æ–¹å‘å¤‰åŒ–ï¼ˆå¢—åŠ â†’æ¸›å°‘ãªã©ï¼‰ã‚’æ¤œå‡ºã€‚3æ¬¡å¤šé …å¼ï¼š2ã¤ã®æ–¹å‘å¤‰åŒ–ï¼ˆå¢—åŠ â†’æ¸›å°‘â†’å¢—åŠ ãªã©ï¼‰ã‚’æ¤œå‡º")
            
            # å¤šé …å¼å®Ÿè£…æ–¹æ³•ã®é¸æŠ
            glm_poly_implementation = st.radio("Implementation method",
                                        ["poly() function", "I() function (explicit powers)"],
                                        index=0,
                                        help="poly()é–¢æ•°ï¼šç›´äº¤å¤šé …å¼ã‚‚ä½¿ç”¨å¯èƒ½ã§æ¨å¥¨ã€‚I()é–¢æ•°ï¼šå˜ç´”ãªã¹ãä¹—é …ã®ä½¿ç”¨")
            
            # poly()é–¢æ•°ã‚’ä½¿ã†å ´åˆã®è¿½åŠ ã‚ªãƒ—ã‚·ãƒ§ãƒ³
            glm_use_poly_function = glm_poly_implementation.startswith("poly()")
            
            if glm_use_poly_function:
                # å¤šé …å¼ã‚¿ã‚¤ãƒ—ã®é¸æŠã‚ªãƒ—ã‚·ãƒ§ãƒ³
                glm_poly_type = st.radio("Polynomial type",
                                   ["Orthogonal", "Raw"],
                                   index=0,
                                   help="ç›´äº¤å¤šé …å¼ï¼ˆOrthogonalï¼‰ï¼šå…±ç·šæ€§ã‚’é¿ã‘ã‚‹ãŸã‚ã«æ¨å¥¨ã€‚Rawï¼šè§£é‡ˆã—ã‚„ã™ã„ä¿‚æ•°ã‚’å¾—ã‚‹ãŒå…±ç·šæ€§ã®å•é¡ŒãŒã‚ã‚‹å ´åˆã‚ã‚Š")
                glm_use_raw = glm_poly_type.startswith("Raw")
            else:
                glm_use_raw = False  # I()é–¢æ•°ä½¿ç”¨æ™‚ã¯é–¢ä¿‚ãªã„ã®ã§False
                            
            glm_polynomial_degree = 2 if glm_polynomial_term.startswith('2:') else 3
            
        else:
            glm_polynomial_variable = None
            glm_polynomial_degree = 1
            glm_use_raw = False
            glm_use_poly_function = True  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤

    # GAMç‰¹æœ‰ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    if test_method == 'Generalized Additive Model (GAM)':
        st.markdown("### GAM Options:")
        # åˆ†å¸ƒãƒ•ã‚¡ãƒŸãƒªãƒ¼ã®é¸æŠã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ 
        dist_family = st.radio("Probability distribution", 
                              ["Beta (0-1)", 
                               "Gaussian", 
                               "Poisson", 
                               "Negative Binomial"],
                              index=0,
                              help="ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸç¢ºç‡åˆ†å¸ƒã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚Beta: 0-1ã®å€¤ï¼ˆå‰²åˆãªã©ï¼‰, Gaussian: é€£ç¶šå€¤ãƒ‡ãƒ¼ã‚¿, Poisson: ã‚·ãƒ³ãƒ—ãƒ«ãªã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿, Negative Binomial: éåˆ†æ•£ã®ã‚ã‚‹ã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆRNA-seq, scRNA-seqç­‰ï¼‰")

        if dist_family == "Beta (0-1)":
            dist_short = "beta"
        elif dist_family == "Gaussian":
            dist_short = "gaussian"
        elif dist_family == "Poisson":
            dist_short = "poisson"
        elif dist_family == "Negative Binomial":
            dist_short = "nb"

        st.write(dist_short)

        epsilon = 0
        nb_theta = None


        # åˆ†å¸ƒã«å¿œã˜ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
        if dist_family == "Beta (0-1)":
            epsilon = st.number_input("Epsilon for boundary adjustment", 
                                   min_value=0.0000001, max_value=0.01, value=0.000001, format="%.7f")
        elif dist_family == "Negative Binomial":
            nb_theta = st.number_input("éåˆ†æ•£ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (theta)", 
                                     min_value=0.1, max_value=100.0, value=10.0,
                                     help="å€¤ãŒå°ã•ã„ã»ã©éåˆ†æ•£ãŒå¤§ãã„ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ã€‚RNA-seqã§ã¯é€šå¸¸5-10ç¨‹åº¦ã€‚scRNA:0.5-3 (10x:1-2)")


        gam_k = st.slider("Spline basis dimension (k)", min_value=3, max_value=20, value=4, help = "éç·šå½¢é–¢ä¿‚ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã™ã‚‹ãŸã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°é–¢æ•°ã®æŸ”è»Ÿæ€§ï¼ˆè¤‡é›‘ã•ï¼‰ã‚’åˆ¶å¾¡ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€‚k ã®å€¤ãŒå¤§ãã„ã»ã©ã€ãƒ¢ãƒ‡ãƒ«ã¯ã‚ˆã‚Šè¤‡é›‘ãªéç·šå½¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ‰ãˆã‚‹ã€‚ã€Œæ™‚é–“ç‚¹ã®æ•° + 0ã€œ1ã€")
        gam_method = st.radio("Smoothing parameter estimation method", 
                            ["REML", "GCV.Cp", "ML"], index=0,
                            help="REML (Restricted Maximum Likelihood):åˆ†æ•£ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨å¹³æ»‘åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’åŒæ™‚ã«æ¨å®šã€‚ãƒã‚¤ã‚¢ã‚¹ãŒå°‘ãªãã€ã‚ˆã‚Šä¿¡é ¼æ€§ã®é«˜ã„æ¨å®šã€‚å°ã•ãªã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã§ã‚‚æ¯”è¼ƒçš„å®‰å®šã€‚   ML (Maximum Likelihood):æœ€å°¤æ¨å®šæ³•ã€‚ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒï¼ˆAIC, BICãªã©ï¼‰ã«é©ã™ã€‚å°ã•ãªã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã§ã¯ãƒã‚¤ã‚¢ã‚¹ãŒç”Ÿã˜ã‚‹å¯èƒ½æ€§ã€‚  GCV.Cp (Generalized Cross Validation / Mallows' Cp):ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã«åŸºã¥ãã€‚ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬èƒ½åŠ›ã‚’æœ€é©åŒ–ã€‚äºˆæ¸¬ãŒç›®çš„ã®å ´åˆã«æœ‰ç”¨ã€‚")

        selected_spline = st.radio("Spline type",
                        ['Thin Plate Regression Splines (tp)', 'Cubic Regression Splines (cr)', 'Cubic Smoothing Splines (cs)'],
                        index =1, help="tp:æœ€ã‚‚æ±ç”¨çš„ãªã‚¹ãƒ—ãƒ©ã‚¤ãƒ³ã‚¿ã‚¤ãƒ—ã€‚ä¸€èˆ¬çš„ã«ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã€‚  cr:3æ¬¡å¤šé …å¼ã®åŒºåˆ†çš„ãªçµ„ã¿åˆã‚ã›ã€‚æ™‚é–“ç‚¹ãŒå°‘ãªã„å ´åˆã«é©ã—ã¦ã„ã‚‹ã‚±ãƒ¼ã‚¹ãŒã‚ã‚‹ã€‚  cs:è¦³æ¸¬ãƒ‡ãƒ¼ã‚¿ç‚¹ã«ãƒãƒƒãƒˆã‚’é…ç½®ã€‚éå¸¸ã«æŸ”è»Ÿã§ã€ãƒ‡ãƒ¼ã‚¿ç‚¹é–“ã‚’æ»‘ã‚‰ã‹ã«è£œé–“ã€‚ãƒ‡ãƒ¼ã‚¿ç‚¹ãŒå°‘ãªã„å ´åˆã«æœ‰ç”¨ãªã“ã¨ãŒã‚ã‚‹")
        # é¸æŠã«åŸºã¥ã„ã¦å¤‰æ•°ã‚’è¨­å®š
        if selected_spline == 'Thin Plate Regression Splines (tp)':
            spline_type = "tp"
        elif selected_spline == 'Cubic Regression Splines (cr)':
            spline_type = "cr"
        elif selected_spline == 'Cubic Smoothing Splines (cs)':
            spline_type = "cs"

    #    beta_norm = st.checkbox("Normalization by maximum value of time variable", value = False,
    #        help='æœ€å¤§å€¤ã«ã‚ˆã‚‹æ­£è¦åŒ–.æ™‚é–“ã‚’å«ã‚€ã¨ãã«åæŸã—ãªã„å ´åˆã«è©¦ã¿ã‚‹') #åŠ¹æœãŒãªã•ãã†

#        beta_normalization = "TRUE" if beta_norm else "FALSE"
        beta_normalization = "FALSE"
    if test_method in ['Beta Regression', 'Generalized Linear Model (GLM)', 'Generalized Additive Model (GAM)']:
        n_cores = st.slider("Parallel cores", min_value=1, 
                           max_value=os.cpu_count()-1, 
                           value=max(1, os.cpu_count()//2-4))


    if test_method == 'maSigPro':
        st.markdown("### maSigPro Options:")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã®é¸æŠ
        data_type = st.radio(
            "Data type:",
            ["RNA-seq count data (GLM)", "qPCR/continuous data (Gaussian)", "0-1 data (logit transformation)"],
            index=0
        )
        
        # ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
        if data_type == "0-1 data (logit transformation)":
            st.markdown("##### Boundary adjustment for 0-1 data:")
            epsilon = st.number_input("Epsilon", 
                                    min_value=1e-8, 
                                    max_value=0.01, 
                                    value=1e-6,
                                    format="%.8f")
        elif data_type == "qPCR/continuous data (Gaussian)":
            st.markdown("##### qPCR/Continuous data options:")
            log_transform = st.checkbox("Log2 transform data", value=True, 
                                      help="qPCRãƒ‡ãƒ¼ã‚¿ã®å ´åˆã€é€šå¸¸log2å¤‰æ›ã‚’è¡Œã„ã¾ã™ï¼ˆÎ”Ctå€¤ãªã©ï¼‰")
            normalization = st.checkbox("Z-score normalization across samples", value=False,
                                       help="qPCRã§ã¯é€šå¸¸ä¸è¦")
        
        # å…±é€šã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        degree = st.slider("Polynomial degree", min_value=1, max_value=3, value=2)
        rsq = st.number_input("R-squared cutoff", min_value=0.1, max_value=0.9, value=0.7, step=0.05)
        q_value = st.number_input("Q-value (FDR)", min_value=0.001, max_value=0.5, value=0.05, step=0.01)
        
        # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        st.markdown("##### Clustering options:")
        cluster_method = st.radio("Clustering method", 
                                ["hclust", "kmeans", "clara"], index=0)
        k = st.slider("Number of clusters", min_value=2, max_value=15, value=9)
        
        # å¯è¦–åŒ–ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        st.markdown("##### Visualization:")
        plot_top_n = st.slider("Number of genes to plot", min_value=5, max_value=50, value=20)

    st.markdown("---")

st.markdown("### DESeq2 likelihood-ratio test (LRT), limma eBayes, betareg, GAM for time-course and ANOVA-like test")
st.markdown("### maSigPro for time-course test")
st.markdown("##### DESeq2-LRT, beta regression can use polynomial terms that help time-course analysis")
st.markdown("##### limma eBayes and GAM can be used with both count and non-count data, including AUC")
st.markdown("##### beta regression, GAM with beta regression and limma with logit transformation are for proportion (0-1) data")
st.markdown("##### See left sidebar for options")
st.write(" ")
use_upload = 'Yes'
if 'df' in st.session_state:
    if st.session_state.df is not None:
        use_upload = st.radio("Upload new file?", ('Yes','No'), index = 1)
    if use_upload == "No":
        df = st.session_state.df
        input_file_type = 'tsv'
        file_name_head = st.session_state.uploaded_file_name
        if "Row_name" in df.columns.to_list(): # Row_nameã‚’å«ã‚€ã¨ã
            df = df.set_index('Row_name')
            df.index.name = "Gene"



if use_upload == 'Yes':
    st.markdown("##### Data format:")
    file_type = st.radio(
        "",    ('Homer','tsv','csv','excel'), index = 1, label_visibility = 'collapsed')


    uploaded_file = st.file_uploader("Choose a file", type=['txt','tsv', 'csv', 'xls','xlsx'])
    if uploaded_file is not None:
        if file_type is not 'excel':
            if file_type == 'csv':
                df = read_csv(uploaded_file)
            else:
                df = read_csv(uploaded_file, sep = '\t')
            st.write("Original:")
            st.write(df.head())
            if file_type == 'Homer':
                df = df.iloc[:,7:]
                colnames = df.columns.tolist()
                colnames[0] = 'Gene'
                # colnamesã®å¤‰æ›
                search_word = '([^\ \(]*)\ \(.*'
                for i in range(1, len(colnames)):
                    match = re.search(search_word, colnames[i])
                    if match:
                        colnames[i] = match.group(1).replace(' ', '_')
                pattern = "([^|]*)"
                repatter = re.compile(pattern)
                f_annotation = lambda x: repatter.match(x).group(1)
                try:
                    df.iloc[:,0] = df.iloc[:,0].apply(f_annotation)
                    df.columns = colnames
                except:
                    st.markdown("### File format error. Non-Homer file?")

            else:
                colnames = df.columns.tolist()
                colnames[0] = 'Gene'
                df.columns = colnames
        else: # excel
            df = read_excel(uploaded_file, index_col = 0)
            content = df.columns.tolist()
            if "Annotation/Divergence" in content:
                 # colnamesã®å¤‰æ›
                search_word = '([^\ \(]*)\ \(.*'

                for i in range(1, len(content)):
                    match = re.search(search_word, content[i])
                    if match:
                        content[i] = match.group(1).replace(' ', '_')
                df.columns = content # ä¸€æ—¦åå‰ã‚’å¤‰æ›´
                df['Annotation/Divergence'] = df['Annotation/Divergence'].astype(str) # excel å¯¾å¿œ
                pattern = "([^|]*)"
                repatter = re.compile(pattern)
                f_annotation = lambda x: repatter.match(x).group(1)
                df.loc[:,'Annotation/Divergence'] = df.loc[:,'Annotation/Divergence'].apply(f_annotation)
                # annotation/divergenceä»¥å‰ã‚’é™¤ã
                df = df.loc[:,'Annotation/Divergence':]
                content = df.columns.tolist()
                content[0] = 'Gene'
                df.columns = content
                st.write("Converted Annotation/Divergence to gene symbols.")
            else:
                colnames = df.columns.tolist()
                colnames[0] = 'Gene'
                df.columns = colnames

        df = df.set_index('Gene')
        file_name_head = os.path.splitext(uploaded_file.name)[0]
    else:
        sys.exit(1)

if df is not None:

############ sampleåã®Rã§ä½¿ãˆãªã„æ–‡å­—ã‚’ä¿®æ­£
    def make_valid_r_names(names):
        """Rã§æœ‰åŠ¹ãªå¤‰æ•°åã«å¤‰æ›ã™ã‚‹é–¢æ•°"""
        valid_names = []
        changes_made = False
        
        for name in names:
            original_name = name
            
            # 1. ç‰¹æ®Šæ–‡å­—ã‚’ç½®æ›
            name = re.sub(r'[ ]+', '.', name)  # ã‚¹ãƒšãƒ¼ã‚¹ã‚’.ã«
            name = re.sub(r'[-]+', '_', name)  # ãƒã‚¤ãƒ•ãƒ³ã‚’_ã«
            name = re.sub(r'[^\w.]', '_', name)  # è‹±æ•°å­—ãƒ»ãƒ”ãƒªã‚ªãƒ‰ãƒ»ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ä»¥å¤–ã‚’_ã«
            
            # 2. å…ˆé ­ãŒæ•°å­—ã®å ´åˆã¯Xã‚’ä»˜ã‘ã‚‹
            if re.match(r'^\d', name):
                name = 'X' + name
            
            # 3. å…ˆé ­ãŒãƒ”ãƒªã‚ªãƒ‰ã§æ•°å­—ãŒç¶šãå ´åˆã¯Xã‚’ä»˜ã‘ã‚‹
            if re.match(r'^\.\d', name):
                name = 'X' + name
            
            # 4. äºˆç´„èªãƒã‚§ãƒƒã‚¯ï¼ˆåŸºæœ¬çš„ãªã‚‚ã®ï¼‰
            r_reserved = ['if', 'else', 'repeat', 'while', 'function', 'for', 'in', 'next', 'break', 
                         'TRUE', 'FALSE', 'NULL', 'Inf', 'NaN', 'NA', 'NA_integer_', 'NA_real_', 
                         'NA_complex_', 'NA_character_']
            if name in r_reserved:
                name = name + '_'
            
            if original_name != name:
                changes_made = True
            
            valid_names.append(name)
        
        return valid_names, changes_made
    
    # ã‚µãƒ³ãƒ—ãƒ«åã‚’ä¿®æ­£
    new_columns, changes_made = make_valid_r_names(df.columns.tolist())
    if changes_made:
        st.write("Sample names have been converted to be R-compatible:")
        for old, new in zip(df.columns.tolist(), new_columns):
            if old != new:
                st.write(f"  '{old}' â†’ '{new}'")
        df.columns = new_columns
############


    st.write('Original gene number:  ' + str(len(df)))

    # floatã«å¤‰æ› èª¤å°„æ‚Ÿå…¥
    df = df.astype(float)

    if not float.is_integer(df.iloc[:,0].sum()*1000):
        if test_method == "DESeq2-LRT":
            st.markdown("## It is likely that your data are normalized. Please upload unnormalized raw count data.")

    if test_method == "DESeq2-LRT": #DESeq2ã¯æ•´æ•°åŒ–
        df = df.round(0)

    df = df.loc[~(df==0).all(axis=1)] #ã™ã¹ã¦0ã®rowã‚’é™¤ã

########## excelå¯¾å¿œ?
    st.write("All zero count genes are removed.")
    if df.isnull().values.sum() > 0:
        st.write("There are " + str(df.isnull().values.sum()) + " NaN in :")
        st.write(df[df.isnull().any(axis=1)])
        convert_nan = st.radio( "NaN:",
        ('remove Nan containing genes', 'conver to 0' ), key='remove Nan containing genes')
        if convert_nan == "conver to 0":
            df = df.fillna(0)
        else:
            df = df.dropna(how='any')
############ sampleåã«-ãŒã‚ã‚‹å ´åˆã¯underscoreã¸ Rã§ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹
    if "-" in "".join(df.columns.values):
        st.write("Minus in sample name will be converted to _.")
        new_columns = [x.replace('-','_') for x in df.columns.values]
        df.columns = new_columns
############


  #  st.write(df.head())
    total_count = pd.DataFrame(df.sum()[1:])
    total_count.columns= ['Total counts']
    large_var = False
    if max(total_count['Total counts']) > min(total_count['Total counts']) * 2:
        large_var = True
        st.markdown("### Large difference (>2x) in counts")
        st.write(f"Minimum total counts: {min(total_count['Total counts'])}")
        st.markdown("##### Low count samples can be filtered on the side panel.")
        import matplotlib.pyplot as plt
        import seaborn as sns
        df_sum = pd.DataFrame(df.sum())
        df_sum.columns = ['Counts']


        f1 = calc_barplot(df_sum.T, ylabel = "Total counts")
        st.pyplot(f1)

        f2 = calc_barplot(np.log1p(df), ylabel = "ln(x+1)")
        st.pyplot(f2)

    with st.sidebar:

        sample_threshold = 0

        if large_var:
            st.markdown("### Filter the samples <= counts:")
            sample_threshold = st.number_input("Minimum total cout", value = 0, label_visibility = 'collapsed')
            st.markdown("---")

        if test_method == 'DESeq2-LRT' or (test_method == 'limma eBayes' and limma_count):
            st.markdown("### Filter out weakly-expressed genes before multiple test correction:",help = "independentFiltering default:TRUE å¹³å‡æ­£è¦åŒ–ã‚«ã‚¦ãƒ³ãƒˆã«åŸºã¥ã„ã¦éºä¼å­ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã€å¤šé‡æ¤œå®šè£œæ­£ã®è² æ‹…ã‚’æ¸›ã‚‰ã™ã“ã¨ã§çµ±è¨ˆçš„æ¤œå‡ºåŠ›ã‚’å‘ä¸Šã•ã›ã‚‹")
            independentFiltering = st.checkbox('Yes', value=True)
            st.markdown("---")

        st.markdown("### Furhter filtering of genes")
        st.markdown("""#### ä½ç™ºç¾éºä¼å­ã®é™¤å¤–ã¯FDRã®è¨ˆç®—ã‚’æ”¹å–„ã™ã‚‹""")

        st.markdown("#### Filter the genes > counts in all samples:")
        min_threshold = st.number_input("count minimum", value = 0, label_visibility = 'collapsed')
        min_threshold = int(min_threshold)
        st.markdown("#### Filter the genes > counts in at least one sample:")
        max_threshold = st.number_input("count max", value = 0, label_visibility = 'collapsed')
        max_threshold = int(max_threshold)
        st.markdown("---")

        if test_method == 'DESeq2-LRT':
            st.markdown("### Batch correction:")
            sva = st.checkbox('SVA batch removal?')
            sva_calc = True
            if sva:
                sva_calc = st.checkbox('Calculate only 2 surrogate variables? Deselect if want to calculate up to the recommended number.', value = True)
                st.markdown("---")

    if any(df.sum() <= sample_threshold): # count 0ã®åˆ—ã‚’é™¤ã
        st.markdown('#### There are the samples that have counts <= ' + str(sample_threshold))
        st.write(", ".join(df.columns[df.sum() <= sample_threshold].to_list()))
        st.markdown('##### They are removed. Now data are:')
        df = df.drop(df.columns[df.sum() <= sample_threshold].to_list(), axis = 1)

    st.write(df.head())

    if min_threshold > 0:
        df = df[df.apply(min, axis=1) > min_threshold]
    if max_threshold > 0:
        df = df[df.apply(max, axis=1) > max_threshold]

    st.markdown(f'#### Filtered gene number: {str(len(df))}')


    condition = [str(i) for i in df.columns.tolist()[:]] #erroré˜²æ­¢
    group_condition = remove_common_suffix(condition) #æœ«å°¾ã®å…±é€šè¦ç´ ã‚’é™¤ã
  #  group_condition = [remove_after_space(x) for x in condition] #ã‚¹ãƒšãƒ¼ã‚¹ä»¥é™ã‚’é™¤ã
    group_condition = [remove_sample_num(x) for x in group_condition] #æœ«å°¾ã®æ•°å­—ã‚’é™¤ã


    st.markdown("##### Add conditions other than group, such as genotype (comma, space, CR separated):")
    genes = st.text_input("genes",label_visibility = 'collapsed')
    gene_list = []
    if len(genes) > 0:
        gene_list = genes.split(' ') #ã¾ãšç©ºç™½ã§åˆ†é›¢
        gene_list = list(filter(lambda a: a != '', gene_list)) #ç©ºç™½ã®ã¿ã‚’é™¤ã
        if ',' in genes:
            gene_list = sum([x.split(',') for x in gene_list],[]) #sumã§å¹³å¦åŒ– sum(x, [])
        if '\t' in genes:
            gene_list = sum([x.split('\t') for x in gene_list],[])
        if '\n' in genes:
            gene_list = sum([x.split('\n') for x in gene_list],[])
        gene_list = [a for a in gene_list if a != ''] #ç©ºã‚’é™¤ã
    condition_col = sum([['Group'], gene_list], [] )

    with st.form("input_groups and batch"):
        df_e = pd.DataFrame(index = condition, columns = condition_col)
        for i in df_e.columns.values:
            df_e[i] = group_condition
        st.write('Set conditions:')
    #    edited_df_e = st.experimental_data_editor(df_e)
        df_e = st.data_editor(df_e)
        submitted = st.form_submit_button("Submit")

    condition = df_e.iloc[:,0].tolist()

    for i in df_e.columns.values:
        st.write(' '.join(df_e.loc[:,i].tolist()))

    # å„å¤‰æ•°ã®å‹ã‚’é¸æŠã™ã‚‹ãŸã‚ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.write('Select variable types:')
    var_types = {}
    cols = st.columns(len(condition_col))
    for i, col in enumerate(condition_col):
        with cols[i]:
            var_types[col] = st.radio(
                f"{col}",
                options=["categorical", "continuous"],
                index=0,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«
                key=f"type_{col}"
            )
   
# modelã‚’ä½œã‚‹ãŸã‚ã®è¦ç´ ã‚’ãƒªã‚¹ãƒˆã«ã™ã‚‹
    comb = [':'.join(x) for x in  list(itertools.combinations(condition_col, 2))]
#ã“ã“ã§ ':'.joint(x)ã¨ã™ã‚‹ã¨ã€ã“ã®ã‚ã¨ã€ãƒ¢ãƒ‡ãƒ«ã‚’ä½œã‚‹ã¨ãã«:ä»¥é™ãŒé™¤ã‹ã‚Œã‚‹
    selections = selections = sum([condition_col, comb],[])

    null_model = st.checkbox("Null model as reduced model?", value = False, help="å¸°ç„¡ãƒ¢ãƒ‡ãƒ«ã‚’reduced modelã«ã™ã‚‹ã€‚ã¤ã¾ã‚Šfull modelã«è¨­å®šã—ãŸè¦å› ã®ã„ãšã‚Œã‹ï¼ã™ã¹ã¦ã«é–¢é€£ã—ãŸç™ºç¾å¤‰å‹•ã‚’æ¤œå‡ºã€‚")

    st.markdown("##### Select conditions for full model:")
    full = st.multiselect('fullmodel',selections, label_visibility = 'collapsed')

    # æœ€åˆã®å¤‰æ•°ã‚’æ™‚é–“å¤‰æ•°ã¨ã—ã¦ä¿å­˜
    time_var = None
    if len(full) > 0:
        time_var = full[0]
    #  st.write(time_var)

    if not null_model:
        st.markdown("##### Select conditions for reduced model:")
        reduced = st.multiselect('reducedmodel',selections, label_visibility = 'collapsed')
    else:
        reduced = []
    # å¤šé …å¼é©ç”¨ã®ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆDESeq2-LRTã€limmaã€GLMã§polynomialãŒTrueã®ã¨ãï¼‰
    polynomial_enabled = False
    if test_method == 'DESeq2-LRT' and add_polynomial and len(full) > 0 and time_var is not None:
        polynomial_enabled = True
        poly_degree = polynomial_degree
        poly_use_raw = use_raw
        poly_use_poly_function = use_poly_function
    elif test_method == 'limma eBayes' and limma_add_polynomial and len(full) > 0 and time_var is not None:
        polynomial_enabled = True
        poly_degree = limma_polynomial_degree
        poly_use_raw = limma_use_raw
        poly_use_poly_function = limma_use_poly_function
    elif test_method == 'Generalized Linear Model (GLM)' and glm_add_polynomial and len(full) > 0 and time_var is not None:
        polynomial_enabled = True
        poly_degree = glm_polynomial_degree
        poly_use_raw = glm_use_raw
        poly_use_poly_function = glm_use_poly_function
    
    if polynomial_enabled:
        
        if poly_use_poly_function:
            # poly()é–¢æ•°ã‚’ä½¿ã£ãŸå®Ÿè£…
            if poly_degree == 2:
                # raw=TRUEãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯è¿½åŠ 
                raw_param = ", raw=TRUE" if poly_use_raw else ""
                full[0] = f"poly({time_var}, degree=2{raw_param})"
            else:  # 3æ¬¡å¤šé …å¼
                raw_param = ", raw=TRUE" if poly_use_raw else ""
                full[0] = f"poly({time_var}, degree=3{raw_param})"
            
            st.markdown(f"##### Using {'raw' if poly_use_raw else 'orthogonal'} polynomial term for {time_var}: {full[0]}")
        else:
            # I()é–¢æ•°ã‚’ä½¿ã£ãŸå®Ÿè£…ï¼ˆæ˜ç¤ºçš„ãªã¹ãä¹—ï¼‰
            if poly_degree == 2:
                # å…ƒã®æ™‚é–“å¤‰æ•°ã‚’ç½®ãæ›ãˆã€2æ¬¡ã®é …ã‚’è¿½åŠ 
                new_terms = [time_var, f"I({time_var}^2)"]
                # fullã®æœ€åˆã®è¦ç´ ã‚’ç½®ãæ›ãˆ
                full[0] = new_terms[0]
                # 2æ¬¡ã®é …ã‚’æŒ¿å…¥
                full.insert(1, new_terms[1])
                
                st.markdown(f"##### Using explicit powers for {time_var}: {time_var} + I({time_var}^2)")
            else:  # 3æ¬¡å¤šé …å¼
                # å…ƒã®æ™‚é–“å¤‰æ•°ã‚’ç½®ãæ›ãˆã€2æ¬¡ã¨3æ¬¡ã®é …ã‚’è¿½åŠ 
                new_terms = [time_var, f"I({time_var}^2)", f"I({time_var}^3)"]
                # fullã®æœ€åˆã®è¦ç´ ã‚’ç½®ãæ›ãˆ
                full[0] = new_terms[0]
                # 2æ¬¡ã¨3æ¬¡ã®é …ã‚’æŒ¿å…¥
                full.insert(1, new_terms[1])
                full.insert(2, new_terms[2])
                
                st.markdown(f"##### Using explicit powers for {time_var}: {time_var} + I({time_var}^2) + I({time_var}^3)")


    full = [x.replace(':','\:') for x in full] # :ã®ã¾ã¾ã ã¨æ–‡å­—åˆ—ãŒæ¶ˆå¤±ã™ã‚‹
    reduced = [x.replace(':','\:') for x in reduced]

    if len(reduced) > 0 and not null_model:
        null_model = False

    full_model = "~ " + " + ".join(full)
    if null_model:
        reduced_model = "~ 1"
    elif len(reduced) == 0: #reducedã‚’æŒ‡å®šã—ã¦ã„ãªã„ã¨ãã¯null modelã«ã™ã‚‹
        reduced_model = "~ 1"
        st.markdown("#### Null model is uses as reduced model.")
    else:
        reduced_model = "~ " + " + ".join(reduced)
    st.markdown("##### Full model:  " + full_model)
    st.markdown("##### Reduced model:  " + reduced_model)
    st.markdown("""
Full modelã¨Reduced modelã¨ã®é•ã„ãŒæ¤œå®šã•ã‚Œã‚‹ã€‚
ä¾‹ãˆã°genotypã¨æ™‚ç³»åˆ—ã®ãƒ‡ãƒ¼ã‚¿ã®ã¨ãã«genptypeã¯é–¢ä¿‚ãªãã€æ™‚ç³»åˆ—å¤‰åŒ–ã‚’ã™ã‚‹éºä¼å­ã‚’æ¤œå‡ºã™ã‚‹å ´åˆã¯
~ genotype + time ã¨ ~ genotype ã®æ¯”è¼ƒã¨ãªã‚‹ã€‚\n
ã‚‚ã—ã€genotypeç‰¹ç•°çš„ã§æ™‚é–“ã§å¤‰åŒ–ã™ã‚‹éºä¼å­ã‚’æ¤œå‡ºã™ã‚‹å ´åˆã¯
~ genotype + time + genotype\:time ã¨ ~ genotype + time ã®æ¯”è¼ƒã¨ãªã‚‹ã€‚\n
\n
Reduced modelã«null modelã‚’è¨­å®šã™ã‚‹ã¨Full modelã®è¦å› ã§å¤‰åŒ–ã™ã‚‹éºä¼å­ã‚’æ¤œå‡ºã™ã‚‹ã€‚\n
ä¾‹ãˆã°WTã®ç´°èƒã®æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã ã‘ã®å ´åˆã€timeã‚’Full modelã«Null modelã‚’Reduced modelã«ã™ã‚‹ã€‚
        """)

    if (len(condition) != len(df.columns)):
            st.write("The number of group name does not match the data.")

#    df_condition = pd.DataFrame(condition)
#    df_batch = pd.DataFrame(batch)

# 1-Marãªã©ã®èª¤å¤‰æ›ã¸ã®å¯¾å¿œ
    check_excel_autoconversion(df)

    if len(df.index.values) != len(set(df.index.values)):
#        st.markdown("#### There are duplicated rows. Converting the names...")
#        st.write("The gene name of the second occurrence has _2 at the end.")
#        lis = df.index.values
#        df.index = [x + ['', '_2'][x in lis[0:i]] for i, x in enumerate(lis)]
        df = rename_duplicates(df)


    # å¤šé …å¼æ¬¡æ•°ãŒ1ã‚ˆã‚Šå¤§ãã„å ´åˆã®æ™‚é–“å¤‰æ•°ãƒã‚§ãƒƒã‚¯
    if (test_method == 'Beta Regression' and 'beta_polynomial_degree' in locals() and beta_polynomial_degree > 1) or (test_method == 'DESeq2-LRT' and 'add_polynomial' in locals() and add_polynomial) or (test_method == 'limma eBayes' and 'limma_add_polynomial' in locals() and limma_add_polynomial) or (test_method == 'Generalized Linear Model (GLM)' and 'glm_add_polynomial' in locals() and glm_add_polynomial):
        if len(full) > 0:
          #  st.write("Using polynomial")
            try:
                coldata_file = os.path.join(temp_dir, 'coldata.tsv')
                df_e.to_csv(coldata_file, sep='\t', index=False)
                coldata = pd.read_table(coldata_file)
                if time_var in coldata.columns:
                    # æ™‚é–“å¤‰æ•°ã®å‹ãƒã‚§ãƒƒã‚¯
                    time_col = coldata[time_var]
                    is_numeric = pd.api.types.is_numeric_dtype(time_col)
                    
                    if not is_numeric:
                        # æ•°å€¤ã«å¤‰æ›å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
                        try:
                            # æ•°å­—ã ã‘ã‚’æŠ½å‡ºã™ã‚‹æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³
                            numeric_values = time_col.str.extract(r'(\d+\.?\d*)')[0].astype(float)
                            st.info(f"æƒ…å ±: æ™‚é–“å¤‰æ•° '{time_var}' ã¯æ–‡å­—åˆ—ã§ã™ãŒã€æ•°å€¤ã¨ã—ã¦æŠ½å‡ºã§ãã¾ã™ã€‚è§£ææ™‚ã«è‡ªå‹•çš„ã«å¤‰æ›ã•ã‚Œã¾ã™ã€‚")
                            coldata[time_var] = numeric_values #coldataã‚’å¤‰ãˆã¦ãŠã
                            
                            # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒã‚¤ãƒ³ãƒˆæ•°ãƒã‚§ãƒƒã‚¯
                            unique_points = len(numeric_values.unique())
                            
                            # å¤šé …å¼æ¬¡æ•°ã®ãƒã‚§ãƒƒã‚¯
                            current_poly_degree = None
                            if test_method == 'Beta Regression' and 'beta_polynomial_degree' in locals():
                                current_poly_degree = beta_polynomial_degree
                            elif test_method == 'DESeq2-LRT' and 'polynomial_degree' in locals():
                                current_poly_degree = polynomial_degree
                            elif test_method == 'limma eBayes' and 'limma_polynomial_degree' in locals():
                                current_poly_degree = limma_polynomial_degree
                            elif test_method == 'Generalized Linear Model (GLM)' and 'glm_polynomial_degree' in locals():
                                current_poly_degree = glm_polynomial_degree
                            
                            if current_poly_degree and current_poly_degree >= unique_points:
                                st.error(f"ã‚¨ãƒ©ãƒ¼: å¤šé …å¼ã®æ¬¡æ•°ï¼ˆ{current_poly_degree}ï¼‰ãŒãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚¿ã‚¤ãƒ ãƒã‚¤ãƒ³ãƒˆæ•°ï¼ˆ{unique_points}ï¼‰ä»¥ä¸Šã§ã™ã€‚")
                                st.error(f"ã‚ãªãŸã®ãƒ‡ãƒ¼ã‚¿ã§ä½¿ç”¨å¯èƒ½ãªæœ€å¤§æ¬¡æ•°: {unique_points - 1}")
                                st.error(f"ã‚¿ã‚¤ãƒ ãƒã‚¤ãƒ³ãƒˆ: {sorted(numeric_values.unique())}")
                                st.stop()
                                
                        except:
                            current_poly_degree = None
                            if test_method == 'Beta Regression' and 'beta_polynomial_degree' in locals():
                                current_poly_degree = beta_polynomial_degree
                            elif test_method == 'DESeq2-LRT' and 'polynomial_degree' in locals():
                                current_poly_degree = polynomial_degree
                            elif test_method == 'limma eBayes' and 'limma_polynomial_degree' in locals():
                                current_poly_degree = limma_polynomial_degree
                            elif test_method == 'Generalized Linear Model (GLM)' and 'glm_polynomial_degree' in locals():
                                current_poly_degree = glm_polynomial_degree
                                
                            if current_poly_degree:
                                st.warning(f"è­¦å‘Š: æ™‚é–“å¤‰æ•° '{time_var}' ã¯æ•°å€¤ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚å¤šé …å¼ãƒ¢ãƒ‡ãƒ«ï¼ˆæ¬¡æ•°{current_poly_degree}ï¼‰ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯æ•°å€¤ãŒå¿…è¦ã§ã™ã€‚ãƒ¢ãƒ‡ãƒ«ãŒåæŸã—ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
                else:
                    st.warning(f"è­¦å‘Š: æ™‚é–“å¤‰æ•° '{time_var}' ãŒå®Ÿé¨“ãƒ‡ã‚¶ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            except Exception as e:
                st.warning(f"å®Ÿé¨“ãƒ‡ã‚¶ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

    st.markdown("""
--------------------------------------------------------------------------
        """)
    if st.button('Run analysis'):
        #ã¾ãšRã®dfã«å¤‰æ›
        if test_method == 'DESeq2-LRT':
    #        ro.r.assign('cts',cts) # ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹ã®ã§ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¸€æ—¦ä¿å­˜ã™ã‚‹
            r.assign('df',df)
            r.assign('df_e',df_e)

            # å¤‰æ•°ã‚¿ã‚¤ãƒ—æƒ…å ±ã‚’Rå´ã«æ¸¡ã™
            continuous_vars = [col for col in condition_col if var_types[col] == "continuous"]
            r_continuous_vars = ro.StrVector(continuous_vars)
            ro.r.assign('continuous_vars', r_continuous_vars)

            pyper_df_path = "saveRDS(df, '" + temp_dir + "/pyper_df.RDS')"
            r(pyper_df_path)
            pyper_df_e_path = "saveRDS(df_e, '" + temp_dir + "/pyper_df_e.RDS')"
            r(pyper_df_e_path)
            read_pyper_df = "cts <- readRDS('" + temp_dir + "/pyper_df.RDS')"
            read_pyper_df_e = "coldata <- readRDS('" + temp_dir + "/pyper_df_e.RDS')"
            ro.r(read_pyper_df)
            ro.r(read_pyper_df_e)
            #ã¾ãšãƒ™ã‚¯ã‚¿ãƒ¼ã«å¤‰æ›
            r_condition =  ro.StrVector(condition)
            ro.r.assign('condition', r_condition)
            full_model = full_model.replace('\:',':')
            reduced_model = reduced_model.replace('\:',':')
            ro.r.assign('full_model', full_model)
            ro.r.assign('reduced_model', reduced_model)
            ro.r.assign('sva',sva)
            ro.r.assign('sva_calc', sva_calc)
            ro.r.assign('independentFiltering', independentFiltering)
            ro.r.assign('res_dir', res_dir)
            ro.r.assign('temp_dir', temp_dir)

            if 'add_polynomial' in locals() and add_polynomial:
                # å¤‰æ•°ã‚’Rã«æ¸¡ã™
                if len(full) > 0:
                    polynomial_variable = full[0]
                    ro.r.assign('add_polynomial', True)
                    ro.r.assign('polynomial_degree', polynomial_degree)
                    ro.r.assign('polynomial_variable', polynomial_variable)
                    ro.r.assign('use_raw', use_raw)
                    ro.r.assign('use_poly_function', use_poly_function)
                    #counts_file = os.path.join(temp_dir, 'counts.tsv')
                    #df.to_csv(counts_file, sep='\t')

                else:
                    st.error("Cannot use polynomial terms: full model is empty")
                    ro.r.assign('add_polynomial', False)
            else:
                ro.r.assign('add_polynomial', False)

            with st.spinner('Calculating DESeq2...'):
                ro.r('calc_dds_LRT()')


            image = Image.open(res_dir + '/DispersionEstimates.png')
            st.image(image, caption='Despersion Estimates')

            res_df = pd.read_csv(res_dir + '/DESeq2_LRT_res.tsv', sep = '\t', index_col= 0)
            st.write("FDR < 0.05: " + str(len(res_df.loc[(res_df['padj']<0.05),])))

            res_df= res_df.loc[(res_df['padj']<0.1),'padj']
            st.dataframe(res_df)
            if sva:
                st.markdown("#### =======SVA=======")
                with st.spinner('Preparing SVAseq...'):
                    sva_n = ro.r("sv_n <- calc_sva_n()")
                st.write("Recommended number of SVA covariates: " + str(int(sva_n[0])))
                with st.spinner('Calculating SVAseq...'):
                    ro.r("calc_svseq_LRT()")

            if sva:
                st.session_state.deseq2lrt = read_csv(res_dir + "/SVA_LRT_res.tsv", sep = '\t', index_col=0)
            else:
                st.session_state.deseq2lrt = read_csv(res_dir + "/DESeq2_LRT_res.tsv", sep = '\t', index_col=0)


            file_name = file_name_head + full_model.replace(" + ", "_").replace(" ", "") + "_vs_" + reduced_model.replace(" + ", "_").replace(" ", "")

            shutil.make_archive("res", format='zip',root_dir= res_dir)

        elif test_method == 'limma eBayes':
            # Save input to files for R import
            counts_file = os.path.join(temp_dir, 'counts.tsv')
            df.to_csv(counts_file, sep='\t')
            coldata_file = os.path.join(temp_dir, 'coldata.tsv')
            df_e.to_csv(coldata_file, sep='\t', index=False)

            voom_plot_path = os.path.join(res_dir, 'voom_plot.png')
        #    if os.path.exists(voom_plot_path):
        #        os.remove(voom_plot_path)

            ro.r.assign('temp_dir', temp_dir)
            
            # å¤‰æ•°ã‚¿ã‚¤ãƒ—æƒ…å ±ã‚’Rå´ã«æ¸¡ã™
            continuous_vars = [col for col in condition_col if var_types[col] == "continuous"]
            r_continuous_vars = ro.StrVector(continuous_vars)
            ro.r.assign('continuous_vars', r_continuous_vars)
            
            # polynomialé–¢é€£ã®å¤‰æ•°ã‚’Rã«æ¸¡ã™
            if 'limma_add_polynomial' in locals() and limma_add_polynomial and len(full) > 0:
                polynomial_variable = full[0]
                ro.r.assign('add_polynomial', True)
                ro.r.assign('polynomial_degree', limma_polynomial_degree)
                ro.r.assign('polynomial_variable', polynomial_variable)
                ro.r.assign('use_raw', limma_use_raw)
                ro.r.assign('use_poly_function', limma_use_poly_function)
            else:
                ro.r.assign('add_polynomial', False)
            
            if apply_logit:
                # For logit-transformed data, use this R code
                r_code = f"""
                sink()
                sink(paste0(temp_dir, "/limma_output.txt"))
                library(limma)
                counts <- read.table('{counts_file}', header=TRUE, row.names=1, sep='\t')
                coldata <- read.table('{coldata_file}', header=TRUE, sep='\t')
                
                # For logit transformed data, apply the transformation in R instead
                eps <- 1e-6
                counts <- pmax(counts, eps)
                counts <- pmin(counts, 1-eps)
                counts <- log(counts/(1-counts))
                
                # Create design matrices
                design_full <- model.matrix(as.formula('{full_model}'), data=coldata)
                design_reduced <- model.matrix(as.formula('{reduced_model}'), data=coldata)
                
                # Identify coefficients specific to the full model
                add_coefs <- setdiff(colnames(design_full), colnames(design_reduced))
                
                # For logit-transformed data, skip voom and directly fit with limma
                fit_full <- lmFit(counts, design_full)
                fit_full <- eBayes(fit_full)
                
                if (length(add_coefs) == 1) {{
                  res <- topTable(fit_full, coef=add_coefs, number=Inf, adjust.method='fdr')
                }} else {{
                  cm <- matrix(0, nrow=ncol(design_full), ncol=length(add_coefs))
                  colnames(cm) <- add_coefs
                  for (i in 1:length(add_coefs)) {{
                    cm[which(colnames(design_full) == add_coefs[i]), i] <- 1
                  }}
                  
                  fit_contrast <- contrasts.fit(fit_full, cm)
                  fit_contrast <- eBayes(fit_contrast)
                  
                  res <- topTable(fit_contrast, number=Inf, sort.by='F', adjust.method='fdr')
                }}
                write.table(res, file='{res_dir}/limma_res.tsv', sep='\t', quote=FALSE, col.names=NA)
                sink()
                """
            elif limma_count:
                # For regular count data, use the original approach
                ro.r.assign('independentFiltering', independentFiltering)

                log_file = f"{res_dir}/limma_debug.log"
                ro.r.assign('log_file', log_file)

                r_code = f"""

                # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ
                sink('{log_file}', append=FALSE, split=TRUE)
                library(edgeR)
                library(limma)
                tryCatch({{
                    counts <- read.table('{counts_file}', header=TRUE, row.names=1, sep='\t')

                    # é‡è¦: ã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ•´æ•°å¤‰æ›ã‚’ç¢ºèª
                    counts <- round(counts)  # å®Ÿæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä½¿ã†å ´åˆã¯æ•´æ•°ã«å¤‰æ›

                    coldata <- read.table('{coldata_file}', header=TRUE, sep='\t')
                    y <- DGEList(counts=counts)


                    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
                    if (independentFiltering) {{
                        keep <- filterByExpr(y, design=model.matrix(as.formula('{full_model}'), data=coldata))
                        y <- y[keep, ]
                    }}

                    # æ­£è¦åŒ–
                    y <- calcNormFactors(y)

                    design_full <- model.matrix(as.formula('{full_model}'), data=coldata)
                    design_reduced <- model.matrix(as.formula('{reduced_model}'), data=coldata)
                    
                    add_coefs <- setdiff(colnames(design_full), colnames(design_reduced))
                    
                    png('{res_dir}/voom_plot.png')
                    v <- voom(y, design_full, plot=TRUE)
                    dev.off()

                    # voomçµæœç¢ºèª
                    print("Post-voom data:")
                    print(dim(v$E))
                    print(range(v$E))
                    
                    fit_full <- lmFit(v, design_full)
                    fit_full <- eBayes(fit_full)
                    
                    if (length(add_coefs) == 1) {{
                      res <- topTable(fit_full, coef=add_coefs, number=Inf, adjust.method='fdr')
                    }} else {{
                      cm <- matrix(0, nrow=ncol(design_full), ncol=length(add_coefs))
                      colnames(cm) <- add_coefs
                      for (i in 1:length(add_coefs)) {{
                        cm[which(colnames(design_full) == add_coefs[i]), i] <- 1
                      }}
                      
                      fit_contrast <- contrasts.fit(fit_full, cm)
                      fit_contrast <- eBayes(fit_contrast)
                      
                      res <- topTable(fit_contrast, number=Inf, sort.by='F', adjust.method='fdr')
                    }}
                    write.table(res, file='{res_dir}/limma_res.tsv', sep='\t', quote=FALSE,  col.names=NA)

                    }}, error = function(e) {{
                        cat("\\n===== ERROR =====\\n")
                        cat("Error in limma analysis:", conditionMessage(e), "\\n")
                        cat("Error occurred at:", format(Sys.time(), "%Y-%m-%d %H:%M:%S"), "\\n")
                        traceback()
                    }}, finally = {{
                        cat("\\n===== ANALYSIS COMPLETE =====\\n")
                        cat("Time:", format(Sys.time(), "%Y-%m-%d %H:%M:%S"), "\\n")
                        # sinkã‚’è§£é™¤
                        sink()
                    }})

                """

                st.write(f"{res_dir}/voom_plot.png")
                st.image(f"{res_dir}/voom_plot.png", caption='Voom mean-variance trend')

            else:
                r_code = f"""
                sink()
                sink(paste0(temp_dir, "/limma_output.txt"))
                library(limma)
                counts <- read.table('{counts_file}', header=TRUE, row.names=1, sep='\t')
                coldata <- read.table('{coldata_file}', header=TRUE, sep='\t')

                design_full <- model.matrix(as.formula('{full_model}'), data=coldata)
                design_reduced <- model.matrix(as.formula('{reduced_model}'), data=coldata)

                add_coefs <- setdiff(colnames(design_full), colnames(design_reduced))

                # éã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ãªã®ã§voomã¯ã‚¹ã‚­ãƒƒãƒ—
                fit_full <- lmFit(counts, design_full)
                fit_full <- eBayes(fit_full)

                if (length(add_coefs) == 1) {{
                  res <- topTable(fit_full, coef=add_coefs, number=Inf, adjust.method='fdr')
                }} else {{
                  cm <- matrix(0, nrow=ncol(design_full), ncol=length(add_coefs))
                  colnames(cm) <- add_coefs
                  for (i in 1:length(add_coefs)) {{
                    cm[which(colnames(design_full) == add_coefs[i]), i] <- 1
                  }}
                  
                  fit_contrast <- contrasts.fit(fit_full, cm)
                  fit_contrast <- eBayes(fit_contrast)
                  
                  res <- topTable(fit_contrast, number=Inf, sort.by='F', adjust.method='fdr')
                }}
                write.table(res, file='{res_dir}/limma_res.tsv', sep='\t', quote=FALSE, col.names=NA)
                sink()
                """

            ro.r(r_code)
            res_df = pd.read_csv(os.path.join(res_dir, 'limma_res.tsv'), sep='\t', index_col=0)
            st.write(f"Significant (FDR<0.05): {(res_df['adj.P.Val']<0.05).sum()}")
            st.dataframe(res_df)

            file_name = file_name_head + "_limma_" + full_model.replace(" + ", "_").replace(" ", "") + "_vs_" + reduced_model.replace(" + ", "_").replace(" ", "")

            shutil.make_archive("res", format='zip',root_dir= res_dir)


        elif test_method == 'Beta Regression':

            # ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜ã¨è¨­å®šã¯åŒã˜
            counts_file = os.path.join(temp_dir, 'counts.tsv')
            df.to_csv(counts_file, sep='\t')
            coldata_file = os.path.join(temp_dir, 'coldata.tsv')
            df_e.to_csv(coldata_file, sep='\t', index=False)

            ro.r.assign('temp_dir', temp_dir)


            r_code = f"""
            sink()
            sink(paste0(temp_dir, "/beta_output.txt"))
            library(betareg)
            library(lmtest)
            library(parallel)

            counts <- read.table('{counts_file}', header=TRUE, row.names=1, sep='\t')
            coldata <- read.table('{coldata_file}', header=TRUE, sep='\t')

            # 0-1ã®å¢ƒç•Œã®èª¿æ•´
            eps <- {epsilon}
            counts <- pmax(pmin(counts, 1-eps), eps)

            # ä¸¦åˆ—å‡¦ç†ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®è¨­å®š
            n_cores <- {n_cores}
            cl <- makeCluster(n_cores)

            # ä¸¦åˆ—å‡¦ç†ã«å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã«èª­ã¿è¾¼ã¿
            clusterEvalQ(cl, {{
              library(betareg)
              library(lmtest)
            }})

            time_var <- "{full[0]}"
            cat("time_var")
            cat(time_var)

            # æ™‚é–“å¤‰æ•°ã®ç¢ºèªã¨å¤‰æ›
            if(time_var %in% colnames(coldata)) {{
              cat("Time variable exists in coldata. Values:", "\\n")
              print(coldata[[time_var]])
              
              # æ™‚é–“å¤‰æ•°ãŒæ•°å€¤ã§ãªã„å ´åˆã¯å¤‰æ›
              if(!is.numeric(coldata[[time_var]])) {{
                cat("Converting time variable to numeric\\n")
                # æ•°å€¤æŠ½å‡ºã¨å¤‰æ›
                coldata[[time_var]] <- as.numeric(gsub("[^0-9.]", "", as.character(coldata[[time_var]])))
                cat("After conversion:", "\\n")
                print(coldata[[time_var]])
              }}
            }} else {{
              cat("WARNING: Time variable not found in coldata!\\n")
            }}

            coldata[[time_var]] <- coldata[[time_var]] / max(coldata[[time_var]]) #æœ€å¤§å€¤ã«ã‚ˆã‚‹normalization

            # å¤šé …å¼ã®æ¬¡æ•°ã«åŸºã¥ãé …ã‚’æ§‹ç¯‰
            polynomial_terms <- ""
            if ({beta_polynomial_degree} >= 2) {{
              polynomial_terms <- paste0(polynomial_terms, " + I(", time_var, "^2)")
            }}
            if ({beta_polynomial_degree} >= 3) {{
              polynomial_terms <- paste0(polynomial_terms, " + I(", time_var, "^3)")
            }}

            # å¤‰æ•°ã‚’ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã«é€ä¿¡
            clusterExport(cl, c("counts", "coldata", "eps", "time_var", "polynomial_terms"))

            # å‡¦ç†é–‹å§‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            cat("Starting parallel beta regression on", n_cores, "cores for", nrow(counts), "genes\\n")

            # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«å®Ÿè¡Œ
            test_model_result <- tryCatch({{
              # ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ‡ãƒ¼ã‚¿
              test_gene_data <- data.frame(y=as.numeric(counts[1,]), coldata)
              
              # ãƒ•ã‚©ãƒ¼ãƒŸãƒ¥ãƒ©ã‚’æ§‹ç¯‰
              full_formula <- paste("{full_model.replace('~', '')}", polynomial_terms)
              
              # ãƒ¢ãƒ‡ãƒ«é©åˆã‚’è©¦è¡Œ
              test_fit <- betareg(as.formula(paste("y ~", full_formula)), data=test_gene_data)
              "success"
            }}, error=function(e) {{
              # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™
              return(conditionMessage(e))
            }})

            # ã‚¨ãƒ©ãƒ¼ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼åˆæœŸåŒ–
            error_counter <- 0
            error_message <- ""

            # ä¸¦åˆ—å‡¦ç†é–¢æ•°
            process_gene <- function(i) {{
              gene_data <- data.frame(y=as.numeric(counts[i,]), coldata)
              
              full_formula <- paste("{full_model.replace('~', '')}", polynomial_terms)
              reduced_formula <- "{reduced_model.replace('~', '')}"
              
              tryCatch({{
                # ãƒ•ãƒ«ãƒ¢ãƒ‡ãƒ«ã¨ãƒªãƒ‡ãƒ¥ãƒ¼ã‚¹ãƒ‰ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°
                full_fit <- betareg(as.formula(paste("y ~", full_formula)), data=gene_data)
                reduced_fit <- betareg(as.formula(paste("y ~", reduced_formula)), data=gene_data)
                
                # å°¤åº¦æ¯”æ¤œå®š
                lr_test <- lrtest(reduced_fit, full_fit)
                
                # çµæœã‚’è¿”ã™
                c(statistic = lr_test$Chisq[2],
                  df = lr_test$Df[2],
                  p_value = lr_test$`Pr(>Chisq)`[2],
                  logLik_diff = lr_test$LogLik[2] - lr_test$LogLik[1])
              }}, error=function(e) {{
                # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯NAã‚’è¿”ã™
                if (i <= 5) cat("Gene", i, "Error:", conditionMessage(e), "\\n")
                c(statistic = NA, df = NA, p_value = NA, logLik_diff = NA)
              }})
            }}

            # ä¸¦åˆ—å‡¦ç†ã®å®Ÿè¡Œ
            system.time(
              results_list <- parLapply(cl, 1:nrow(counts), process_gene)
            )

            # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®çµ‚äº†
            stopCluster(cl)

            # çµæœã‚’ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã«å¤‰æ›
            results_matrix <- do.call(rbind, results_list)
            rownames(results_matrix) <- rownames(counts)

            # NULLã®æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
            na_count <- sum(is.na(results_matrix[, "statistic"]))
            total_genes <- nrow(results_matrix)
            na_percent <- round(100 * na_count / total_genes, 2)

            # çµæœãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’è¿½åŠ 
            cat("\\n### ãƒ¢ãƒ‡ãƒ«åæŸæƒ…å ± ###\\n", file='{res_dir}/model_convergence_info.txt')
            cat("å¤šé …å¼æ¬¡æ•°:", {beta_polynomial_degree}, "\\n", file='{res_dir}/model_convergence_info.txt', append=TRUE)
            cat("ãƒ•ãƒ«ãƒ¢ãƒ‡ãƒ«å¼:", paste("y ~", paste("{full_model.replace('~', '')}", polynomial_terms)), "\\n", file='{res_dir}/model_convergence_info.txt', append=TRUE)
            cat("ç¸®å°ãƒ¢ãƒ‡ãƒ«å¼:", paste("y ~", "{reduced_model.replace('~', '')}"), "\\n", file='{res_dir}/model_convergence_info.txt', append=TRUE)

            if (na_count > 0) {{
              cat("è­¦å‘Š: ", na_count, " å€‹ã®éºä¼å­ (", na_percent, "%) ã§ãƒ¢ãƒ‡ãƒ«ãŒåæŸã—ã¾ã›ã‚“ã§ã—ãŸã€‚\\n", file='{res_dir}/model_convergence_info.txt', append=TRUE)
              
              if (na_count == total_genes) {{
                cat("ã™ã¹ã¦ã®éºä¼å­ã§ãƒ¢ãƒ‡ãƒ«ãŒåæŸã—ã¾ã›ã‚“ã§ã—ãŸã€‚å¤šé …å¼æ¬¡æ•°ã‚’ä¸‹ã’ã‚‹ã€æ™‚é–“å¤‰æ•°ã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°(ç¾åœ¨æœ€å¤§å€¤ã§ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã—ã¦ã‚ã‚‹)ã€ä¸å‡ç­‰ã®æ™‚é–“ã‚’å‡ç­‰åŒ–ã™ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚\\n", file='{res_dir}/model_convergence_info.txt', append=TRUE)
                cat("ãƒ†ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®ã‚¨ãƒ©ãƒ¼: ", test_model_result, "\\n", file='{res_dir}/model_convergence_info.txt', append=TRUE)
              }} else {{
                cat(total_genes - na_count, " å€‹ã®éºä¼å­ (", 100 - na_percent, "%) ã§æ­£å¸¸ã«è§£æã§ãã¾ã—ãŸã€‚\\n", file='{res_dir}/model_convergence_info.txt', append=TRUE)
              }}
            }} else {{
              cat("ã™ã¹ã¦ã®éºä¼å­ã§æ­£å¸¸ã«ãƒ¢ãƒ‡ãƒ«ãŒåæŸã—ã¾ã—ãŸã€‚\\n", file='{res_dir}/model_convergence_info.txt', append=TRUE)
            }}

            # å¤šé‡æ¤œå®šè£œæ­£
            results_matrix <- cbind(results_matrix, 
                                  adj.P.Val = p.adjust(results_matrix[, "p_value"], method="BH"))

            # çµæœã®ä¿å­˜
            res_df <- as.data.frame(results_matrix)
            res_df <- res_df[order(res_df$p_value), ]
            write.table(res_df, file='{res_dir}/betareg_res.tsv', sep='\\t', quote=FALSE, col.names=NA)
            sink()
            """

        elif test_method == 'Generalized Linear Model (GLM)':
            # ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜ã¨è¨­å®š
            counts_file = os.path.join(temp_dir, 'counts.tsv')
            df.to_csv(counts_file, sep='\t')
            coldata_file = os.path.join(temp_dir, 'coldata.tsv')
            df_e.to_csv(coldata_file, sep='\t', index=False)

            ro.r.assign('temp_dir', temp_dir)
            
            # å¤‰æ•°ã‚¿ã‚¤ãƒ—æƒ…å ±ã‚’Rå´ã«æ¸¡ã™
            continuous_vars = [col for col in condition_col if var_types[col] == "continuous"]
            r_continuous_vars = ro.StrVector(continuous_vars)
            ro.r.assign('continuous_vars', r_continuous_vars)
            
            # polynomialé–¢é€£ã®å¤‰æ•°ã‚’Rã«æ¸¡ã™
            if 'glm_add_polynomial' in locals() and glm_add_polynomial and len(full) > 0:
                polynomial_variable = full[0]
                ro.r.assign('add_polynomial', True)
                ro.r.assign('polynomial_degree', glm_polynomial_degree)
                ro.r.assign('polynomial_variable', polynomial_variable)
                ro.r.assign('use_raw', glm_use_raw)
                ro.r.assign('use_poly_function', glm_use_poly_function)
            else:
                ro.r.assign('add_polynomial', False)

            r_code = f"""
            sink()
            sink(paste0(temp_dir, "/glm_output.txt"))
            library(parallel)

            counts <- read.table('{counts_file}', header=TRUE, row.names=1, sep='\t')
            coldata <- read.table('{coldata_file}', header=TRUE, sep='\t')

            # é€£ç¶šå¤‰æ•°ã‚’å‡¦ç†
            if (exists("continuous_vars") && length(continuous_vars) > 0) {{
                cat("Processing continuous variables...\\n")
                for (col_name in continuous_vars) {{
                    if (col_name %in% colnames(coldata)) {{
                        cat(paste0("Treating '", col_name, "' as continuous variable\\n"))
                        if (!is.numeric(coldata[[col_name]])) {{
                            original_values <- coldata[[col_name]]
                            numeric_values <- as.numeric(gsub("[^0-9.]", "", as.character(original_values)))
                            if (any(is.na(numeric_values))) {{
                                warning(paste0("Cannot convert '", col_name, "' to numeric. Using as factor."))
                                coldata[[col_name]] <- factor(coldata[[col_name]])
                            }} else {{
                                coldata[[col_name]] <- numeric_values
                                cat(paste0("Converted '", col_name, "' to numeric values: ", 
                                         paste(head(numeric_values), collapse=", "), "...\\n"))
                            }}
                        }}
                    }}
                }}
            }}

            # æ®‹ã‚Šã®å¤‰æ•°ã‚’å› å­å‹ã«å¤‰æ›ï¼ˆé€£ç¶šå¤‰æ•°ä»¥å¤–ï¼‰
            for (i in c(1:dim(coldata)[2])) {{
                col_name <- colnames(coldata)[i]
                if (!exists("continuous_vars") || !(col_name %in% continuous_vars)) {{
                    cat(paste0("Treating '", col_name, "' as categorical variable\\n"))
                    coldata[,i] <- factor(coldata[,i])
                }}
            }}

            # åˆ†å¸ƒãƒ•ã‚¡ãƒŸãƒªãƒ¼ã«å¿œã˜ãŸãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
            if ("{glm_dist_short}" == "beta") {{
                # 0-1ã®å¢ƒç•Œã®èª¿æ•´
                eps <- {glm_epsilon}
                counts <- pmax(pmin(counts, 1-eps), eps)
            }} else if ("{glm_dist_short}" == "gaussian") {{
                # ã‚¬ã‚¦ã‚¹ã®å ´åˆã¯ç‰¹ã«å‰å‡¦ç†ä¸è¦
            }} else if ("{glm_dist_short}" == "poisson" || "{glm_dist_short}" == "nb") {{
                # ãƒã‚¢ã‚½ãƒ³ã¨NBã¯ã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æƒ³å®šï¼ˆæ•´æ•°åŒ–ï¼‰
                counts <- round(counts)
            }}

            # åˆ†å¸ƒãƒ•ã‚¡ãƒŸãƒªãƒ¼ã®è¨­å®šé–¢æ•°
            get_family <- function() {{
                if ("{glm_dist_short}" == "beta") {{
                    # Betaã®å ´åˆã¯betaregãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ä½¿ç”¨
                    library(betareg)
                    if ("{glm_link}" == "logit") {{
                        return(list(family = "beta", link = "logit"))
                    }} else if ("{glm_link}" == "probit") {{
                        return(list(family = "beta", link = "probit"))
                    }} else if ("{glm_link}" == "cloglog") {{
                        return(list(family = "beta", link = "cloglog"))
                    }}
                }} else if ("{glm_dist_short}" == "gaussian") {{
                    if ("{glm_link}" == "identity") {{
                        return(gaussian(link = "identity"))
                    }} else if ("{glm_link}" == "log") {{
                        return(gaussian(link = "log"))
                    }} else if ("{glm_link}" == "inverse") {{
                        return(gaussian(link = "inverse"))
                    }}
                }} else if ("{glm_dist_short}" == "poisson") {{
                    if ("{glm_link}" == "log") {{
                        return(poisson(link = "log"))
                    }} else if ("{glm_link}" == "identity") {{
                        return(poisson(link = "identity"))
                    }} else if ("{glm_link}" == "sqrt") {{
                        return(poisson(link = "sqrt"))
                    }}
                }} else if ("{glm_dist_short}" == "nb") {{
                    library(MASS)
                    if ("{glm_link}" == "log") {{
                        return(negative.binomial(theta = {glm_nb_theta if glm_nb_theta else 1}, link = "log"))
                    }} else if ("{glm_link}" == "identity") {{
                        return(negative.binomial(theta = {glm_nb_theta if glm_nb_theta else 1}, link = "identity"))
                    }} else if ("{glm_link}" == "sqrt") {{
                        return(negative.binomial(theta = {glm_nb_theta if glm_nb_theta else 1}, link = "sqrt"))
                    }}
                }}
            }}

            # ä¸¦åˆ—ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®è¨­å®š
            n_cores <- {n_cores}
            cl <- makeCluster(n_cores)

            # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã«å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã¨ãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡
            clusterEvalQ(cl, {{
                library(MASS)
                if ("{glm_dist_short}" == "beta") {{
                    library(betareg)
                    library(lmtest)
                }}
            }})

            clusterExport(cl, c("counts", "coldata", "get_family"))

            # å‡¦ç†é–¢æ•°
            process_gene <- function(i) {{
                gene_data <- data.frame(y=as.numeric(counts[i,]), coldata)
                family_to_use <- get_family()
                
                result <- tryCatch({{
                    if ("{glm_dist_short}" == "beta") {{
                        # Betaå›å¸°ã®å ´åˆã¯betaregãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ä½¿ç”¨
                        library(betareg)
                        full_fit <- betareg(as.formula("{full_model}"), 
                                          data=gene_data, 
                                          link=family_to_use$link)
                        reduced_fit <- betareg(as.formula("{reduced_model}"), 
                                             data=gene_data, 
                                             link=family_to_use$link)
                        
                        # å°¤åº¦æ¯”æ¤œå®š
                        library(lmtest)
                        lr_test <- lrtest(reduced_fit, full_fit)
                        
                        # çµæœã‚’è¿”ã™
                        c(statistic = lr_test$Chisq[2],
                          df = lr_test$Df[2],
                          p_value = lr_test$`Pr(>Chisq)`[2],
                          logLik_diff = lr_test$LogLik[2] - lr_test$LogLik[1])
                    }} else {{
                        # é€šå¸¸ã®GLMã®å ´åˆ
                        full_fit <- glm(as.formula("{full_model}"), family=family_to_use, data=gene_data)
                        reduced_fit <- glm(as.formula("{reduced_model}"), family=family_to_use, data=gene_data)
                        
                        # å°¤åº¦æ¯”æ¤œå®š
                        anova_result <- anova(reduced_fit, full_fit, test="LRT")
                        
                        # çµæœã‚’è¿”ã™
                        c(statistic = anova_result$Deviance[2],
                          df = anova_result$Df[2],
                          p_value = anova_result$`Pr(>Chi)`[2],
                          logLik_diff = logLik(full_fit) - logLik(reduced_fit))
                    }}
                }}, error=function(e) {{
                    # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯NAã‚’è¿”ã™
                    if (i <= 5) cat("Gene", i, "Error:", conditionMessage(e), "\\n")
                    c(statistic = NA, df = NA, p_value = NA, logLik_diff = NA)
                }})
                
                return(result)
            }}

            # ä¸¦åˆ—å‡¦ç†ã®å®Ÿè¡Œ
            cat("Starting parallel GLM regression on", n_cores, "cores for", nrow(counts), "genes\\n")
            cat("Using distribution family:", "{glm_dist_family}", "\\n")
            system.time(
                results_list <- parLapply(cl, 1:nrow(counts), process_gene)
            )

            # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®çµ‚äº†
            stopCluster(cl)

            # çµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
            results_matrix <- do.call(rbind, results_list)
            results <- as.data.frame(results_matrix)
            rownames(results) <- rownames(counts)

            # NAã®æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
            na_count <- sum(is.na(results$statistic))
            if (na_count > 0) {{
                cat("è­¦å‘Š:", na_count, "å€‹ã®éºä¼å­ã§ãƒ¢ãƒ‡ãƒ«ãŒåæŸã—ã¾ã›ã‚“ã§ã—ãŸ (", 
                    round(100 * na_count / nrow(results), 2), "%)\\n")
            }}

            # å¤šé‡æ¤œå®šè£œæ­£
            results$adj.P.Val <- p.adjust(results$p_value, method="BH")

            # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã®ä¿å­˜
            cat("\\n### GLMãƒ¢ãƒ‡ãƒ«æƒ…å ± ###\\n", file='{res_dir}/glm_model_info.txt')
            cat("åˆ†å¸ƒãƒ•ã‚¡ãƒŸãƒªãƒ¼:", "{glm_dist_family}", "\\n", file='{res_dir}/glm_model_info.txt', append=TRUE)
            cat("ãƒªãƒ³ã‚¯é–¢æ•°:", "{glm_link}", "\\n", file='{res_dir}/glm_model_info.txt', append=TRUE)
            cat("ãƒ•ãƒ«GLMãƒ¢ãƒ‡ãƒ«å¼:", "{full_model}", "\\n", file='{res_dir}/glm_model_info.txt', append=TRUE)
            cat("ç¸®å°GLMãƒ¢ãƒ‡ãƒ«å¼:", "{reduced_model}", "\\n", file='{res_dir}/glm_model_info.txt', append=TRUE)

            # çµæœã‚’ä¿å­˜
            write.table(results[order(results$p_value), ], 
                        file='{res_dir}/glm_{glm_dist_short}_{glm_link}_res.tsv', 
                        sep='\\t', quote=FALSE, col.names=NA)

            cat("GLM regression analysis completed\\n")
            sink()
            """

        elif test_method == 'Generalized Additive Model (GAM)':
            ro.r.assign('beta_normalization', beta_normalization)
            ro.r.assign('spline_type', spline_type)
            if dist_short == "nb":
                ro.r.assign('nb_theta', nb_theta)
            ro.r.assign('dist_short', dist_short)
            # Save input to files for R import
            counts_file = os.path.join(temp_dir, 'counts.tsv')
            df.to_csv(counts_file, sep='\t')
            coldata_file = os.path.join(temp_dir, 'coldata.tsv')
            df_e.to_csv(coldata_file, sep='\t', index=False)
            ro.r.assign('temp_dir', temp_dir)


            # æ›´æ–°ã•ã‚ŒãŸGAM Rã‚³ãƒ¼ãƒ‰
            r_code = f"""
                sink()
                sink(paste0({temp_dir}, "/GAM_output.txt"))
                library(mgcv)
                library(lmtest)
                library(parallel)

                counts <- read.table('{counts_file}', header=TRUE, row.names=1, sep='\\t')
                coldata <- read.table('{coldata_file}', header=TRUE, sep='\\t')

                # åˆ†å¸ƒãƒ•ã‚¡ãƒŸãƒªãƒ¼ã«å¿œã˜ãŸãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
                if ("{dist_short}" == "beta") {{
                    # 0-1ã®å¢ƒç•Œã®èª¿æ•´
                    eps <- {epsilon}
                    counts <- pmax(pmin(counts, 1-eps), eps)
                }} else if ("{dist_short}" == "gaussian") {{
                    # ã‚¬ã‚¦ã‚¹ã®å ´åˆã¯ç‰¹ã«å‰å‡¦ç†ä¸è¦
                }} else if ("{dist_short}" == "poisson" || "{dist_short}" == "nb") {{
                    # ãƒã‚¢ã‚½ãƒ³ã¨NBã¯ã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æƒ³å®šï¼ˆæ•´æ•°åŒ–ï¼‰
                    counts <- round(counts)
                }}

                # æ™‚é–“å¤‰æ•°ã®ç‰¹å®šã¨ãƒ•ã‚©ãƒ¼ãƒŸãƒ¥ãƒ©ã®ä½œæˆ
                time_var <- "{full[0]}"
                cat("Time variable:", time_var, "\\n")

                # æ™‚é–“å¤‰æ•°ã®ç¢ºèªã¨å¤‰æ›
                if(time_var %in% colnames(coldata)) {{
                  cat("Time variable exists in coldata. Values:", "\\n")
                  print(coldata[[time_var]])
                  
                  # æ™‚é–“å¤‰æ•°ãŒæ•°å€¤ã§ãªã„å ´åˆã¯å¤‰æ›
                  if(!is.numeric(coldata[[time_var]])) {{
                    cat("Converting time variable to numeric\\n")
                    coldata[[time_var]] <- as.numeric(gsub("[^0-9.]", "", as.character(coldata[[time_var]])))
                    cat("After conversion:", "\\n")
                    print(coldata[[time_var]])
                  }}
                }} else {{
                  cat("WARNING: Time variable not found in coldata!\\n")
                }}

                # normalizationï¼ˆãƒ™ãƒ¼ã‚¿åˆ†å¸ƒä»¥å¤–ã§ã‚‚ä½¿ãˆã‚‹ï¼‰
                if ({beta_normalization} == "TRUE"){{
                    coldata[[time_var]] <- coldata[[time_var]] / max(coldata[[time_var]])
                    cat("Time is normalized by max value.")
                }}

                # GAMãƒ¢ãƒ‡ãƒ«å¼ã®ä½œæˆ
                gam_full_formula <- "{full_model.replace('~', '')}"
                gam_reduced_formula <- "{reduced_model.replace('~', '')}"

                # å¹³æ»‘åŒ–é …ã®è¿½åŠ  (æ™‚é–“å¤‰æ•°ã«å¯¾ã—ã¦)
                if(time_var %in% colnames(coldata)) {{
                  if(length(unique(coldata[[time_var]])) >= 3) {{  # å°‘ãªãã¨ã‚‚3ã¤ã®ç•°ãªã‚‹å€¤ãŒå¿…è¦
                    # ãƒ•ãƒ«ãƒ¢ãƒ‡ãƒ«ã«ã®ã¿å¹³æ»‘åŒ–é …ã‚’è¿½åŠ 
                    if(grepl(time_var, gam_full_formula)) {{
                      gam_full_formula <- gsub(
                        paste0("\\\\b", time_var, "\\\\b"), 
                        paste0("s(", time_var, ", k={gam_k}, bs='{spline_type}')"), 
                        gam_full_formula
                      )
                    }} else {{
                      # time_varãŒæ˜ç¤ºçš„ã«å«ã¾ã‚Œã¦ã„ãªã„å ´åˆã¯è¿½åŠ 
                      gam_full_formula <- paste(gam_full_formula, "+", paste0("s(", time_var, ", k={gam_k}, bs='{spline_type}')"))
                    }}
                    cat("Full GAM formula:", gam_full_formula, "\\n")
                    cat("Reduced GAM formula:", gam_reduced_formula, "\\n")
                  }} else {{
                    cat("Not enough unique time points for smoothing, using linear terms\\n")
                  }}
                }}

                cat("{dist_short}")

                # åˆ†å¸ƒãƒ•ã‚¡ãƒŸãƒªãƒ¼ã®è¨­å®šé–¢æ•°
                get_family <- function() {{
                    if ("{dist_short}" == "beta") {{
                        return(betar())
                    }} else if ("{dist_short}" == "gaussian") {{
                        return(gaussian())
                    }} else if ("{dist_short}" == "poisson") {{
                        return(poisson())
                    }} else if ("{dist_short}" == "nb") {{
                        library(mgcv)
                        # mgcvã®nbé–¢æ•°ã¯thetaãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å—ã‘å–ã‚‹
                        return(negbin(theta = {nb_theta}))
                    }}
                }}

                # ä¸¦åˆ—ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®è¨­å®š
                n_cores <- {n_cores}
                cl <- makeCluster(n_cores)

                # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã«å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã¨ãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡
                clusterEvalQ(cl, {{
                  library(mgcv)
                  library(lmtest)
                }})

                clusterExport(cl, c("counts", "coldata", "gam_full_formula", 
                                    "gam_reduced_formula", "get_family"))

                # å‡¦ç†é–¢æ•°
                process_gene <- function(i) {{
                  gene_data <- data.frame(y=as.numeric(counts[i,]), coldata)
                  family_to_use <- get_family()
                  
                  result <- tryCatch({{
                    # ãƒ•ãƒ«ãƒ¢ãƒ‡ãƒ«ã¨ç¸®å°ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°
                    full_fit <- gam(as.formula(paste("y ~", gam_full_formula)), 
                                    family=family_to_use, data=gene_data, method="{gam_method}")
                    
                    reduced_fit <- gam(as.formula(paste("y ~", gam_reduced_formula)), 
                                       family=family_to_use, data=gene_data, method="{gam_method}")
                    
                    # å°¤åº¦æ¯”æ¤œå®š
                    lr_test <- lrtest(reduced_fit, full_fit)
                    
                    # çµæœã‚’è¿”ã™
                    c(statistic = lr_test$Chisq[2],
                      df = lr_test$Df[2],
                      p_value = lr_test$`Pr(>Chisq)`[2],
                      logLik_diff = lr_test$LogLik[2] - lr_test$LogLik[1])
                  }}, error=function(e) {{
                    # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯NAã‚’è¿”ã™
                    if (i <= 5) cat("Gene", i, "Error:", conditionMessage(e), "\\n")
                    c(statistic = NA, df = NA, p_value = NA, logLik_diff = NA)
                  }})
                  
                  return(result)
                }}

                # ä¸¦åˆ—å‡¦ç†ã®å®Ÿè¡Œ
                cat("Starting parallel GAM regression on", n_cores, "cores for", nrow(counts), "genes\\n")
                cat("Using distribution family:", "{dist_family}", "\\n")
                system.time(
                  results_list <- parLapply(cl, 1:nrow(counts), process_gene)
                )

                # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®çµ‚äº†
                stopCluster(cl)

                # çµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
                results_matrix <- do.call(rbind, results_list)
                results <- as.data.frame(results_matrix)
                rownames(results) <- rownames(counts)

                # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã®ä¿å­˜
                cat("\\n### ãƒ¢ãƒ‡ãƒ«æƒ…å ± ###\\n", file='{res_dir}/gam_model_info.txt')
                cat("åˆ†å¸ƒãƒ•ã‚¡ãƒŸãƒªãƒ¼:", "{dist_family}", "\\n", file='{res_dir}/gam_model_info.txt', append=TRUE)
                cat("GAMå¹³æ»‘åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ k:", {gam_k}, "\\n", file='{res_dir}/gam_model_info.txt', append=TRUE)
                cat("æ¨å®šæ–¹æ³•:", "{gam_method}", "\\n", file='{res_dir}/gam_model_info.txt', append=TRUE)
                cat("ãƒ•ãƒ«GAMãƒ¢ãƒ‡ãƒ«å¼:", paste("y ~", gam_full_formula), "\\n", file='{res_dir}/gam_model_info.txt', append=TRUE)
                cat("ç¸®å°GAMãƒ¢ãƒ‡ãƒ«å¼:", paste("y ~", gam_reduced_formula), "\\n", file='{res_dir}/gam_model_info.txt', append=TRUE)

                # NAã®æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                na_count <- sum(is.na(results$statistic))
                if (na_count > 0) {{
                  cat("è­¦å‘Š:", na_count, "å€‹ã®éºä¼å­ã§ãƒ¢ãƒ‡ãƒ«ãŒåæŸã—ã¾ã›ã‚“ã§ã—ãŸ (", 
                      round(100 * na_count / nrow(results), 2), "%)  k, spline, ä¸å‡ç­‰æ™‚ç³»åˆ—ã®æ­£è¦åŒ–ç­‰ã‚’æ¤œè¨", 
                      file='{res_dir}/gam_model_info.txt', append=TRUE)
                }}

                # å¤šé‡æ¤œå®šè£œæ­£
                results$adj.P.Val <- p.adjust(results$p_value, method="BH")

                # çµæœã‚’ä¿å­˜
                write.table(results[order(results$p_value), ], 
                            file='{res_dir}/gam_{dist_short}_{spline_type}_res.tsv', 
                            sep='\\t', quote=FALSE, col.names=NA)

                cat("GAM regression analysis completed\\n")
                sink()
            """



        elif test_method == 'maSigPro':
            # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜è¨­å®š
            counts_file = os.path.join(temp_dir, 'counts.tsv')
            df.to_csv(counts_file, sep='\t')
            coldata_file = os.path.join(temp_dir, 'coldata.tsv')
            df_e.to_csv(coldata_file, sep='\t', index=False)


            # æ™‚é–“æƒ…å ±ã‚’å«ã‚€é©åˆ‡ãªedesignãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆã™ã‚‹Rã‚³ãƒ¼ãƒ‰
            r_code = f"""
            library(maSigPro)
            
            # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
            cat("Loading data...\\n")
            counts <- read.table("{counts_file}", header=TRUE, row.names=1, sep="\\t")
            coldata <- read.table("{coldata_file}", header=TRUE, sep="\\t")
            print(coldata)

            # maSigProç”¨ã®é©åˆ‡ãªãƒ‡ã‚¶ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
            cat("Creating proper design matrix for maSigPro...\\n")
            
            # ã‚°ãƒ«ãƒ¼ãƒ—æƒ…å ±ã‚’å–å¾—ï¼ˆ"Group"åˆ—ï¼‰
            time_col <- as.character(coldata${full[0]})
            

            # æ™‚é–“æƒ…å ±ã‚’æŠ½å‡ºï¼ˆä¾‹ï¼š"0w", "1w", "4w"ã‹ã‚‰æ•°å€¤ã«å¤‰æ›ï¼‰
            time_values <- as.numeric(gsub("[^0-9.]", "", time_col))
            cat("time_values")
            cat(time_values)
            
            # ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ãƒˆæƒ…å ±ã‚’ä½œæˆ
            # åŒã˜æ™‚é–“å€¤ã‚’æŒã¤ã‚µãƒ³ãƒ—ãƒ«ã«ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªç•ªå·ã‚’å‰²ã‚Šå½“ã¦
            replicates <- numeric(length(time_values))
            for (t in unique(time_values)) {{
                idx <- which(time_values == t)
                replicates[idx] <- 1:length(idx)
            }}
            
            # maSigProç”¨ã®æ­£ã—ã„edesignãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
            edesign <- data.frame(
                Time = time_values,
                Replicate = replicates
            )
            rownames(edesign) <- colnames(counts)
            
      #      # ä»–ã®å®Ÿé¨“æ¡ä»¶ãŒã‚ã‚Œã°è¿½åŠ 
      #      if (ncol(coldata) > 1) {{
      #          for (i in 2:ncol(coldata)) {{
      #              col_name <- colnames(coldata)[i]
      #              edesign[[col_name]] <- coldata[[i]]
      #          }}
      #      }}

            # Add Group column (all 1s for single condition)
            edesign$Group <- rep(1, nrow(edesign)) #tutorialã«åˆã‚ã›ã¦å…¨éƒ¨1ã«ã™ã‚‹
            
            # ãƒ‡ãƒ¼ã‚¿å‹ã®ç¢ºèª
            cat("Time values:", paste(time_values, collapse=", "), "\\n")
            cat("Time values are numeric:", is.numeric(edesign$Time), "\\n")
            cat("edesign")
            print(edesign)
            
            # å‰å‡¦ç†
            """
            
            # ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸå‡¦ç†ã®è¿½åŠ 
            if data_type == "0-1 data (logit transformation)":
                r_code += f"""
            # 0-1ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†
            eps <- {epsilon}
            counts <- pmax(pmin(counts, 1-eps), eps)
            counts <- log(counts/(1-counts))
            use_counts_param <- FALSE
            cat("Applied logit transformation\\n")
            """
            elif data_type == "qPCR/continuous data (Gaussian)":
                r_code += f"""
            # qPCR/é€£ç¶šãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†
            use_counts_param <- FALSE
            cat("Using Gaussian model for continuous data\\n")
            
            # ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
            original_counts <- counts
            """
                
                # logå¤‰æ›ã‚ªãƒ—ã‚·ãƒ§ãƒ³
                if log_transform:
                    r_code += """
            # Log2å¤‰æ›ã‚’é©ç”¨
            counts <- log2(counts + 1)  # +1ã‚’åŠ ãˆã¦0å€¤ã‚’é¿ã‘ã‚‹
            cat("Applied log2(x+1) transformation\\n")
            """
                
                # æ­£è¦åŒ–ã‚ªãƒ—ã‚·ãƒ§ãƒ³
                if normalization:
                    r_code += """
            # Z-scoreæ­£è¦åŒ–ï¼ˆã‚µãƒ³ãƒ—ãƒ«é–“ï¼‰
            counts <- t(scale(t(counts)))
            cat("Applied z-score normalization across samples\\n")
            """
                
                r_code += """
            cat("qPCR data preprocessing completed\\n")
            """
            else:  # RNA-seq count data
                r_code += """
            # RNA-seqãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†
            use_counts_param <- TRUE
            cat("Using GLM for count data\\n")
            """
            
            # ãƒ‡ã‚¶ã‚¤ãƒ³è¡Œåˆ—ã‚’ä½¿ç”¨ã—ãŸåˆ†æ
            r_code += f"""
            # ãƒ‡ã‚¶ã‚¤ãƒ³è¡Œåˆ—ã‚’ä½¿ç”¨ã—ã¦åˆ†æ
            cat("Running maSigPro analysis...\\n")
            
            # æŒ‡å®šã•ã‚ŒãŸæ¬¡æ•°ã§ãƒ‡ã‚¶ã‚¤ãƒ³è¡Œåˆ—ã‚’ä½œæˆ
            design <- make.design.matrix(edesign, degree={degree})
            
            # å›å¸°åˆ†æã®å®Ÿè¡Œ
            cat("Running p.vector...\\n")
            fit <- p.vector(counts, design$edesign, Q={q_value}, MT.adjust="none", counts=use_counts_param)
           # fit <- p.vector(counts, design$edesign, Q={q_value}, MT.adjust="BH", counts=use_counts_param)
            
            # æœ‰æ„ãªéºä¼å­æ•°ã®ç¢ºèª
            sig_count <- sum(fit$p < {q_value}, na.rm=TRUE)
            cat("Genes with p <", {q_value}, ":", sig_count, "\\n")

            # After running p.vector() and finding no significant genes

            
            # æœ‰æ„ãªéºä¼å­ãŒã‚ã‚‹å ´åˆã®ã¿æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¸
            if (sig_count > 0) {{
                cat("Running T.fit...\\n")
                tstep <- T.fit(fit, step.method="backward", alfa={q_value})
                
                cat("Getting significant genes...\\n")
                sigs <- get.siggenes(tstep, rsq={rsq}, vars="each")
                
                # çµæœã‚’ä¿å­˜
                if (!is.null(sigs) && !is.null(sigs$sig.genes) && !is.null(sigs$sig.genes$sig.profiles) && nrow(sigs$sig.genes$sig.profiles) > 0) {{
                    cat("Found", nrow(sigs$sig.genes$sig.profiles), "significant genes\\n")
                    
                    # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã¨ä¿‚æ•°ã‚’ä¿å­˜
                    write.table(sigs$sig.genes$sig.profiles, file="{res_dir}/maSigPro_sig_profiles.tsv", sep="\\t", quote=FALSE)
                    write.table(sigs$coefficients, file="{res_dir}/maSigPro_coefficients.tsv", sep="\\t", quote=FALSE)
                    
                    # è¦ç´„æƒ…å ±ã®ä¿å­˜
                    cat("maSigPro Analysis Results\\n",
                        "------------------------\\n",
                        "Total genes analyzed: ", nrow(counts), "\\n",
                        "Significant genes (p <", {q_value}, "): ", sig_count, "\\n",
                        "Significant genes (rsq >", {rsq}, "): ", nrow(sigs$sig.genes$sig.profiles), "\\n",
                        file="{res_dir}/maSigPro_summary.txt")
                }} else {{
                    cat("No genes passed R-squared threshold\\n")
                    cat("No genes passed R-squared threshold of", {rsq}, "\\n", file="{res_dir}/maSigPro_summary.txt")
                }}
            }} else {{
                cat("No significant genes found\\n")
                cat("No significant genes found at Q-value", {q_value}, "\\n", file="{res_dir}/maSigPro_summary.txt")
            }}
            """
            
            # Rã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œ
            with st.spinner('Calculating maSigPro... This may take a while.'):
                try:
                    # Rã‚³ãƒ¼ãƒ‰ã‚’ãƒ‡ãƒãƒƒã‚°ç”¨ã«ä¿å­˜
                    with open(os.path.join(temp_dir, 'debug_maSigPro.R'), 'w') as f:
                        f.write(r_code)
                    
                    # Rã‚³ãƒ¼ãƒ‰å®Ÿè¡Œ
                    ro.r(r_code)
                    
                    # çµæœç”¨ã®ç©ºãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆï¼ˆã‚¨ãƒ©ãƒ¼å›é¿ç”¨ï¼‰
                    res_df = pd.DataFrame()
                    
                    # çµæœã®è¡¨ç¤º
                    st.markdown("### maSigPro Analysis Results")
                    
                    # çµæœãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèªã¨è¡¨ç¤º
                    summary_file = os.path.join(res_dir, 'maSigPro_summary.txt')
                    if os.path.exists(summary_file):
                        with open(summary_file, 'r') as f:
                            summary = f.read()
                        st.text(summary)
                    
                    # æœ‰æ„ãªéºä¼å­ã®çµæœã‚’è¡¨ç¤º
                    sig_profiles_file = os.path.join(res_dir, 'maSigPro_sig_profiles.tsv')
                    if os.path.exists(sig_profiles_file):
                        res_df = pd.read_csv(sig_profiles_file, sep='\t', index_col=0)
                        if not res_df.empty:
                            st.write("### Top significant genes:")
                            st.dataframe(res_df.head(10))
                            
                            # ä¿‚æ•°ã®è¡¨ç¤º
                            coef_file = os.path.join(res_dir, 'maSigPro_coefficients.tsv')
                            if os.path.exists(coef_file):
                                st.write("### Regression coefficients:")
                                coef = pd.read_csv(coef_file, sep='\t', index_col=0)
                                st.dataframe(coef.head(10))
                            
                            # çµæœã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                            data_type_short = ""
                            if data_type == "RNA-seq count data (GLM)":
                                data_type_short = "RNAseq"
                            elif data_type == "qPCR/continuous data (Gaussian)":
                                data_type_short = "qPCR"
                            elif data_type == "0-1 data (logit transformation)":
                                data_type_short = "logit"
                            
                            file_name = file_name_head + f"_maSigPro_{data_type_short}"
                            shutil.make_archive("res", format='zip', root_dir=res_dir)
                    else:
                        st.info("No significant genes were found. Try adjusting the Q-value or R-squared threshold.")
                
                except Exception as e:
                    st.error(f"Error executing R code: {str(e)}")
                    # ã‚¨ãƒ©ãƒ¼æ™‚ã«ã‚‚ç©ºã®DataFrameã‚’ä½œæˆ
                    res_df = pd.DataFrame()
            
     
            
            # çµæœã®ZIPç”Ÿæˆ
            data_type_short = ""
            if data_type == "RNA-seq count data (GLM)":
                data_type_short = "RNAseq"
            elif data_type == "qPCR/continuous data (Gaussian)":
                data_type_short = "qPCR"
            elif data_type == "0-1 data (logit transformation)":
                data_type_short = "logit"
            
            file_name = file_name_head + f"_maSigPro_{data_type_short}"
            shutil.make_archive("res", format='zip', root_dir=res_dir)

        # çµæœã®è¡¨ç¤ºã¨ä¿å­˜
        if test_method == 'Beta Regression':
            ro.r(r_code)
            res_df = pd.read_csv(os.path.join(res_dir, 'betareg_res.tsv'), sep='\t', index_col=0)
            st.write(f"Significant (FDR<0.05): {(res_df['adj.P.Val']<0.05).sum()}")
            st.dataframe(res_df)

            # ãƒ¢ãƒ‡ãƒ«åæŸæƒ…å ±ã®ç¢ºèªã¨è¡¨ç¤º
            convergence_file = os.path.join(res_dir, 'model_convergence_info.txt')
            if os.path.exists(convergence_file):
                with open(convergence_file, 'r') as f:
                    convergence_info = f.read()
        
            # åæŸã«å•é¡ŒãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if "è­¦å‘Š" in convergence_info:
                st.warning(convergence_info)
            else:
                st.success(convergence_info)
                
            file_name = file_name_head + "_betareg_" + full_model.replace(" + ", "_").replace(" ", "") + "_vs_" + reduced_model.replace(" + ", "_").replace(" ", "")
            shutil.make_archive("res", format='zip',root_dir= res_dir)

        elif test_method == 'Generalized Linear Model (GLM)':
            ro.r(r_code)
            res_df = pd.read_csv(os.path.join(res_dir, f'glm_{glm_dist_short}_{glm_link}_res.tsv'), sep='\t', index_col=0)
            st.write(f"Significant (FDR<0.05): {(res_df['adj.P.Val']<0.05).sum()}")
            st.dataframe(res_df)
            
            # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã®è¡¨ç¤º
            model_info_file = os.path.join(res_dir, 'glm_model_info.txt')
            if os.path.exists(model_info_file):
                with open(model_info_file, 'r') as f:
                    model_info = f.read()
                st.text(model_info)
            
            file_name = file_name_head + f"_glm_{glm_dist_short}_{glm_link}_" + full_model.replace(" + ", "_").replace(" ", "") + "_vs_" + reduced_model.replace(" + ", "_").replace(" ", "")
            shutil.make_archive("res", format='zip',root_dir= res_dir)

        elif test_method == 'Generalized Additive Model (GAM)':
            ro.r(r_code)
            res_df = pd.read_csv(os.path.join(res_dir, f'gam_{dist_short}_{spline_type}_res.tsv'), sep='\t', index_col=0)
            st.write(f"Significant (FDR<0.05): {(res_df['adj.P.Val']<0.05).sum()}")
            st.dataframe(res_df)
            
            file_name = file_name_head + "_gam_" + full_model.replace(" + ", "_").replace(" ", "") + "_vs_" + reduced_model.replace(" + ", "_").replace(" ", "")
            shutil.make_archive("res", format='zip',root_dir= res_dir)


            # ãƒ¢ãƒ‡ãƒ«åæŸæƒ…å ±ã®ç¢ºèªã¨è¡¨ç¤º
            convergence_file = os.path.join(res_dir, 'gam_model_info.txt')
            if os.path.exists(convergence_file):
                with open(convergence_file, 'r') as f:
                    convergence_info = f.read()
        
            # åæŸã«å•é¡ŒãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if "è­¦å‘Š" in convergence_info:
                st.warning(convergence_info)
            else:
                st.success(convergence_info)

        if res_df is not None:
            with open("res.zip", "rb") as fp:
                btn = st.download_button(
                    label="Download Results",
                data=fp,
                file_name=file_name + "_DESeq2-LRT.zip",
                mime = "zip"
                )
            try:
                os.remove(file_name + "_DESeq2-LRT.zip")
                shutil.rmtree(temp_dir)
                os.mkdir(temp_dir)
            except:
                pass


#ã€€ãƒ‡ãƒ¼ã‚¿ã‚’é€ã‚‹å‰ã«ã™ã¹ã¦ã‚¼ãƒ­ã®ãƒ‡ãƒ¼ã‚¿ã¯é™¤ãã¹ã


# refãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹ã¨ãã¯ãƒ•ã‚¡ã‚¤ãƒ«åã‚’èª¿æ•´ã™ã‚‹?
