#!!!!!!!!!!!!!! pip install rpy2==3.5.1  æ–°ã—ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹

# åŸºæœ¬çš„ã«globalå¤‰æ•°ã§è¨ˆç®—ã™ã‚‹ã€‚
# pythonã‹ã‚‰assgnã•ã‚Œã‚‹ã®ã¯globalå¤‰æ•°


import streamlit as st
import rpy2
import csv
import re
import os
import numpy as np
import pandas as pd
import rpy2.robjects as ro
from rpy2.robjects.packages import importr
from rpy2.robjects import pandas2ri
from rpy2.robjects.vectors import StrVector
import pyper
import shutil
from PIL import Image
import itertools
from helper_func import clear_old_directories, clear_old_files, remove_after_space, remove_sample_num
import time
import sys
from collections import Counter

def remove_common_suffix(strings):
    if not strings or len(strings) == 0:
        return []    
    # æœ€ã‚‚çŸ­ã„æ–‡å­—åˆ—ã®é•·ã•ã‚’å–å¾—
    min_length = min(len(s) for s in strings)
    # å…±é€šã®æœ«å°¾éƒ¨åˆ†ã®é•·ã•ã‚’è¦‹ã¤ã‘ã‚‹
    suffix_length = 0
    for i in range(1, min_length + 1):
        suffix = strings[0][-i:]
        if all(s.endswith(suffix) for s in strings):
            suffix_length = i
        else:
            break            
    # å…±é€šã®æœ«å°¾éƒ¨åˆ†ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯å…ƒã®ãƒªã‚¹ãƒˆã‚’è¿”ã™
    if suffix_length == 0:
        return strings        
    # å…±é€šã®æœ«å°¾éƒ¨åˆ†ã‚’å‰Šé™¤ã—ã¦æ–°ã—ã„ãƒªã‚¹ãƒˆã‚’ä½œæˆ
    return [s[:-suffix_length] for s in strings]


def rename_duplicates(df):
    """
    Rename duplicate indices by adding _2, _3, etc. to subsequent occurrences   
    Args:
        df: pandas DataFrame
    Returns:
        DataFrame with renamed indices
    """
    # Get current index values
    lis = df.index.values
    
    # Count occurrences of each value
    counts = Counter()
    new_indices = []
    
    for x in lis:
        counts[x] += 1
        if counts[x] == 1:
            new_indices.append(x)
        else:
            new_indices.append(f"{x}_{counts[x]}")
    
    # Check if there were any duplicates
    if len(lis) != len(set(lis)):
        st.markdown("#### There are duplicated rows. Converting the names...")
        st.write("The gene names of subsequent occurrences have _2, _3, etc. at the end.")
        
        # Display which names were changed
        for name, count in counts.items():
            if count > 1:
                st.write(f"'{name}' appears {count} times â†’ {name}, " + 
                        ", ".join([f"{name}_{i}" for i in range(2, count + 1)]))
    
    # Set new index
    df.index = new_indices
    return df

@st.cache_data
def check_excel_autoconversion(dfx):
    p = re.compile(r'(\d+)\-(Mar|Sep|Oct|Dec|Feb|Nov)')
    index_name = dfx.index.values
    j = 0
    k = 0
    for i in df.index.values:
        x = p.match(i)
        if x:
            if k == 0:
                st.markdown("#### There are Excel-autoconverted gene names")
                st.write("Gene names are not converted.")
                k = 1
            autoconvert_flag = True
            st.write(i)


r = pyper.R(use_pandas=True)
f = ro.r("source('pages/deseq2_func.R')") # full pathãŒå¿…è¦

st.set_page_config(page_title="Calculate DESeq2.", page_icon="ğŸ“ƒ")

@st.cache_data
def read_csv(file, index_col=None, sep=',', header = 0):
    df_c = pd.read_csv(file, index_col = index_col, header = header, sep = sep)
    return df_c


@st.cache_data
def convert_df(df):
   return df.to_csv(index=True, sep='\t').encode('utf-8')

@st.cache_data
def read_excel(file, index_col=None, header = 0):
    df_xl = pd.read_excel(file, index_col = index_col, header = header)
    return df_xl

@st.cache_data
def calc_barplot(data, ylabel):
    fig, ax = plt.subplots()
    ax = sns.barplot(data=data)
    ax.set_xticklabels(ax.get_xticklabels(),rotation = 90)
    ax.set_ylabel(ylabel, fontsize = 14)
    return fig


# tempå†…ã«ä¿å­˜ã™ã‚‹
# --- Initialising SessionState ---
if "temp_dir" not in st.session_state:
    st.session_state.temp_dir = True
    #å¤ã„direcotryã¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã™ã‚‹
    temp_dir = "temp/" + str(round(time.time()))
    if not os.path.exists('temp'):
        os.mkdir('temp')
    else:
        clear_old_directories("temp")
        clear_old_files("temp")
    os.mkdir(temp_dir)
    st.session_state.temp_dir = temp_dir
    res_dir = temp_dir + '/res_LRT'
    st.session_state.res_dir = res_dir
    os.mkdir(res_dir)

else:
    temp_dir = st.session_state.temp_dir
    res_dir = temp_dir + '/res_LRT'
    st.session_state.res_dir = res_dir
    if not os.path.exists(temp_dir):
        os.mkdir(temp_dir)
        os.mkdir(res_dir)
    if not os.path.exists(res_dir):
        os.mkdir(res_dir)

st.sidebar.title("Options")
with st.sidebar:
    st.markdown("#### Test medhod:")
    test_method = st.radio("Test method:", 
                         ["DESeq2-LRT", "limma eBays", "Beta Regression", 
                          "GAM Beta Regression", "maSigPro"], 
                         index=0, label_visibility = 'collapsed')

    st.markdown("##### limma eBays with ligit transformation and beta regression are for proportion data.")

    if test_method == 'limma eBays':
        limma_data = st.radio("Data type:",
            ["RNA-seq count", "Non-count data", "0-1 data (proportion, AUC etc) to logit transformation"],
            index = 1)

        if limma_data == "RNA-seq count":
            apply_logit = False
            limma_count = True
        elif limma_data == "Non-count data":
            apply_logit = False
            limma_count = False
        else:
            apply_logit = True
            limma_count = False            
            
    # ãƒ™ãƒ¼ã‚¿å›å¸°ç‰¹æœ‰ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    if test_method in ['Beta Regression', 'GAM Beta Regression']:
        st.markdown("#### Beta Regression Options:")
        epsilon = st.number_input("Epsilon for boundary adjustment (0-1 data)", 
                                min_value=0.0000001, max_value=0.01, value=0.000001, format="%.7f")
        add_higher = st.checkbox("Add polynomial terms?", value=False, help="éç·šå½¢çš„ãªå¤‰åŒ–ã‚’æ‰ãˆã‚‹ãŸã‚å¤šé …é …ã‚’åŠ ãˆã‚‹")
        beta_polynomial_degree = 1
        if add_higher:
            polynomial_term = st.radio("Degree", ['2:Quadratic term','3:Cubic term'], index = 0, help = "2æ¬¡ã®é …ã‚’åŠ ãˆã‚‹ã¨U-shaped/inverted U-shaped patternsãŒæ‰ãˆã‚‰ã‚Œã‚‹ã€‚3æ¬¡ã®é …ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šè¤‡é›‘ãªç™ºç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ‰ãˆã‚‹ã€‚ä¾‹ãˆã°ï¼šæ€¥ä¸Šæ˜‡å¾Œã«æ¨ªã°ã„ã«ãªã‚Šã€ãã®å¾Œä½ä¸‹ã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã€æ³¢å½¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã€‚")
            st.markdown("#### The first item in full model will be used for polynominal term.")
            if polynomial_term == "2:Quadratic term":
                beta_polynomial_degree = 2
            else:
                beta_polynomial_degree = 3

        
    # GAMç‰¹æœ‰ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    if test_method == 'GAM Beta Regression':
        st.markdown("##### GAM Options:")
        gam_k = st.slider("Spline basis dimension (k)", min_value=3, max_value=20, value=5)
        gam_method = st.radio("Smoothing parameter estimation method", 
                            ["REML", "GCV.Cp", "ML"], index=0)

    if test_method in ['Beta Regression', 'GAM Beta Regression']:
        n_cores = st.slider("Parallel cores", min_value=1, 
                           max_value=os.cpu_count()-1, 
                           value=max(1, os.cpu_count()//2))


    if test_method == 'maSigPro':
        st.markdown("##### maSigPro Options:")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã®é¸æŠ
        data_type = st.radio(
            "Data type:",
            ["RNA-seq count data (GLM)", "0-1 data (logit transformation)"],
            index=0
        )
        
        # ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
        if data_type == "0-1 data (logit transformation)":
            st.markdown("##### Boundary adjustment for 0-1 data:")
            epsilon = st.number_input("Epsilon", 
                                    min_value=1e-8, 
                                    max_value=0.01, 
                                    value=1e-6,
                                    format="%.8f")
        
        # å…±é€šã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        degree = st.slider("Polynomial degree", min_value=1, max_value=3, value=2)
        rsq = st.number_input("R-squared cutoff", min_value=0.1, max_value=0.9, value=0.7, step=0.05)
        q_value = st.number_input("Q-value (FDR)", min_value=0.001, max_value=0.5, value=0.05, step=0.01)
        
        # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        st.markdown("##### Clustering options:")
        cluster_method = st.radio("Clustering method", 
                                ["hclust", "kmeans", "clara"], index=0)
        k = st.slider("Number of clusters", min_value=2, max_value=15, value=9)
        
        # å¯è¦–åŒ–ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        st.markdown("##### Visualization:")
        plot_top_n = st.slider("Number of genes to plot", min_value=5, max_value=50, value=20)

    st.markdown("---")

st.markdown("## DESeq2 likelihood-ratio test (LRT) and limma eBays test for time-course and ANOVA-like test")
st.markdown("#### limma eBays can be used with non-count data, including AUC")
st.write(" ")
use_upload = 'Yes'
if 'df' in st.session_state:
    if st.session_state.df is not None:
        use_upload = st.radio("Upload new file?", ('Yes','No'), index = 1)
    if use_upload == "No":
        df = st.session_state.df
        input_file_type = 'tsv'
        file_name_head = st.session_state.uploaded_file_name
        if "Row_name" in df.columns.to_list(): # Row_nameã‚’å«ã‚€ã¨ã
            df = df.set_index('Row_name')
            df.index.name = "Gene"



if use_upload == 'Yes':
    st.markdown("##### Data format:")
    file_type = st.radio(
        "",    ('Homer','tsv','csv','excel'), index = 1, label_visibility = 'collapsed')


    uploaded_file = st.file_uploader("Choose a file", type=['txt','tsv', 'csv', 'xls','xlsx'])
    if uploaded_file is not None:
        if file_type is not 'excel':
            if file_type == 'csv':
                df = read_csv(uploaded_file)
            else:
                df = read_csv(uploaded_file, sep = '\t')
            st.write("Original:")
            st.write(df.head())
            if file_type == 'Homer':
                df = df.iloc[:,7:]
                colnames = df.columns.tolist()
                colnames[0] = 'Gene'
                # colnamesã®å¤‰æ›
                search_word = '([^\ \(]*)\ \(.*'
                for i in range(1, len(colnames)):
                    match = re.search(search_word, colnames[i])
                    if match:
                        colnames[i] = match.group(1).replace(' ', '_')
                pattern = "([^|]*)"
                repatter = re.compile(pattern)
                f_annotation = lambda x: repatter.match(x).group(1)
                try:
                    df.iloc[:,0] = df.iloc[:,0].apply(f_annotation)
                    df.columns = colnames
                except:
                    st.markdown("### File format error. Non-Homer file?")

            else:
                colnames = df.columns.tolist()
                colnames[0] = 'Gene'
                df.columns = colnames
        else: # excel
            df = read_excel(uploaded_file, index_col = 0)
            content = df.columns.tolist()
            if "Annotation/Divergence" in content:
                 # colnamesã®å¤‰æ›
                search_word = '([^\ \(]*)\ \(.*'

                for i in range(1, len(content)):
                    match = re.search(search_word, content[i])
                    if match:
                        content[i] = match.group(1).replace(' ', '_')
                df.columns = content # ä¸€æ—¦åå‰ã‚’å¤‰æ›´
                df['Annotation/Divergence'] = df['Annotation/Divergence'].astype(str) # excel å¯¾å¿œ
                pattern = "([^|]*)"
                repatter = re.compile(pattern)
                f_annotation = lambda x: repatter.match(x).group(1)
                df.loc[:,'Annotation/Divergence'] = df.loc[:,'Annotation/Divergence'].apply(f_annotation)
                # annotation/divergenceä»¥å‰ã‚’é™¤ã
                df = df.loc[:,'Annotation/Divergence':]
                content = df.columns.tolist()
                content[0] = 'Gene'
                df.columns = content
                st.write("Converted Annotation/Divergence to gene symbols.")
            else:
                colnames = df.columns.tolist()
                colnames[0] = 'Gene'
                df.columns = colnames

        df = df.set_index('Gene')
        file_name_head = os.path.splitext(uploaded_file.name)[0]
    else:
        sys.exit(1)

if df is not None:

############ sampleåã«-ãŒã‚ã‚‹å ´åˆã¯underscoreã¸ Rã§ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹
    if "-" in "".join(df.columns.values):
        st.write("Minus in sample name will be converted to _.")
        new_columns = [x.replace('-','_') for x in df.columns.values]
        df.columns = new_columns
############

    # å…ˆé ­ãŒæ•°å­—ã®å ´åˆã®å¯¾å¿œ
    #å…ˆé ­æ–‡å­—ã®å¤‰æ›´
    numericstart = False
    colnames = df.columns.to_list()
    for i in range(len(colnames)):
        if re.search('^\d+', colnames[i]) is not None:
            numericstart = True
            colnames[i] = "X" + colnames[i]
    if numericstart:
        df.columns = colnames
        st.write("Some sample names start with numbers. They will be converted to X...")

    st.write('Original gene number:  ' + str(len(df)))

    # floatã«å¤‰æ› èª¤å°„æ‚Ÿå…¥
    df = df.astype(float)

    if not float.is_integer(df.iloc[:,0].sum()*1000):
        if test_method == "DESeq2-LRT":
            st.markdown("## It is likely that your data are normalized. Please upload unnormalized raw count data.")

    if test_method == "DESeq2-LRT": #DESeq2ã¯æ•´æ•°åŒ–
        df = df.round(0)

    df = df.loc[~(df==0).all(axis=1)] #ã™ã¹ã¦0ã®rowã‚’é™¤ã

########## excelå¯¾å¿œ?
    st.write("All zero count genes are removed.")
    if df.isnull().values.sum() > 0:
        st.write("There are " + str(df.isnull().values.sum()) + " NaN in :")
        st.write(df[df.isnull().any(axis=1)])
        convert_nan = st.radio( "NaN:",
        ('remove Nan containing genes', 'conver to 0' ), key='remove Nan containing genes')
        if convert_nan == "conver to 0":
            df = df.fillna(0)
        else:
            df = df.dropna(how='any')
############ sampleåã«-ãŒã‚ã‚‹å ´åˆã¯underscoreã¸ Rã§ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹
    if "-" in "".join(df.columns.values):
        st.write("Minus in sample name will be converted to _.")
        new_columns = [x.replace('-','_') for x in df.columns.values]
        df.columns = new_columns
############


  #  st.write(df.head())
    total_count = pd.DataFrame(df.sum()[1:])
    total_count.columns= ['Total counts']
    large_var = False
    if max(total_count['Total counts']) > min(total_count['Total counts']) * 2:
        large_var = True
        st.markdown("### Large difference (>2x) in counts")
        st.write(f"Minimum total counts: {min(total_count['Total counts'])}")
        st.markdown("##### Low count samples can be filtered on the side panel.")
        import matplotlib.pyplot as plt
        import seaborn as sns
        df_sum = pd.DataFrame(df.sum())
        df_sum.columns = ['Counts']


        f1 = calc_barplot(df_sum.T, ylabel = "Total counts")
        st.pyplot(f1)

        f2 = calc_barplot(np.log1p(df), ylabel = "ln(x+1)")
        st.pyplot(f2)

    with st.sidebar:
        st.markdown("##### Filter out weakly-expressed genes:")
        independentFiltering = st.checkbox('Yes', value= True)
        st.markdown("""ä½ç™ºç¾éºä¼å­ã®é™¤å¤–ã¯FDRã®è¨ˆç®—ã‚’æ”¹å–„ã™ã‚‹ã€‚
        filtered outã•ã‚ŒãŸéºä¼å­ãŒå¤šã„å ´åˆã€GSEAç”¨ã«å…¨éºä¼å­ã‚’ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã™ã‚‹ãŸã‚ã«ã¯ãƒã‚§ãƒƒã‚¯ã‚’å¤–ã™ã€‚""")

        st.markdown("##### Filter the genes > counts in all samples:")
        min_threshold = st.number_input("count minimum", value = 0, label_visibility = 'collapsed')
        min_threshold = int(min_threshold)
        st.markdown("##### Filter the genes > counts in at least one sample:")
        max_threshold = st.number_input("count max", value = 0, label_visibility = 'collapsed')
        max_threshold = int(max_threshold)

        sample_threshold = 0

        if large_var:
            st.markdown("##### Filter the samples <= counts:")
            sample_threshold = st.number_input("Minimum total cout", value = 0, label_visibility = 'collapsed')
        st.markdown("---")

        if test_method == 'DESeq2-LRT':
            st.markdown("### Batch correction:")
            sva = st.checkbox('SVA batch removal?')
            sva_calc = True
            if sva:
                sva_calc = st.checkbox('Calculate only 2 surrogate variables? Deselect if want to calculate up to the recommended number.', value = True)
                st.markdown("---")

    if any(df.sum() <= sample_threshold): # count 0ã®åˆ—ã‚’é™¤ã
        st.markdown('#### There are the samples that have counts <= ' + str(sample_threshold))
        st.write(", ".join(df.columns[df.sum() <= sample_threshold].to_list()))
        st.markdown('##### They are removed. Now data are:')
        df = df.drop(df.columns[df.sum() <= sample_threshold].to_list(), axis = 1)

    st.write(df.head())

    if min_threshold > 0:
        df = df[df.apply(min, axis=1) > min_threshold]
    if max_threshold > 0:
        df = df[df.apply(max, axis=1) > max_threshold]

    st.markdown(f'#### Filtered gene number: {str(len(df))}')


    condition = [str(i) for i in df.columns.tolist()[:]] #erroré˜²æ­¢
    group_condition = remove_common_suffix(condition) #æœ«å°¾ã®å…±é€šè¦ç´ ã‚’é™¤ã
  #  group_condition = [remove_after_space(x) for x in condition] #ã‚¹ãƒšãƒ¼ã‚¹ä»¥é™ã‚’é™¤ã
    group_condition = [remove_sample_num(x) for x in group_condition] #æœ«å°¾ã®æ•°å­—ã‚’é™¤ã


    st.markdown("##### Add conditions other than group, such as genotype (comma, space, CR separated):")
    genes = st.text_input("genes",label_visibility = 'collapsed')
    gene_list = []
    if len(genes) > 0:
        gene_list = genes.split(' ') #ã¾ãšç©ºç™½ã§åˆ†é›¢
        gene_list = list(filter(lambda a: a != '', gene_list)) #ç©ºç™½ã®ã¿ã‚’é™¤ã
        if ',' in genes:
            gene_list = sum([x.split(',') for x in gene_list],[]) #sumã§å¹³å¦åŒ– sum(x, [])
        if '\t' in genes:
            gene_list = sum([x.split('\t') for x in gene_list],[])
        if '\n' in genes:
            gene_list = sum([x.split('\n') for x in gene_list],[])
        gene_list = [a for a in gene_list if a != ''] #ç©ºã‚’é™¤ã
    condition_col = sum([['Group'], gene_list], [] )

    with st.form("input_groups and batch"):
        df_e = pd.DataFrame(index = condition, columns = condition_col)
        for i in df_e.columns.values:
            df_e[i] = group_condition
        st.write('Set conditions:')
    #    edited_df_e = st.experimental_data_editor(df_e)
        df_e = st.data_editor(df_e)
        submitted = st.form_submit_button("Submit")

    condition = df_e.iloc[:,0].tolist()

    for i in df_e.columns.values:
        st.write(' '.join(df_e.loc[:,i].tolist()))

    # å¤šé …å¼æ¬¡æ•°ãŒ1ã‚ˆã‚Šå¤§ãã„å ´åˆã®æ™‚é–“å¤‰æ•°ãƒã‚§ãƒƒã‚¯
    if test_method == 'Beta Regression' and 'beta_polynomial_degree' in locals() and beta_polynomial_degree > 1:
        if full and len(full) > 0:
            try:
                coldata = pd.read_table(coldata_file)
                if full[0] in coldata.columns:
                    # æ™‚é–“å¤‰æ•°ã®å‹ãƒã‚§ãƒƒã‚¯
                    time_col = coldata[full[0]]
                    is_numeric = pd.api.types.is_numeric_dtype(time_col)
                    
                    if not is_numeric:
                        # æ•°å€¤ã«å¤‰æ›å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
                        try:
                            # æ•°å­—ã ã‘ã‚’æŠ½å‡ºã™ã‚‹æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³
                            numeric_values = time_col.str.extract(r'(\d+\.?\d*)')[0].astype(float)
                            st.info(f"æƒ…å ±: æ™‚é–“å¤‰æ•° '{full[0]}' ã¯æ–‡å­—åˆ—ã§ã™ãŒã€æ•°å€¤ã¨ã—ã¦æŠ½å‡ºã§ãã¾ã™ã€‚è§£ææ™‚ã«è‡ªå‹•çš„ã«å¤‰æ›ã•ã‚Œã¾ã™ã€‚")
                        except:
                            st.warning(f"è­¦å‘Š: æ™‚é–“å¤‰æ•° '{full[0]}' ã¯æ•°å€¤ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚å¤šé …å¼ãƒ¢ãƒ‡ãƒ«ï¼ˆæ¬¡æ•°{beta_polynomial_degree}ï¼‰ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯æ•°å€¤ãŒå¿…è¦ã§ã™ã€‚ãƒ¢ãƒ‡ãƒ«ãŒåæŸã—ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
                else:
                    st.warning(f"è­¦å‘Š: æ™‚é–“å¤‰æ•° '{full[0]}' ãŒå®Ÿé¨“ãƒ‡ã‚¶ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            except Exception as e:
                st.warning(f"å®Ÿé¨“ãƒ‡ã‚¶ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")


# modelã‚’ä½œã‚‹ãŸã‚ã®è¦ç´ ã‚’ãƒªã‚¹ãƒˆã«ã™ã‚‹
    comb = [':'.join(x) for x in  list(itertools.combinations(condition_col, 2))]
#ã“ã“ã§ ':'.joint(x)ã¨ã™ã‚‹ã¨ã€ã“ã®ã‚ã¨ã€ãƒ¢ãƒ‡ãƒ«ã‚’ä½œã‚‹ã¨ãã«:ä»¥é™ãŒé™¤ã‹ã‚Œã‚‹
    selections = selections = sum([condition_col, comb],[])
    st.markdown("##### Select conditions for full model:")
    full = st.multiselect('fullmodel',selections, label_visibility = 'collapsed')

    st.markdown("##### Select conditions for reduced model:")
    reduced = st.multiselect('reducedmodel',selections, label_visibility = 'collapsed')
    full = [x.replace(':','\:') for x in full] # :ã®ã¾ã¾ã ã¨æ–‡å­—åˆ—ãŒæ¶ˆå¤±ã™ã‚‹
    reduced = [x.replace(':','\:') for x in reduced]
    if len(reduced) == 0:
        null_model = st.checkbox("Null model as reduced model?", value = False, help="å¸°ç„¡ãƒ¢ãƒ‡ãƒ«ã‚’reduced modelã«ã™ã‚‹ã€‚ã¤ã¾ã‚Šfull modelã«è¨­å®šã—ãŸè¦å› ã®ã„ãšã‚Œã‹ï¼ã™ã¹ã¦ã«é–¢é€£ã—ãŸç™ºç¾å¤‰å‹•ã‚’æ¤œå‡ºã€‚")
    else:
        null_model = False

    full_model = "~ " + " + ".join(full)
    if null_model:
        reduced_model = "~ 1"
    elif len(reduced) == 0: #reducedã‚’æŒ‡å®šã—ã¦ã„ãªã„ã¨ãã¯null modelã«ã™ã‚‹
        reduced_model = "~ 1"
        st.write("Null model is uses ad reduced model.")
    else:
        reduced_model = "~ " + " + ".join(reduced)
    st.markdown("##### Full model:  " + full_model)
    st.markdown("##### Reduced model:  " + reduced_model)
    st.markdown("""
Full modelã¨Reduced modelã¨ã®é•ã„ãŒæ¤œå®šã•ã‚Œã‚‹ã€‚
ä¾‹ãˆã°genotypã¨æ™‚ç³»åˆ—ã®ãƒ‡ãƒ¼ã‚¿ã®ã¨ãã«genptypeã¯é–¢ä¿‚ãªãã€æ™‚ç³»åˆ—å¤‰åŒ–ã‚’ã™ã‚‹éºä¼å­ã‚’æ¤œå‡ºã™ã‚‹å ´åˆã¯
~ genotype + time ã¨ ~ genotype ã®æ¯”è¼ƒã¨ãªã‚‹ã€‚\n
ã‚‚ã—ã€genotypeç‰¹ç•°çš„ã§æ™‚é–“ã§å¤‰åŒ–ã™ã‚‹éºä¼å­ã‚’æ¤œå‡ºã™ã‚‹å ´åˆã¯
~ genotype + time + genotype\:time ã¨ ~ genotype + time ã®æ¯”è¼ƒã¨ãªã‚‹ã€‚\n
\n
Reduced modelã«null modelã‚’è¨­å®šã™ã‚‹ã¨Full modelã®è¦å› ã§å¤‰åŒ–ã™ã‚‹éºä¼å­ã‚’æ¤œå‡ºã™ã‚‹ã€‚\n
ä¾‹ãˆã°WTã®ç´°èƒã®æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã ã‘ã®å ´åˆã€timeã‚’Full modelã«Null modelã‚’Reduced modelã«ã™ã‚‹ã€‚
        """)

    if (len(condition) != len(df.columns)):
            st.write("The number of group name does not match the data.")

#    df_condition = pd.DataFrame(condition)
#    df_batch = pd.DataFrame(batch)

# 1-Marãªã©ã®èª¤å¤‰æ›ã¸ã®å¯¾å¿œ
    check_excel_autoconversion(df)

    if len(df.index.values) != len(set(df.index.values)):
#        st.markdown("#### There are duplicated rows. Converting the names...")
#        st.write("The gene name of the second occurrence has _2 at the end.")
#        lis = df.index.values
#        df.index = [x + ['', '_2'][x in lis[0:i]] for i, x in enumerate(lis)]
        df = rename_duplicates(df)

    st.markdown("""
--------------------------------------------------------------------------
        """)
    if st.button('Run analysis'):
        #ã¾ãšRã®dfã«å¤‰æ›
        if test_method == 'DESeq2-LRT':
    #        ro.r.assign('cts',cts) # ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹ã®ã§ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¸€æ—¦ä¿å­˜ã™ã‚‹
            r.assign('df',df)
            r.assign('df_e',df_e)
            pyper_df_path = "saveRDS(df, '" + temp_dir + "/pyper_df.RDS')"
            r(pyper_df_path)
            pyper_df_e_path = "saveRDS(df_e, '" + temp_dir + "/pyper_df_e.RDS')"
            r(pyper_df_e_path)
            read_pyper_df = "cts <- readRDS('" + temp_dir + "/pyper_df.RDS')"
            read_pyper_df_e = "coldata <- readRDS('" + temp_dir + "/pyper_df_e.RDS')"
            ro.r(read_pyper_df)
            ro.r(read_pyper_df_e)
            #ã¾ãšãƒ™ã‚¯ã‚¿ãƒ¼ã«å¤‰æ›
            r_condition =  ro.StrVector(condition)
            ro.r.assign('condition', r_condition)
            full_model = full_model.replace('\:',':')
            reduced_model = reduced_model.replace('\:',':')
            ro.r.assign('full_model', full_model)
            ro.r.assign('reduced_model', reduced_model)
            ro.r.assign('sva',sva)
            ro.r.assign('sva_calc', sva_calc)
            ro.r.assign('independentFiltering', independentFiltering)
            ro.r.assign('res_dir', res_dir)
            ro.r.assign('temp_dir', temp_dir)

            with st.spinner('Calculating DESeq2...'):
                ro.r('calc_dds_LRT()')


            image = Image.open(res_dir + '/DispersionEstimates.png')
            st.image(image, caption='Despersion Estimates')

            res_df = pd.read_csv(res_dir + '/DESeq2_LRT_res.tsv', sep = '\t', index_col= 0)
            st.write("FDR < 0.05: " + str(len(res_df.loc[(res_df['padj']<0.05),])))

            res_df= res_df.loc[(res_df['padj']<0.1),'padj']
            st.dataframe(res_df)
            if sva:
                st.markdown("#### =======SVA=======")
                with st.spinner('Preparing SVAseq...'):
                    sva_n = ro.r("sv_n <- calc_sva_n()")
                st.write("Recommended number of SVA covariates: " + str(int(sva_n[0])))
                with st.spinner('Calculating SVAseq...'):
                    ro.r("calc_svseq_LRT()")

            if sva:
                st.session_state.deseq2lrt = read_csv(res_dir + "/SVA_LRT_res.tsv", sep = '\t', index_col=0)
            else:
                st.session_state.deseq2lrt = read_csv(res_dir + "/DESeq2_LRT_res.tsv", sep = '\t', index_col=0)


            file_name = file_name_head + full_model.replace(" + ", "_").replace(" ", "") + "_vs_" + reduced_model.replace(" + ", "_").replace(" ", "")

            shutil.make_archive("res", format='zip',root_dir= res_dir)

        elif test_method == 'limma eBays':
            # Save input to files for R import
            counts_file = os.path.join(temp_dir, 'counts.tsv')
            df.to_csv(counts_file, sep='\t')
            coldata_file = os.path.join(temp_dir, 'coldata.tsv')
            df_e.to_csv(coldata_file, sep='\t', index=False)

            voom_plot_path = os.path.join(res_dir, 'voom_plot.png')
            if os.path.exists(voom_plot_path):
                os.remove(voom_plot_path)
            
            if apply_logit:
                # For logit-transformed data, use this R code
                r_code = f"""
                library(limma)
                counts <- read.table('{counts_file}', header=TRUE, row.names=1, sep='\t')
                coldata <- read.table('{coldata_file}', header=TRUE, sep='\t')
                
                # For logit transformed data, apply the transformation in R instead
                eps <- 1e-6
                counts <- pmax(counts, eps)
                counts <- pmin(counts, 1-eps)
                counts <- log(counts/(1-counts))
                
                # Create design matrices
                design_full <- model.matrix(as.formula('{full_model}'), data=coldata)
                design_reduced <- model.matrix(as.formula('{reduced_model}'), data=coldata)
                
                # Identify coefficients specific to the full model
                add_coefs <- setdiff(colnames(design_full), colnames(design_reduced))
                
                # For logit-transformed data, skip voom and directly fit with limma
                fit_full <- lmFit(counts, design_full)
                fit_full <- eBayes(fit_full)
                
                if (length(add_coefs) == 1) {{
                  res <- topTable(fit_full, coef=add_coefs, number=Inf, adjust.method='fdr')
                }} else {{
                  cm <- matrix(0, nrow=ncol(design_full), ncol=length(add_coefs))
                  colnames(cm) <- add_coefs
                  for (i in 1:length(add_coefs)) {{
                    cm[which(colnames(design_full) == add_coefs[i]), i] <- 1
                  }}
                  
                  fit_contrast <- contrasts.fit(fit_full, cm)
                  fit_contrast <- eBayes(fit_contrast)
                  
                  res <- topTable(fit_contrast, number=Inf, sort.by='F', adjust.method='fdr')
                }}
                write.table(res, file='{res_dir}/limma_res.tsv', sep='\t', quote=FALSE, col.names=NA)
                """
            elif limma_count:
                # For regular count data, use the original approach
                r_code = f"""
                library(edgeR); library(limma)
                counts <- read.table('{counts_file}', header=TRUE, row.names=1, sep='\t')
                coldata <- read.table('{coldata_file}', header=TRUE, sep='\t')
                y <- DGEList(counts=counts); y <- calcNormFactors(y)
                
                design_full <- model.matrix(as.formula('{full_model}'), data=coldata)
                design_reduced <- model.matrix(as.formula('{reduced_model}'), data=coldata)
                
                add_coefs <- setdiff(colnames(design_full), colnames(design_reduced))
                
                png('{res_dir}/voom_plot.png')
                v <- voom(y, design_full, plot=TRUE)
                dev.off()
                
                fit_full <- lmFit(v, design_full)
                fit_full <- eBayes(fit_full)
                
                if (length(add_coefs) == 1) {{
                  res <- topTable(fit_full, coef=add_coefs, number=Inf, adjust.method='fdr')
                }} else {{
                  cm <- matrix(0, nrow=ncol(design_full), ncol=length(add_coefs))
                  colnames(cm) <- add_coefs
                  for (i in 1:length(add_coefs)) {{
                    cm[which(colnames(design_full) == add_coefs[i]), i] <- 1
                  }}
                  
                  fit_contrast <- contrasts.fit(fit_full, cm)
                  fit_contrast <- eBayes(fit_contrast)
                  
                  res <- topTable(fit_contrast, number=Inf, sort.by='F', adjust.method='fdr')
                }}
                write.table(res, file='{res_dir}/limma_res.tsv', sep='\t', quote=FALSE,  col.names=NA)
                """
                st.image(f"{res_dir}/voom_plot.png", caption='Voom mean-variance trend')
            else:
                r_code = f"""
                library(limma)
                counts <- read.table('{counts_file}', header=TRUE, row.names=1, sep='\t')
                coldata <- read.table('{coldata_file}', header=TRUE, sep='\t')

                design_full <- model.matrix(as.formula('{full_model}'), data=coldata)
                design_reduced <- model.matrix(as.formula('{reduced_model}'), data=coldata)

                add_coefs <- setdiff(colnames(design_full), colnames(design_reduced))

                # éã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ãªã®ã§voomã¯ã‚¹ã‚­ãƒƒãƒ—
                fit_full <- lmFit(counts, design_full)
                fit_full <- eBayes(fit_full)

                if (length(add_coefs) == 1) {{
                  res <- topTable(fit_full, coef=add_coefs, number=Inf, adjust.method='fdr')
                }} else {{
                  cm <- matrix(0, nrow=ncol(design_full), ncol=length(add_coefs))
                  colnames(cm) <- add_coefs
                  for (i in 1:length(add_coefs)) {{
                    cm[which(colnames(design_full) == add_coefs[i]), i] <- 1
                  }}
                  
                  fit_contrast <- contrasts.fit(fit_full, cm)
                  fit_contrast <- eBayes(fit_contrast)
                  
                  res <- topTable(fit_contrast, number=Inf, sort.by='F', adjust.method='fdr')
                }}
                write.table(res, file='{res_dir}/limma_res.tsv', sep='\t', quote=FALSE, col.names=NA)
                """

            ro.r(r_code)
            res_df = pd.read_csv(os.path.join(res_dir, 'limma_res.tsv'), sep='\t', index_col=0)
            st.write(f"Significant (FDR<0.05): {(res_df['adj.P.Val']<0.05).sum()}")
            st.dataframe(res_df)

            file_name = file_name_head + "_limma_" + full_model.replace(" + ", "_").replace(" ", "") + "_vs_" + reduced_model.replace(" + ", "_").replace(" ", "")

            shutil.make_archive("res", format='zip',root_dir= res_dir)


        elif test_method == 'Beta Regression':
            # ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜ã¨è¨­å®šã¯åŒã˜
            counts_file = os.path.join(temp_dir, 'counts.tsv')
            df.to_csv(counts_file, sep='\t')
            coldata_file = os.path.join(temp_dir, 'coldata.tsv')
            df_e.to_csv(coldata_file, sep='\t', index=False)


            r_code = f"""
            library(betareg)
            library(lmtest)
            library(parallel)

            counts <- read.table('{counts_file}', header=TRUE, row.names=1, sep='\t')
            coldata <- read.table('{coldata_file}', header=TRUE, sep='\t')

            # 0-1ã®å¢ƒç•Œã®èª¿æ•´
            eps <- {epsilon}
            counts <- pmax(pmin(counts, 1-eps), eps)

            # ä¸¦åˆ—å‡¦ç†ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®è¨­å®š
            n_cores <- {n_cores}
            cl <- makeCluster(n_cores)

            # ä¸¦åˆ—å‡¦ç†ã«å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã«èª­ã¿è¾¼ã¿
            clusterEvalQ(cl, {{
              library(betareg)
              library(lmtest)
            }})

            time_var <- "{full[0]}"
            cat("time_var")
            cat(time_var)

            # æ™‚é–“å¤‰æ•°ã®ç¢ºèªã¨å¤‰æ›
            if(time_var %in% colnames(coldata)) {{
              cat("Time variable exists in coldata. Values:", "\\n")
              print(coldata[[time_var]])
              
              # æ™‚é–“å¤‰æ•°ãŒæ•°å€¤ã§ãªã„å ´åˆã¯å¤‰æ›
              if(!is.numeric(coldata[[time_var]])) {{
                cat("Converting time variable to numeric\\n")
                # æ•°å€¤æŠ½å‡ºã¨å¤‰æ›
                coldata[[time_var]] <- as.numeric(gsub("[^0-9.]", "", as.character(coldata[[time_var]])))
                cat("After conversion:", "\\n")
                print(coldata[[time_var]])
              }}
            }} else {{
              cat("WARNING: Time variable not found in coldata!\\n")
            }}

            # å¤šé …å¼ã®æ¬¡æ•°ã«åŸºã¥ãé …ã‚’æ§‹ç¯‰
            polynomial_terms <- ""
            if ({beta_polynomial_degree} >= 2) {{
              polynomial_terms <- paste0(polynomial_terms, " + I(", time_var, "^2)")
            }}
            if ({beta_polynomial_degree} >= 3) {{
              polynomial_terms <- paste0(polynomial_terms, " + I(", time_var, "^3)")
            }}

            # å¤‰æ•°ã‚’ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã«é€ä¿¡
            clusterExport(cl, c("counts", "coldata", "eps", "time_var", "polynomial_terms"))

            # å‡¦ç†é–‹å§‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            cat("Starting parallel beta regression on", n_cores, "cores for", nrow(counts), "genes\\n")

            # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«å®Ÿè¡Œ
            test_model_result <- tryCatch({{
              # ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ‡ãƒ¼ã‚¿
              test_gene_data <- data.frame(y=as.numeric(counts[1,]), coldata)
              
              # ãƒ•ã‚©ãƒ¼ãƒŸãƒ¥ãƒ©ã‚’æ§‹ç¯‰
              full_formula <- paste("{full_model.replace('~', '')}", polynomial_terms)
              
              # ãƒ¢ãƒ‡ãƒ«é©åˆã‚’è©¦è¡Œ
              test_fit <- betareg(as.formula(paste("y ~", full_formula)), data=test_gene_data)
              "success"
            }}, error=function(e) {{
              # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™
              return(conditionMessage(e))
            }})

            # ã‚¨ãƒ©ãƒ¼ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼åˆæœŸåŒ–
            error_counter <- 0
            error_message <- ""

            # ä¸¦åˆ—å‡¦ç†é–¢æ•°
            process_gene <- function(i) {{
              gene_data <- data.frame(y=as.numeric(counts[i,]), coldata)
              
              full_formula <- paste("{full_model.replace('~', '')}", polynomial_terms)
              reduced_formula <- "{reduced_model.replace('~', '')}"
              
              tryCatch({{
                # ãƒ•ãƒ«ãƒ¢ãƒ‡ãƒ«ã¨ãƒªãƒ‡ãƒ¥ãƒ¼ã‚¹ãƒ‰ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°
                full_fit <- betareg(as.formula(paste("y ~", full_formula)), data=gene_data)
                reduced_fit <- betareg(as.formula(paste("y ~", reduced_formula)), data=gene_data)
                
                # å°¤åº¦æ¯”æ¤œå®š
                lr_test <- lrtest(reduced_fit, full_fit)
                
                # çµæœã‚’è¿”ã™
                c(statistic = lr_test$Chisq[2],
                  df = lr_test$Df[2],
                  p_value = lr_test$`Pr(>Chisq)`[2],
                  logLik_diff = lr_test$LogLik[2] - lr_test$LogLik[1])
              }}, error=function(e) {{
                # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯NAã‚’è¿”ã™
                if (i <= 5) cat("Gene", i, "Error:", conditionMessage(e), "\\n")
                c(statistic = NA, df = NA, p_value = NA, logLik_diff = NA)
              }})
            }}

            # ä¸¦åˆ—å‡¦ç†ã®å®Ÿè¡Œ
            system.time(
              results_list <- parLapply(cl, 1:nrow(counts), process_gene)
            )

            # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®çµ‚äº†
            stopCluster(cl)

            # çµæœã‚’ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã«å¤‰æ›
            results_matrix <- do.call(rbind, results_list)
            rownames(results_matrix) <- rownames(counts)

            # NULLã®æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
            na_count <- sum(is.na(results_matrix[, "statistic"]))
            total_genes <- nrow(results_matrix)
            na_percent <- round(100 * na_count / total_genes, 2)

            # çµæœãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’è¿½åŠ 
            cat("\\n### ãƒ¢ãƒ‡ãƒ«åæŸæƒ…å ± ###\\n", file='{res_dir}/model_convergence_info.txt')
            cat("å¤šé …å¼æ¬¡æ•°:", {beta_polynomial_degree}, "\\n", file='{res_dir}/model_convergence_info.txt', append=TRUE)
            cat("ãƒ•ãƒ«ãƒ¢ãƒ‡ãƒ«å¼:", paste("y ~", paste("{full_model.replace('~', '')}", polynomial_terms)), "\\n", file='{res_dir}/model_convergence_info.txt', append=TRUE)
            cat("ç¸®å°ãƒ¢ãƒ‡ãƒ«å¼:", paste("y ~", "{reduced_model.replace('~', '')}"), "\\n", file='{res_dir}/model_convergence_info.txt', append=TRUE)

            if (na_count > 0) {{
              cat("è­¦å‘Š: ", na_count, " å€‹ã®éºä¼å­ (", na_percent, "%) ã§ãƒ¢ãƒ‡ãƒ«ãŒåæŸã—ã¾ã›ã‚“ã§ã—ãŸã€‚\\n", file='{res_dir}/model_convergence_info.txt', append=TRUE)
              
              if (na_count == total_genes) {{
                cat("ã™ã¹ã¦ã®éºä¼å­ã§ãƒ¢ãƒ‡ãƒ«ãŒåæŸã—ã¾ã›ã‚“ã§ã—ãŸã€‚å¤šé …å¼æ¬¡æ•°ã‚’ä¸‹ã’ã‚‹ã‹ã€æ™‚é–“å¤‰æ•°ã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã™ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚\\n", file='{res_dir}/model_convergence_info.txt', append=TRUE)
                cat("ãƒ†ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®ã‚¨ãƒ©ãƒ¼: ", test_model_result, "\\n", file='{res_dir}/model_convergence_info.txt', append=TRUE)
              }} else {{
                cat(total_genes - na_count, " å€‹ã®éºä¼å­ (", 100 - na_percent, "%) ã§æ­£å¸¸ã«è§£æã§ãã¾ã—ãŸã€‚\\n", file='{res_dir}/model_convergence_info.txt', append=TRUE)
              }}
            }} else {{
              cat("ã™ã¹ã¦ã®éºä¼å­ã§æ­£å¸¸ã«ãƒ¢ãƒ‡ãƒ«ãŒåæŸã—ã¾ã—ãŸã€‚\\n", file='{res_dir}/model_convergence_info.txt', append=TRUE)
            }}

            # å¤šé‡æ¤œå®šè£œæ­£
            results_matrix <- cbind(results_matrix, 
                                  adj.P.Val = p.adjust(results_matrix[, "p_value"], method="BH"))

            # çµæœã®ä¿å­˜
            res_df <- as.data.frame(results_matrix)
            res_df <- res_df[order(res_df$p_value), ]
            write.table(res_df, file='{res_dir}/betareg_res.tsv', sep='\\t', quote=FALSE, col.names=NA)
            """

        elif test_method == 'GAM Beta Regression':
            # Save input to files for R import
            counts_file = os.path.join(temp_dir, 'counts.tsv')
            df.to_csv(counts_file, sep='\t')
            coldata_file = os.path.join(temp_dir, 'coldata.tsv')
            df_e.to_csv(coldata_file, sep='\t', index=False)
            
            # GAMãƒ™ãƒ¼ã‚¿å›å¸°ï¼ˆä¸¦åˆ—å‡¦ç†ç‰ˆï¼‰
            r_code = f"""
            library(mgcv)
            library(lmtest)
            library(parallel)

            counts <- read.table('{counts_file}', header=TRUE, row.names=1, sep='\t')
            coldata <- read.table('{coldata_file}', header=TRUE, sep='\t')

            # 0-1ã®å¢ƒç•Œã®èª¿æ•´
            eps <- {epsilon}
            counts <- pmax(pmin(counts, 1-eps), eps)

            # æ™‚é–“å¤‰æ•°ã®ç‰¹å®š
            time_vars <- colnames(coldata)[grep("time|Time|day|Day|week|Week", colnames(coldata))]

            # å„å¤‰æ•°ã®ä¸€æ„ãªå€¤ã®æ•°ã‚’ç¢ºèª
            n_unique_values <- sapply(coldata, function(x) length(unique(x)))

            # GAMãƒ¢ãƒ‡ãƒ«å¼ã®ä½œæˆ - å‰è¿°ã¨åŒæ§˜ã®é–¢æ•°
            # ...

            # ä¸¦åˆ—ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®è¨­å®š
            n_cores <- {n_cores}
            cl <- makeCluster(n_cores)

            # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã«å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã¨ãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡
            clusterEvalQ(cl, {{
              library(mgcv)
              library(lmtest)
            }})

            clusterExport(cl, c("counts", "coldata", "eps", "gam_full_formula", 
                                "gam_reduced_formula", "time_vars"))

            # å‡¦ç†é–¢æ•°
            process_gene <- function(i) {{
              gene_data <- data.frame(y=as.numeric(counts[i,]), coldata)
              
              result <- tryCatch({{
                # ãƒ•ãƒ«ãƒ¢ãƒ‡ãƒ«ã¨ç¸®å°ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°
                full_fit <- gam(as.formula(paste("y", gam_full_formula)), 
                                family=betar(), data=gene_data, method="{gam_method}")
                
                reduced_fit <- gam(as.formula(paste("y", gam_reduced_formula)), 
                                   family=betar(), data=gene_data, method="{gam_method}")
                
                # å°¤åº¦æ¯”æ¤œå®š
                lr_test <- lrtest(reduced_fit, full_fit)
                
                # çµæœã‚’è¿”ã™
                c(statistic = lr_test$Chisq[2],
                  df = lr_test$Df[2],
                  p_value = lr_test$`Pr(>Chisq)`[2],
                  logLik_diff = lr_test$LogLik[2] - lr_test$LogLik[1])
              }}, error=function(e) {{
                # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯NAã‚’è¿”ã™
                c(statistic = NA, df = NA, p_value = NA, logLik_diff = NA)
              }})
              
              return(result)
            }}

            # ä¸¦åˆ—å‡¦ç†ã®å®Ÿè¡Œ
            system.time(
              results_list <- parLapply(cl, 1:nrow(counts), process_gene)
            )

            # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®çµ‚äº†
            stopCluster(cl)

            # çµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
            results_matrix <- do.call(rbind, results_list)
            results <- as.data.frame(results_matrix)
            rownames(results) <- rownames(counts)

            # å¤šé‡æ¤œå®šè£œæ­£
            results$adj.P.Val <- p.adjust(results$p_value, method="BH")

            # çµæœã®ä¿å­˜
            write.table(results[order(results$p_value), ], file='{res_dir}/gam_betareg_parallel.tsv', sep='\\t', quote=FALSE, col.names=NA)
            """


        elif test_method == 'maSigPro':
            # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜è¨­å®š
            counts_file = os.path.join(temp_dir, 'counts.tsv')
            df.to_csv(counts_file, sep='\t')
            coldata_file = os.path.join(temp_dir, 'coldata.tsv')
            df_e.to_csv(coldata_file, sep='\t', index=False)


            # æ™‚é–“æƒ…å ±ã‚’å«ã‚€é©åˆ‡ãªedesignãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆã™ã‚‹Rã‚³ãƒ¼ãƒ‰
            r_code = f"""
            library(maSigPro)
            
            # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
            cat("Loading data...\\n")
            counts <- read.table("{counts_file}", header=TRUE, row.names=1, sep="\\t")
            coldata <- read.table("{coldata_file}", header=TRUE, sep="\\t")
            print(coldata)

            # maSigProç”¨ã®é©åˆ‡ãªãƒ‡ã‚¶ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
            cat("Creating proper design matrix for maSigPro...\\n")
            
            # ã‚°ãƒ«ãƒ¼ãƒ—æƒ…å ±ã‚’å–å¾—ï¼ˆ"Group"åˆ—ï¼‰
            time_col <- as.character(coldata${full[0]})
            

            # æ™‚é–“æƒ…å ±ã‚’æŠ½å‡ºï¼ˆä¾‹ï¼š"0w", "1w", "4w"ã‹ã‚‰æ•°å€¤ã«å¤‰æ›ï¼‰
            time_values <- as.numeric(gsub("[^0-9.]", "", time_col))
            cat("time_values")
            cat(time_values)
            
            # ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ãƒˆæƒ…å ±ã‚’ä½œæˆ
            # åŒã˜æ™‚é–“å€¤ã‚’æŒã¤ã‚µãƒ³ãƒ—ãƒ«ã«ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªç•ªå·ã‚’å‰²ã‚Šå½“ã¦
            replicates <- numeric(length(time_values))
            for (t in unique(time_values)) {{
                idx <- which(time_values == t)
                replicates[idx] <- 1:length(idx)
            }}
            
            # maSigProç”¨ã®æ­£ã—ã„edesignãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
            edesign <- data.frame(
                Time = time_values,
                Replicate = replicates
            )
            rownames(edesign) <- colnames(counts)
            
      #      # ä»–ã®å®Ÿé¨“æ¡ä»¶ãŒã‚ã‚Œã°è¿½åŠ 
      #      if (ncol(coldata) > 1) {{
      #          for (i in 2:ncol(coldata)) {{
      #              col_name <- colnames(coldata)[i]
      #              edesign[[col_name]] <- coldata[[i]]
      #          }}
      #      }}

            # Add Group column (all 1s for single condition)
            edesign$Group <- rep(1, nrow(edesign)) #tutorialã«åˆã‚ã›ã¦å…¨éƒ¨1ã«ã™ã‚‹
            
            # ãƒ‡ãƒ¼ã‚¿å‹ã®ç¢ºèª
            cat("Time values:", paste(time_values, collapse=", "), "\\n")
            cat("Time values are numeric:", is.numeric(edesign$Time), "\\n")
            cat("edesign")
            print(edesign)
            
            # å‰å‡¦ç†
            """
            
            # ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸå‡¦ç†ã®è¿½åŠ 
            if data_type == "0-1 data (logit transformation)":
                r_code += f"""
            # 0-1ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†
            eps <- {epsilon}
            counts <- pmax(pmin(counts, 1-eps), eps)
            counts <- log(counts/(1-counts))
            use_counts_param <- FALSE
            cat("Applied logit transformation\\n")
            """
            else:  # RNA-seq count data
                r_code += """
            # RNA-seqãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†
            use_counts_param <- TRUE
            cat("Using GLM for count data\\n")
            """
            
            # ãƒ‡ã‚¶ã‚¤ãƒ³è¡Œåˆ—ã‚’ä½¿ç”¨ã—ãŸåˆ†æ
            r_code += f"""
            # ãƒ‡ã‚¶ã‚¤ãƒ³è¡Œåˆ—ã‚’ä½¿ç”¨ã—ã¦åˆ†æ
            cat("Running maSigPro analysis...\\n")
            
            # æŒ‡å®šã•ã‚ŒãŸæ¬¡æ•°ã§ãƒ‡ã‚¶ã‚¤ãƒ³è¡Œåˆ—ã‚’ä½œæˆ
            design <- make.design.matrix(edesign, degree={degree})
            
            # å›å¸°åˆ†æã®å®Ÿè¡Œ
            cat("Running p.vector...\\n")
            fit <- p.vector(counts, design$edesign, Q={q_value}, MT.adjust="none", counts=use_counts_param)
           # fit <- p.vector(counts, design$edesign, Q={q_value}, MT.adjust="BH", counts=use_counts_param)
            
            # æœ‰æ„ãªéºä¼å­æ•°ã®ç¢ºèª
            sig_count <- sum(fit$p < {q_value}, na.rm=TRUE)
            cat("Genes with p <", {q_value}, ":", sig_count, "\\n")

            # After running p.vector() and finding no significant genes

            
            # æœ‰æ„ãªéºä¼å­ãŒã‚ã‚‹å ´åˆã®ã¿æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¸
            if (sig_count > 0) {{
                cat("Running T.fit...\\n")
                tstep <- T.fit(fit, step.method="backward", alfa={q_value})
                
                cat("Getting significant genes...\\n")
                sigs <- get.siggenes(tstep, rsq={rsq}, vars="each")
                
                # çµæœã‚’ä¿å­˜
                if (!is.null(sigs) && !is.null(sigs$sig.genes) && !is.null(sigs$sig.genes$sig.profiles) && nrow(sigs$sig.genes$sig.profiles) > 0) {{
                    cat("Found", nrow(sigs$sig.genes$sig.profiles), "significant genes\\n")
                    
                    # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã¨ä¿‚æ•°ã‚’ä¿å­˜
                    write.table(sigs$sig.genes$sig.profiles, file="{res_dir}/maSigPro_sig_profiles.tsv", sep="\\t", quote=FALSE)
                    write.table(sigs$coefficients, file="{res_dir}/maSigPro_coefficients.tsv", sep="\\t", quote=FALSE)
                    
                    # è¦ç´„æƒ…å ±ã®ä¿å­˜
                    cat("maSigPro Analysis Results\\n",
                        "------------------------\\n",
                        "Total genes analyzed: ", nrow(counts), "\\n",
                        "Significant genes (p <", {q_value}, "): ", sig_count, "\\n",
                        "Significant genes (rsq >", {rsq}, "): ", nrow(sigs$sig.genes$sig.profiles), "\\n",
                        file="{res_dir}/maSigPro_summary.txt")
                }} else {{
                    cat("No genes passed R-squared threshold\\n")
                    cat("No genes passed R-squared threshold of", {rsq}, "\\n", file="{res_dir}/maSigPro_summary.txt")
                }}
            }} else {{
                cat("No significant genes found\\n")
                cat("No significant genes found at Q-value", {q_value}, "\\n", file="{res_dir}/maSigPro_summary.txt")
            }}
            """
            
            # Rã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œ
            with st.spinner('Calculating maSigPro... This may take a while.'):
                try:
                    # Rã‚³ãƒ¼ãƒ‰ã‚’ãƒ‡ãƒãƒƒã‚°ç”¨ã«ä¿å­˜
                    with open(os.path.join(temp_dir, 'debug_maSigPro.R'), 'w') as f:
                        f.write(r_code)
                    
                    # Rã‚³ãƒ¼ãƒ‰å®Ÿè¡Œ
                    ro.r(r_code)
                    
                    # çµæœç”¨ã®ç©ºãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆï¼ˆã‚¨ãƒ©ãƒ¼å›é¿ç”¨ï¼‰
                    res_df = pd.DataFrame()
                    
                    # çµæœã®è¡¨ç¤º
                    st.markdown("### maSigPro Analysis Results")
                    
                    # çµæœãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèªã¨è¡¨ç¤º
                    summary_file = os.path.join(res_dir, 'maSigPro_summary.txt')
                    if os.path.exists(summary_file):
                        with open(summary_file, 'r') as f:
                            summary = f.read()
                        st.text(summary)
                    
                    # æœ‰æ„ãªéºä¼å­ã®çµæœã‚’è¡¨ç¤º
                    sig_profiles_file = os.path.join(res_dir, 'maSigPro_sig_profiles.tsv')
                    if os.path.exists(sig_profiles_file):
                        res_df = pd.read_csv(sig_profiles_file, sep='\t', index_col=0)
                        if not res_df.empty:
                            st.write("### Top significant genes:")
                            st.dataframe(res_df.head(10))
                            
                            # ä¿‚æ•°ã®è¡¨ç¤º
                            coef_file = os.path.join(res_dir, 'maSigPro_coefficients.tsv')
                            if os.path.exists(coef_file):
                                st.write("### Regression coefficients:")
                                coef = pd.read_csv(coef_file, sep='\t', index_col=0)
                                st.dataframe(coef.head(10))
                            
                            # çµæœã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                            file_name = file_name_head + "_maSigPro"
                            shutil.make_archive("res", format='zip', root_dir=res_dir)
                    else:
                        st.info("No significant genes were found. Try adjusting the Q-value or R-squared threshold.")
                
                except Exception as e:
                    st.error(f"Error executing R code: {str(e)}")
                    # ã‚¨ãƒ©ãƒ¼æ™‚ã«ã‚‚ç©ºã®DataFrameã‚’ä½œæˆ
                    res_df = pd.DataFrame()
            
     
            
            # çµæœã®ZIPç”Ÿæˆ
            file_name = file_name_head + "_maSigPro"
            shutil.make_archive("res", format='zip', root_dir=res_dir)

        # çµæœã®è¡¨ç¤ºã¨ä¿å­˜
        if test_method == 'Beta Regression':
            ro.r(r_code)
            res_df = pd.read_csv(os.path.join(res_dir, 'betareg_res.tsv'), sep='\t', index_col=0)
            st.write(f"Significant (FDR<0.05): {(res_df['adj.P.Val']<0.05).sum()}")
            st.dataframe(res_df)

            # ãƒ¢ãƒ‡ãƒ«åæŸæƒ…å ±ã®ç¢ºèªã¨è¡¨ç¤º
            convergence_file = os.path.join(res_dir, 'model_convergence_info.txt')
            if os.path.exists(convergence_file):
                with open(convergence_file, 'r') as f:
                    convergence_info = f.read()
        
            # åæŸã«å•é¡ŒãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if "è­¦å‘Š" in convergence_info:
                st.warning(convergence_info)
            else:
                st.success(convergence_info)
                
                file_name = file_name_head + "_betareg_" + full_model.replace(" + ", "_").replace(" ", "") + "_vs_" + reduced_model.replace(" + ", "_").replace(" ", "")
                shutil.make_archive("res", format='zip',root_dir= res_dir)

        elif test_method == 'GAM Beta Regression':
            ro.r(r_code)
            res_df = pd.read_csv(os.path.join(res_dir, 'gam_betareg_res.tsv'), sep='\t', index_col=0)
            st.write(f"Significant (FDR<0.05): {(res_df['adj.P.Val']<0.05).sum()}")
            st.dataframe(res_df)
            
            file_name = file_name_head + "_gam_betareg_" + full_model.replace(" + ", "_").replace(" ", "") + "_vs_" + reduced_model.replace(" + ", "_").replace(" ", "")
            shutil.make_archive("res", format='zip',root_dir= res_dir)

        if res_df is not None:
            with open("res.zip", "rb") as fp:
                btn = st.download_button(
                    label="Download Results",
                data=fp,
                file_name=file_name + "_DESeq2-LRT.zip",
                mime = "zip"
                )
            try:
                os.remove(file_name + "_DESeq2-LRT.zip")
                shutil.rmtree(temp_dir)
                os.mkdir(temp_dir)
            except:
                pass


#ã€€ãƒ‡ãƒ¼ã‚¿ã‚’é€ã‚‹å‰ã«ã™ã¹ã¦ã‚¼ãƒ­ã®ãƒ‡ãƒ¼ã‚¿ã¯é™¤ãã¹ã


# refãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹ã¨ãã¯ãƒ•ã‚¡ã‚¤ãƒ«åã‚’èª¿æ•´ã™ã‚‹?
