
import scanpy as sc
import memento
import pandas as pd
import numpy as np
import os
from helper_func import clear_old_directories
from helper_func import clear_old_files
import time
import streamlit as st
from scipy.sparse import csr_matrix, isspmatrix_csr, issparse
import shutil
from statsmodels.stats.multitest import multipletests
st.set_page_config(page_title="Memento", page_icon="ğŸ’¬")

import scipy as sp
from scipy import interpolate

def estimate(pv, m=None, verbose=False, lowmem=False, pi0=None):
    """
    Estimates q-values from p-values

    Args
    =====

    m: number of tests. If not specified m = pv.size
    verbose: print verbose messages? (default False)
    lowmem: use memory-efficient in-place algorithm
    pi0: if None, it's estimated as suggested in Storey and Tibshirani, 2003.
         For most GWAS this is not necessary, since pi0 is extremely likely to be
         1

    """
    assert(pv.min() >= 0 and pv.max() <= 1), "p-values should be between 0 and 1"

    original_shape = pv.shape
    pv = pv.ravel()  # flattens the array in place, more efficient than flatten()

    if m is None:
        m = float(len(pv))
    else:
        # the user has supplied an m
        m *= 1.0

    # if the number of hypotheses is small, just set pi0 to 1
    if len(pv) < 100 and pi0 is None:
        pi0 = 1.0
    elif pi0 is not None:
        pi0 = pi0
    else:
        # evaluate pi0 for different lambdas
        pi0 = []
        lam = np.arange(0, 0.90, 0.01)
        counts = np.array([(pv > i).sum() for i in np.arange(0, 0.9, 0.01)])
        for l in range(len(lam)):
            pi0.append(counts[l]/(m*(1-lam[l])))

        pi0 = np.array(pi0)

        # fit natural cubic spline
        tck = interpolate.splrep(lam, pi0, k=3)
        pi0 = interpolate.splev(lam[-1], tck)
        if verbose:
            print("qvalues pi0=%.3f, estimated proportion of null features " % pi0)

        if pi0 > 1:
            if verbose:
                print("got pi0 > 1 (%.3f) while estimating qvalues, setting it to 1" % pi0)
            pi0 = 1.0

    assert(pi0 >= 0 and pi0 <= 1), "pi0 is not between 0 and 1: %f" % pi0

    if lowmem:
        # low memory version, only uses 1 pv and 1 qv matrices
        qv = sp.zeros((len(pv),))
        last_pv = pv.argmax()
        qv[last_pv] = (pi0*pv[last_pv]*m)/float(m)
        pv[last_pv] = -sp.inf
        prev_qv = last_pv
        for i in range(int(len(pv))-2, -1, -1):
            cur_max = pv.argmax()
            qv_i = (pi0*m*pv[cur_max]/float(i+1))
            pv[cur_max] = -sp.inf
            qv_i1 = prev_qv
            qv[cur_max] = min(qv_i, qv_i1)
            prev_qv = qv[cur_max]

    else:
        p_ordered = np.argsort(pv)
        pv = pv[p_ordered]
        qv = pi0 * m/len(pv) * pv
        qv[-1] = min(qv[-1], 1.0)

        for i in range(len(pv)-2, -1, -1):
            qv[i] = min(pi0*m*pv[i]/(i+1.0), qv[i+1])

        # reorder qvalues
        qv_temp = qv.copy()
        qv = np.zeros_like(qv)
        qv[p_ordered] = qv_temp

    # reshape qvalues
    qv = qv.reshape(original_shape)

    return qv

def convert_covariates_to_numeric(adata, covariate_cols):
    """
    æŒ‡å®šã•ã‚ŒãŸã‚«ãƒ©ãƒ ã‚’æ•°å€¤ã«å¤‰æ›ã—ã¾ã™ã€‚
    
    Args:
        adata: AnnData object
        covariate_cols: æ•°å€¤ã«å¤‰æ›ã—ãŸã„ã‚«ãƒ©ãƒ ã®ãƒªã‚¹ãƒˆ
    
    Returns:
        å¤‰æ›å¾Œã®AnnData object
    """
    adata = adata.copy()
    
    for col in covariate_cols:
        # ã‚«ãƒ©ãƒ ã®å‹ã‚’ç¢ºèª
        if adata.obs[col].dtype == 'object' or adata.obs[col].dtype == 'category':
            unique_values = adata.obs[col].unique()
            if len(unique_values) <= 100:
                # ã‚«ãƒ†ã‚´ãƒªæ•°ãŒ10ä»¥ä¸‹ã®å ´åˆã¯ãƒ©ãƒ™ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
                categories = pd.Categorical(adata.obs[col]).categories
                adata.obs[col] = pd.Categorical(adata.obs[col]).codes

            else:
                try:
                    # 10åˆ†ä½æ•°ã«åˆ†å‰²ï¼ˆé‡è¤‡ã‚’è¨±å¯ï¼‰
                    adata.obs[col] = pd.qcut(
                        pd.factorize(adata.obs[col])[0], 
                        q=10, 
                        labels=False,
                        duplicates='drop'  # é‡è¤‡ã™ã‚‹å€¤ã¯å‰Šé™¤
                    )
                    st.write(f"{col} was divided into quantiles")
                except:
                    # qcutãŒå¤±æ•—ã—ãŸå ´åˆã¯å˜ç´”ãªãƒ©ãƒ™ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
                    categories = pd.Categorical(adata.obs[col]).categories
                    adata.obs[col] = pd.Categorical(adata.obs[col]).codes
                    st.write(f"Fallback to label encoding for {col}")
                    for i, cat in enumerate(categories):
                        st.write(f"{cat} -> {i}")
        else:
            st.write(f"{col} is already numeric")
            
    return adata

def run_memento_by_group(adata, groupby, label_columns, num_cpus=12, num_boot=5000, min_perc_group=0.9):
    # ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã®çµæœã‚’æ ¼ç´ã™ã‚‹è¾æ›¸
    results_dict = {}
    
    # ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã«ãƒ«ãƒ¼ãƒ—
    for group in adata.obs[groupby].unique():
        # ã‚°ãƒ«ãƒ¼ãƒ—ã§ãƒ‡ãƒ¼ã‚¿ã‚’ã‚µãƒ–ã‚»ãƒƒãƒˆ
        group_adata = adata[adata.obs[groupby] == group].copy()
        
        try:
            # mementoã®è§£æã‚’å®Ÿè¡Œ

            if len(cov_column) > 0:

            #    adata.obs['capture_rate'] = capture_rate
                memento.setup_memento(group_adata, q_column='capture_rate')
                memento.create_groups(group_adata, label_columns=label_columns) 
                # 3. ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆè¨ˆç®—
                memento.compute_1d_moments(group_adata, min_perc_group=min_perc_group)           
                # 4. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æº–å‚™
                sample_meta = memento.get_groups(group_adata)
                # The covariate DataFrame - pick the covariate columns
                cov_df = sample_meta[cov_column]
                st.write()

                # The treatment DataFrame - pick the treatment column
                treat_df = sample_meta[['condition_encoded']]

                memento.ht_1d_moments(
                    group_adata,
                    treatment=treat_df,
                    covariate=cov_df,
                    num_boot=num_boot,
                    num_cpus=num_cpus
                )
                result = memento.get_1d_ht_result(group_adata)   
            
            else:
                #wrapper functionã‚’ãã®ã¾ã¾æ›¸ã
             #   adata.obs['capture_rate'] = capture_rate
                memento.setup_memento(group_adata, q_column='capture_rate')
                memento.create_groups(group_adata, label_columns=['condition_encoded'])
                memento.compute_1d_moments(group_adata, min_perc_group=min_perc_group)
                sample_meta = memento.get_groups(group_adata)[['condition_encoded']]
                memento.ht_1d_moments(
                    group_adata, 
                    treatment=sample_meta,
                    num_boot=num_boot,
                    num_cpus=num_cpus)
                result = memento.get_1d_ht_result(group_adata)

            # çµæœã‚’è¾æ›¸ã«ä¿å­˜
            results_dict[group] = result
            st.write(f"Completed analysis for {group}")
            
        except Exception as e:
            st.write(f"Error in group {group}: {str(e)}")
            continue
    
    return results_dict



def save_results_to_tsv(results_dict, memento_temp_dir, comparison_str, control_group, test_group, adata, groupby):
    if os.path.exists(memento_temp_dir + "/memento"):
        shutil.rmtree(memento_temp_dir + "/memento")
    os.mkdir(memento_temp_dir + "/memento")
    for celltype, result in results_dict.items():
        filename = memento_temp_dir + "/memento/" + celltype.replace('/', '_').replace(' ', '_') + comparison_str + '.tsv'
        result.set_index('gene', inplace=True)

        try:
            # ãã®ç´°èƒã‚¿ã‚¤ãƒ—ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            if groupby == "asone":
                adata_subset = adata.copy()
            else:
                adata_subset = adata[adata.obs[groupby] == celltype].copy()
            
            # ãƒ‡ãƒ¼ã‚¿ã®çŠ¶æ…‹ã‚’ç¢ºèª
          #  st.write(f"\nDiagnostics for {celltype}:")
         #   value_counts = adata_subset.obs['condition_encoded'].value_counts()
          #  st.write("condition_encoded values:")
         #   st.write(value_counts)
            
            if len(adata_subset) == 0:
                st.write(f"No cells found for {celltype}")
                continue
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¨æ­£è¦åŒ–
            cell_counts = adata_subset.X.sum(axis=1).A1
            adata_subset = adata_subset[cell_counts > 0].copy()
            
            if len(adata_subset) == 0:
                st.write(f"No valid cells after filtering for {celltype}")
                continue
                
            # æ­£è¦åŒ–
            adata_norm = adata_subset.copy()
            sc.pp.normalize_total(adata_norm)
            sc.pp.log1p(adata_norm)
            
            # æ¡ä»¶ã”ã¨ã®å¹³å‡ã‚’è¨ˆç®—
            cond_0 = adata_norm.obs['condition_encoded'] == 0
            cond_1 = adata_norm.obs['condition_encoded'] == 1
            
            if not any(cond_0) or not any(cond_1):
                st.write(f"Missing one or both conditions for {celltype}")
                st.write("Number of condition 0:", sum(cond_0))
                st.write("Number of condition 1:", sum(cond_1))
                continue
                
            mean_0 = adata_norm[cond_0].X.mean(axis=0).A1
            mean_1 = adata_norm[cond_1].X.mean(axis=0).A1
            
            result_genes = result.index.to_list()
          
            df_mean = pd.DataFrame(index = adata_norm.var_names)
            df_mean[f'mean_expr_{control_group}'] = mean_0
            df_mean[f'mean_expr_{test_group}'] = mean_1
            df_mean['log2FC'] = df_mean[f'mean_expr_{test_group}'] - df_mean[f'mean_expr_{control_group}']
            result['log2FC'] = df_mean.loc[result_genes,'log2FC']
            result[f'mean_expr_{control_group}'] = df_mean.loc[result_genes,f'mean_expr_{control_group}']
            result[f'mean_expr_{test_group}'] = df_mean.loc[result_genes,f'mean_expr_{test_group}']
            result = result.sort_values(by='de_pval', ascending = True)
            st.write(f"Saved results for {celltype}")
            st.write(result.head())
            # ä¿å­˜
            result.to_csv(filename, sep='\t')
            
        except Exception as e:
            st.write(f"Error saving {celltype}: Detailed error - {type(e).__name__}: {str(e)}")


def prepare_covariates(adata, covariate_cols):
    """
    adata.obsã‹ã‚‰æŒ‡å®šã•ã‚ŒãŸåˆ—ã‚’å–å¾—ã—ã€å¿…è¦ã«å¿œã˜ã¦ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–ã—ã¾ã™ã€‚
    
    Args:
        adata: AnnData object
        covariate_cols: covariateã¨ã—ã¦ä½¿ç”¨ã™ã‚‹åˆ—åã®ãƒªã‚¹ãƒˆ
    
    Returns:
        pd.DataFrame: å‡¦ç†æ¸ˆã¿ã®covariate dataframe
    """
    cov_df = pd.DataFrame(index=adata.obs.index)
    
    for col in covariate_cols:
        # åˆ—ã®ãƒ‡ãƒ¼ã‚¿å‹ã‚’ç¢ºèª
        dtype = adata.obs[col].dtype
        
        # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ï¼ˆobjectã¾ãŸã¯categoryï¼‰ã®å ´åˆ
        if dtype == 'object' or dtype == 'category':
            # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ã®æ•°ã‚’ç¢ºèª
            n_unique = len(adata.obs[col].unique())
            
            if n_unique == 2:
                # 2å€¤ã‚«ãƒ†ã‚´ãƒªã®å ´åˆã¯0/1ã«å¤‰æ›
                cov_df[col] = (adata.obs[col] == adata.obs[col].unique()[1]).astype(int)
            else:
                # 3å€¤ä»¥ä¸Šã®ã‚«ãƒ†ã‚´ãƒªã¯ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–
                dummy = pd.get_dummies(adata.obs[col], prefix=col)
                # å¤šé‡å…±ç·šæ€§ã‚’é¿ã‘ã‚‹ãŸã‚ã€æœ€å¾Œã®åˆ—ã‚’é™¤å¤–
                cov_df = pd.concat([cov_df, dummy.iloc[:, :-1]], axis=1)
        
        # æ•°å€¤å‹ã®å ´åˆã¯ãã®ã¾ã¾ä½¿ç”¨
        else:
            cov_df[col] = adata.obs[col]
    
    # interceptã‚’è¿½åŠ 
    cov_df['intercept'] = 1
    
    return cov_df


@st.cache_data
def read_h5ad(file):
    adata = sc.read_h5ad(file)
    st.write("uploaded_file data")
    temp_df = pd.DataFrame(
    adata.raw.X[:5,:8].toarray() if issparse(adata.raw.X) else adata.raw.X[:5,:8],
    index=adata.obs_names[:5],
    columns=adata.var_names[:8]
    )
    st.dataframe(temp_df) 
    return adata

def find_first_index_or_zero(lst, elements):
    for element in elements:
        try:
            return lst.index(element)
        except ValueError:
            continue
    return 0



#============ æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸã¨ãã¯ã€cacheã‚’clearã™ã‚‹

def get_file_identifier(file):
    if file is not None:
        return f"{file.name}_{file.size}"
    return None


# tempå†…ã«ä¿å­˜ã™ã‚‹
# --- Initialising SessionState ---
if "memento_temp_dir" not in st.session_state:
    memento_temp_dir = "temp/" + str(round(time.time()))
    if not os.path.exists('temp'):
        os.mkdir('temp')
    else:
        clear_old_directories("temp")
        clear_old_files("temp")
    if not os.path.exists(memento_temp_dir):
        os.mkdir(memento_temp_dir)
#    if not os.path.exists(memento_temp_dir + "/memento"):
#        os.mkdir(memento_temp_dir + "/memento")
    st.session_state.memento_temp_dir = memento_temp_dir
else:
    memento_temp_dir = st.session_state.memento_temp_dir


uploaded_file = st.file_uploader("Upload a h5ad file", type=['h5ad'])

if uploaded_file  is not None:
    current_file_id = get_file_identifier(uploaded_file)

    if 'last_file_id' not in st.session_state:
        st.session_state.last_file_id = None

    if current_file_id != st.session_state.last_file_id:
        st.cache_data.clear()
        st.cache_resource.clear()
        st.session_state.last_file_id = current_file_id
        st.success("æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸã€‚")

#---------------

    adata = read_h5ad(uploaded_file)


    meta = adata.obs.columns.to_list()
    for i in ['nFeature_RNA','nCount_RNA','percent.mt', 'Cell_id']:
        try:
            meta.remove(i)
        except:
            pass
    submitted_basic = False

    st.markdown("##### Select condition:")
    sampleby = st.selectbox("sample/condition:", meta, index = find_first_index_or_zero(meta, ["orig.ident",
    "sample","KO"]), label_visibility = 'collapsed')
    sample_list = sorted(adata.obs[sampleby].cat.categories.to_list())

    if len(sample_list) > 2:
        # è¤‡æ•°ã®æ¡ä»¶ã‹ã‚‰2ã¤ã‚’é¸æŠã™ã‚‹ãƒãƒ«ãƒã‚»ãƒ¬ã‚¯ãƒˆ
        selected_conditions = st.multiselect(
            "Select 2 conditions to compare:",
            sample_list,
            max_selections=2  # æœ€å¤§2ã¤ã¾ã§é¸æŠå¯èƒ½
        )
        
        # 2ã¤é¸æŠã•ã‚Œã‚‹ã¾ã§å¾…æ©Ÿ
        if len(selected_conditions) != 2:
            st.warning("Please select exactly 2 conditions to compare.")
            st.stop()
            
        # é¸æŠã•ã‚ŒãŸ2æ¡ä»¶ã§ãƒ‡ãƒ¼ã‚¿ã‚’ã‚µãƒ–ã‚»ãƒƒãƒˆåŒ–
        mask = adata.obs[sampleby].isin(selected_conditions)
        adata = adata[mask].copy()
        
        # condition_encodedã‚«ãƒ©ãƒ ã®ä½œæˆï¼ˆ1ã¤ç›®ã®æ¡ä»¶ã‚’0ã€2ã¤ç›®ã‚’1ã¨ã™ã‚‹ï¼‰
        adata.obs['condition_encoded'] = (adata.obs[sampleby] == selected_conditions[1]).astype(int)
        
        # é¸æŠã•ã‚ŒãŸæ¡ä»¶ã‚’è¡¨ç¤º
        st.write(f"Comparing: {selected_conditions[0]} and {selected_conditions[1]}")

        sample_list = selected_conditions
        
    elif len(sample_list) < 2:
        st.warning("At least 2 conditions are required.")
        st.stop()

    st.markdown("##### Select control group:")
    control_group = st.radio("Control group",[sample_list[0], sample_list[1]], index =0, label_visibility = 'collapsed')
    test_group = [i for i in sample_list if i != control_group][0]

    comparison_str = "_" + test_group + "_vs_" + control_group + "_"

    st.markdown("---")

    asone = st.checkbox("Treat all cells as one type?")

    if not asone:
        st.markdown("##### Select cell type:")
        groupby = st.selectbox("cell identity:", [x for x in meta if x != sampleby], index = find_first_index_or_zero(meta, ["cell.ident", "seurat_clusters"]), label_visibility = 'collapsed')
        cell_list = sorted(adata.obs[groupby].cat.categories.to_list())
    else:
        groupby = "asone"

    st.write(f"Conditions: {', '.join(sample_list)}")
    if not asone:
        st.write(f"Cell types: {', '.join(cell_list)}")

    st.markdown("---")

    cov_column = []
    label_columns = ['condition_encoded']
    add_covariates = st.checkbox("Add covariates (e.g., replicates, batch)")
    if add_covariates:
        cov_options = [x for x in adata.obs.columns.to_list() if x not in [sampleby, groupby]]
        cov_column = st.multiselect("Choose covariates", cov_options)
        #cov_df = prepare_covariates(adata, cov_column)        
        label_columns.extend(cov_column)

        # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ã‚’covariatesã‚ˆã†ã«å¤‰æ›
        adata = convert_covariates_to_numeric(adata, covariate_cols=cov_column)
    
    use_saturation_col = st.checkbox("Use a column containing sequence saturation for each sample?")
    if use_saturation_col:
        saturation_col = st.selectbox("Select thec colum for seq saturation", meta)
        adata.obs['capture_rate'] = adata.obs[[saturation_col]] * 0.25

    else:
        st.markdown("Please see web_summay.html for sequence saturation")
        saturation = st.number_input("Sequence saturation", min_value=0.10, max_value=1.00, value = 1.00, step = 0.05)
        capture_rate=0.25 * saturation
        adata.obs['capture_rate'] = capture_rate

    min_perc_group = st.number_input("min_percent_group", min_value=0.01, max_value=1.00, value = 0.70, step = 0.05)
    st.write("The minimum fraction of cells in each group where a gene must be detected to be included in the analysis")
    st.write("The default value is 0.7.(May need to decrease to analyze low expression genes.)")
    st.write("sequence saturationã‚’ä½ä¸‹ã•ã›ã‚‹ã»ã©ã€ã¾ãŸmin_percent_groupã‚’ä½ä¸‹ã•ã›ã‚‹ã»ã©ã€å˜ç´”ãªæ¯”è¼ƒã‚ˆã‚ŠFCãŒä¹–é›¢ã™ã‚‹éºä¼å­ãŒå¢—ãˆã‚‹å‚¾å‘")
    st.write("min_percent_group = 0.5ã¾ã§ã¯å¤§ããªä¹–é›¢ã¯ãªã•ãã†ã ãŒã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã‚ˆã£ã¦ç¢ºèªã‚’")

    if st.button('Run analysis'):
        adata.obs['condition_encoded'] = (adata.obs[sampleby] == test_group).astype(int) #test_groupãŒ1ã«ãªã‚‹
        adata.X = adata.raw.X
        # adata.Xã®å½¢å¼ã‚’ç¢ºèªã—ã€CSRã§ãªã„å ´åˆã®ã¿å¤‰æ›
        if not isspmatrix_csr(adata.X):
            adata.X = csr_matrix(adata.X)


        num_cpus=12
        num_boot=5000


        # å®Ÿè¡Œä¾‹ï¼ˆä¾‹ãˆã°cell.ident2ã§ã‚°ãƒ«ãƒ¼ãƒ—åˆ†ã‘ï¼‰
        if not asone:
            results_by_celltype = run_memento_by_group(adata, groupby=groupby,  min_perc_group=min_perc_group, label_columns=label_columns)
        else:
            results_by_celltype = {}
                # mementoã®è§£æã‚’å®Ÿè¡Œ       
            if len(cov_column) > 0:

#                adata.obs['capture_rate'] = capture_rate
                memento.setup_memento(adata, q_column='capture_rate')
                memento.create_groups(adata, label_columns=label_columns) 
                # 3. ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆè¨ˆç®—
                memento.compute_1d_moments(adata, min_perc_group=min_perc_group)           
                # 4. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æº–å‚™
                sample_meta = memento.get_groups(adata)
                # The covariate DataFrame - pick the covariate columns
                cov_df = sample_meta[cov_column]

                # The treatment DataFrame - pick the treatment column
                treat_df = sample_meta[['condition_encoded']]


                memento.ht_1d_moments(
                    adata,
                    treatment=treat_df,
                    covariate=cov_df,
                    num_boot=num_boot,
                    num_cpus=num_cpus
                )
                result = memento.get_1d_ht_result(adata)   
            
            else:
                #wrapper functionã‚’ãã®ã¾ã¾æ›¸ã
                adata = adata.copy().copy()
                adata.obs['capture_rate'] = capture_rate
                memento.setup_memento(adata, q_column='capture_rate')
                memento.create_groups(adata, label_columns=['condition_encoded'])
                memento.compute_1d_moments(adata, min_perc_group=min_perc_group)
                sample_meta = memento.get_groups(adata)[['condition_encoded']]
                memento.ht_1d_moments(
                    adata, 
                    treatment=sample_meta,
                    num_boot=num_boot,
                    num_cpus=num_cpus)
                result = memento.get_1d_ht_result(adata)


            results_by_celltype["all_cells"] = result
  #      st.write(results_by_celltype)

        for celltype, result in results_by_celltype.items():
            # DM genes ã®è£œæ­£
            result['de_padj'] = multipletests(result.de_pval, method='fdr_bh')[1]
            result['de_STqval'] = estimate(result.de_pval)
            # DV genes ã®è£œæ­£
            result['dv_padj'] = multipletests(result.dv_pval, method='fdr_bh')[1]

                        # DE p-valueã§ã‚½ãƒ¼ãƒˆ
            result.sort_values('de_pval', ascending=True, inplace=True)
        st.markdown("##### Results summary")
        # çµæœã®ç¢ºèªä¾‹
        for celltype, result in results_by_celltype.items():
            st.write(f"\nResults for {celltype}:")
            st.write(f"Number of significant DM genes (FDR q<0.01): {sum(result.de_padj < 0.01)}")
            st.write(f"Number of significant DV genes (FDR q<0.1): {sum(result.dv_padj < 0.1)}")

        st.markdown("""
### 
##### Differential Mean (DM) genesï¼š
de_coef (mean effect size): 2ç¾¤é–“ã§ã®éºä¼å­ç™ºç¾ã®å¹³å‡å€¤ã®å·®ã®å¤§ãã•ã‚’ç¤ºã—ã¾ã™

å˜ç´”ãª2ç¾¤é–“æ¯”è¼ƒã§ã¯ln(FC) covariatesãŒã‚ã‚‹å ´åˆã¯å˜ç´”ãªln(FC)ã§ã¯ãªã„

æ­£ã®å€¤ï¼šå‡¦ç†ç¾¤ã§ç™ºç¾ãŒä¸Šæ˜‡

è² ã®å€¤ï¼šå‡¦ç†ç¾¤ã§ç™ºç¾ãŒæ¸›å°‘

de_pval: å¹³å‡å€¤ã®å·®ã«é–¢ã™ã‚‹çµ±è¨ˆçš„æœ‰æ„æ€§ã‚’ç¤ºã™på€¤ï¼ˆè£œæ­£å‰ï¼‰

de_padj: FDR

##### Differential Variability (DV) genesï¼š
ve_coef (variability effect size): 2ç¾¤é–“ã§ã®éºä¼å­ç™ºç¾ã®å¤‰å‹•ï¼ˆã°ã‚‰ã¤ãï¼‰ã®å·®ã®å¤§ãã•

æ­£ã®å€¤ï¼šå‡¦ç†ç¾¤ã§ç™ºç¾ã®ã°ã‚‰ã¤ããŒå¢—åŠ 

è² ã®å€¤ï¼šå‡¦ç†ç¾¤ã§ç™ºç¾ã®ã°ã‚‰ã¤ããŒæ¸›å°‘

dv_pval: ç™ºç¾å¤‰å‹•ã®å·®ã«é–¢ã™ã‚‹çµ±è¨ˆçš„æœ‰æ„æ€§ã‚’ç¤ºã™på€¤ï¼ˆè£œæ­£å‰ï¼‰)

dv_padj: FDR

åŸè‘—ã§ã¯DMG (differentially mean expression genes)ã¨ã—ã¦FDR<0.01ã‚’ç”¨ã„ã¦ã„ã‚‹ã€‚
DVG (Differentially variable genes) FDR<0.1
""")


        output_dir = os.path.join(memento_temp_dir, "memento")
        os.makedirs(output_dir, exist_ok=True)

        st.write(groupby)
        
        # çµæœã‚’TSVã¨ã—ã¦ä¿å­˜
        save_results_to_tsv(
            results_dict=results_by_celltype,
            memento_temp_dir=memento_temp_dir,
            comparison_str=comparison_str,
            control_group=control_group,
            test_group=test_group,
            adata=adata,
            groupby=groupby
        )
        # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        zip_path = os.path.join(memento_temp_dir, "memento.zip")
        

        # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
        shutil.make_archive(
            os.path.join(memento_temp_dir, "memento"), 
            'zip',
            root_dir=output_dir
        )
        
        # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
        with open(zip_path, "rb") as fp:
            zip_data = fp.read()
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã®è¡¨ç¤º
        st.download_button(
            label="Download Results",
            data=zip_data,
            file_name="memento_results.zip",
            mime="application/zip"
        )
                
